{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Back Translation + Synonym augmented possible only.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[],"mount_file_id":"1FRJvTJOJnCCC05umt-328dIdL2Zp24WC","authorship_tag":"ABX9TyO0vUP4zURBx0t9IRUJ8w8m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"130016c34d454517b87deef82e93803f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7454ee55cbf4439a65b0cb65316d541","IPY_MODEL_6bbca153740246439ca678d57876d700","IPY_MODEL_fab8f5e2022a48ae9601b2fce17d3d11"],"layout":"IPY_MODEL_6a9583cef5e44fc59e63cb1b47e61987"}},"d7454ee55cbf4439a65b0cb65316d541":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e53e9e4dce434968876e61eee05d7f98","placeholder":"​","style":"IPY_MODEL_454701725d1c4a66a7886bfe86019ab7","value":"Downloading data files: 100%"}},"6bbca153740246439ca678d57876d700":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_443b11740e2d43729c5129374c194987","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9be92769f4cd486c88b91716373675cf","value":2}},"fab8f5e2022a48ae9601b2fce17d3d11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef5a2d7d059345fda0f12ecfafdd1745","placeholder":"​","style":"IPY_MODEL_10152dfaa04944cca2e0d3069a06072b","value":" 2/2 [00:00&lt;00:00, 66.91it/s]"}},"6a9583cef5e44fc59e63cb1b47e61987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e53e9e4dce434968876e61eee05d7f98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"454701725d1c4a66a7886bfe86019ab7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"443b11740e2d43729c5129374c194987":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9be92769f4cd486c88b91716373675cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ef5a2d7d059345fda0f12ecfafdd1745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10152dfaa04944cca2e0d3069a06072b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48fb0df9f87d484aa2c6878978a4ace7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e69e762199a4860932f5729a60a4a68","IPY_MODEL_943f8a1121fa43059fddfd13819e397d","IPY_MODEL_8b729efc0be941f9944b3949200cc541"],"layout":"IPY_MODEL_b8bbaa91caae45ee83789acd64a7a24b"}},"7e69e762199a4860932f5729a60a4a68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c41ea972232482f954657751b618477","placeholder":"​","style":"IPY_MODEL_98b3ca9162d34ebabedf567b23aa86c8","value":"Extracting data files: 100%"}},"943f8a1121fa43059fddfd13819e397d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bc25ce5007cb416391ad195ef0ca6e2e","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_535be5a2c0e54d23a638d370f7093b20","value":2}},"8b729efc0be941f9944b3949200cc541":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31aaca35806b428a86ca1318c2116c4b","placeholder":"​","style":"IPY_MODEL_81d93d42dd6e4fd8a88fb56836272381","value":" 2/2 [00:00&lt;00:00, 37.73it/s]"}},"b8bbaa91caae45ee83789acd64a7a24b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c41ea972232482f954657751b618477":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98b3ca9162d34ebabedf567b23aa86c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc25ce5007cb416391ad195ef0ca6e2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"535be5a2c0e54d23a638d370f7093b20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31aaca35806b428a86ca1318c2116c4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81d93d42dd6e4fd8a88fb56836272381":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3cb01caa5aad43a88f9b0364255f6495":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_11fa8561a58147c78ef30841c6cfbaf1","IPY_MODEL_5f3266f879c7479d9fe6f58eabd917b9","IPY_MODEL_66369b216be34e83be90f76b4a6719b3"],"layout":"IPY_MODEL_6d4402f4b7c54d4aac00ea4b8f34cde8"}},"11fa8561a58147c78ef30841c6cfbaf1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6e9165b3c104133ae9c09ee36f9992a","placeholder":"​","style":"IPY_MODEL_270f8303230e42ac8011dacc0c2e79a9","value":"Generating train split: "}},"5f3266f879c7479d9fe6f58eabd917b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_40507ff95a50480ba0435974b2aa75ef","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05864f77bde44def8df23cf9ce736993","value":1}},"66369b216be34e83be90f76b4a6719b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad58ad88b14f41e09ad13b59740a80c8","placeholder":"​","style":"IPY_MODEL_aaf5c18e1d064544913951888dee2d41","value":" 129053/0 [00:12&lt;00:00, 12838.65 examples/s]"}},"6d4402f4b7c54d4aac00ea4b8f34cde8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6e9165b3c104133ae9c09ee36f9992a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"270f8303230e42ac8011dacc0c2e79a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40507ff95a50480ba0435974b2aa75ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"05864f77bde44def8df23cf9ce736993":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad58ad88b14f41e09ad13b59740a80c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaf5c18e1d064544913951888dee2d41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21ebf9b95bab496097cc40e6d2668c67":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_978741d3c8b148c683f83da748082c23","IPY_MODEL_fa2414abeb2f4a7ea7067721aaa0cd31","IPY_MODEL_38626ce976fd4a2f8404431e2d426f52"],"layout":"IPY_MODEL_33b522486f5a47c295ef8ed0a6b59d30"}},"978741d3c8b148c683f83da748082c23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5adbdb85b98407eae6097c3a25ae24a","placeholder":"​","style":"IPY_MODEL_8215287950d44d68993d0d5bbbdef033","value":"Generating validation split: "}},"fa2414abeb2f4a7ea7067721aaa0cd31":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_5de71fddc78a479fb234325b7dee7357","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8717c556487f431dba2221ac3f8bf53b","value":1}},"38626ce976fd4a2f8404431e2d426f52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48e06be5db2142e1861986223f349877","placeholder":"​","style":"IPY_MODEL_9582bedcd3154bb89ea8a295494dc14b","value":" 10620/0 [00:00&lt;00:00, 10919.37 examples/s]"}},"33b522486f5a47c295ef8ed0a6b59d30":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5adbdb85b98407eae6097c3a25ae24a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8215287950d44d68993d0d5bbbdef033":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5de71fddc78a479fb234325b7dee7357":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"8717c556487f431dba2221ac3f8bf53b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"48e06be5db2142e1861986223f349877":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9582bedcd3154bb89ea8a295494dc14b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"969ae9f3c853434584b0de2db01936f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e5c58fdb9cda4ff8bbb18924abc729cb","IPY_MODEL_53cd6faffb4045aaa5055d3b046e6b60","IPY_MODEL_b2c51fe13c5142e79ec509d7f57581d4"],"layout":"IPY_MODEL_924e49bd16934da382ecb505806a1c3c"}},"e5c58fdb9cda4ff8bbb18924abc729cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f8741c34f4e46a78f974fb9629fb3d4","placeholder":"​","style":"IPY_MODEL_2264896b951d4f8396b0c788ce1c4f91","value":"100%"}},"53cd6faffb4045aaa5055d3b046e6b60":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8100ef87d2a4c5c8136387eb143164d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_406a4fc6345b43b7b2f7a846d0925d91","value":2}},"b2c51fe13c5142e79ec509d7f57581d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bb3d9e541894cd688c5677873e3863e","placeholder":"​","style":"IPY_MODEL_badc6b98185441d6a0239ad4b4b0f78c","value":" 2/2 [00:00&lt;00:00, 51.64it/s]"}},"924e49bd16934da382ecb505806a1c3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f8741c34f4e46a78f974fb9629fb3d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2264896b951d4f8396b0c788ce1c4f91":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8100ef87d2a4c5c8136387eb143164d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"406a4fc6345b43b7b2f7a846d0925d91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4bb3d9e541894cd688c5677873e3863e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"badc6b98185441d6a0239ad4b4b0f78c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b64b657aa4344d9b81ee4e99782fa47":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6864904d54fe47bcbe451901fa521c53","IPY_MODEL_fc0079bdd4dc47c4b4b2073ccb8673fa","IPY_MODEL_15fcf29f4d6b4e0fa85be7a18e07791e"],"layout":"IPY_MODEL_526dafe5cf2d4610b0cf00df61313bae"}},"6864904d54fe47bcbe451901fa521c53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06c8925799404135857b90bbe08c6de1","placeholder":"​","style":"IPY_MODEL_9c757523e1564cab8e94c209d5508f88","value":"Pushing dataset shards to the dataset hub: 100%"}},"fc0079bdd4dc47c4b4b2073ccb8673fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_778c302e39754baeabb5c50076cc6715","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26c5f26ace7240d084d4cca9d0abedf1","value":1}},"15fcf29f4d6b4e0fa85be7a18e07791e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4530bdcc3b24c7bb7d18e0d1e67dec6","placeholder":"​","style":"IPY_MODEL_ba43630f161f4a978ebbe15279db46a9","value":" 1/1 [00:06&lt;00:00,  6.88s/it]"}},"526dafe5cf2d4610b0cf00df61313bae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06c8925799404135857b90bbe08c6de1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c757523e1564cab8e94c209d5508f88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"778c302e39754baeabb5c50076cc6715":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26c5f26ace7240d084d4cca9d0abedf1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4530bdcc3b24c7bb7d18e0d1e67dec6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba43630f161f4a978ebbe15279db46a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36fe2ad2022847e2a1f82347c1ea3d81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b87532a012d74305a1e6ecc7a54aaafc","IPY_MODEL_00ea330766c041ed8f483d160533c35c","IPY_MODEL_6639b526eec945e494736905a400f834"],"layout":"IPY_MODEL_229e5bb366204a6e825e526eb450da28"}},"b87532a012d74305a1e6ecc7a54aaafc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24e8ceca88de43f9875d94229078de92","placeholder":"​","style":"IPY_MODEL_198ec4114a2b4981ba1d2aca21f1a8e4","value":"Pushing dataset shards to the dataset hub: 100%"}},"00ea330766c041ed8f483d160533c35c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdc862b8ccb54ae59c954622a54ce4c2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d92d0afdcf1747a7ac6df6c9fa412c15","value":1}},"6639b526eec945e494736905a400f834":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c89acd153e747f9bbe48692ed170587","placeholder":"​","style":"IPY_MODEL_ee29a6a23f68430a92f96b32934d5079","value":" 1/1 [00:01&lt;00:00,  1.96s/it]"}},"229e5bb366204a6e825e526eb450da28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24e8ceca88de43f9875d94229078de92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"198ec4114a2b4981ba1d2aca21f1a8e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdc862b8ccb54ae59c954622a54ce4c2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d92d0afdcf1747a7ac6df6c9fa412c15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c89acd153e747f9bbe48692ed170587":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee29a6a23f68430a92f96b32934d5079":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70oLi9mZP6oK","executionInfo":{"status":"ok","timestamp":1649310841185,"user_tz":240,"elapsed":16,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"40f3ef60-6f63-43d1-8544-64719c2e5337"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Apr  7 05:53:59 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   43C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGqcN-zXTvvo","executionInfo":{"status":"ok","timestamp":1649310851067,"user_tz":240,"elapsed":9887,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"bd7666c3-2856-4d83-ef1b-cb982f00b856"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 51 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 61 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 71 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 81 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 92 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 102 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 112 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 122 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 133 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 143 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 153 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 163 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 174 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 184 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 194 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 204 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 215 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 225 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 235 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 245 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 256 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 266 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 276 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 286 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 296 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 307 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 317 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 325 kB 12.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 54.7 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 53.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 53.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 55.3 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 54.0 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 53.0 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.5 MB/s \n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}]},{"cell_type":"code","source":["!pip install git+https://github.com/huggingface/transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":867},"id":"tI_RBT1FSotu","outputId":"e2323662-96b3-4641-f836-0f1dd7381915","executionInfo":{"status":"ok","timestamp":1649310910480,"user_tz":240,"elapsed":28938,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-89e3o_57\n","  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-89e3o_57\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.63.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (1.21.5)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 11.9 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 61.9 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (3.6.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 45.3 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (0.5.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.11.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.0.dev0) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.0.dev0) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2021.10.8)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (7.1.2)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.19.0.dev0-py3-none-any.whl size=3965509 sha256=3fbcb10bedef6159b2f8f40e0f5fc6042e19f5dc6308c9eaefe02fcf401fcc4a\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7ocbzjdk/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.19.0.dev0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{}}]},{"cell_type":"code","source":["import torch\n","import datetime\n","import json\n","import os\n","import time\n","import datasets\n","import pprint\n","import random\n","import string\n","import sys\n","import transformers\n","from datasets import load_dataset\n","from datasets.tasks import QuestionAnsweringExtractive"],"metadata":{"id":"DZ3Ma-pCRJDJ","executionInfo":{"status":"ok","timestamp":1649310910480,"user_tz":240,"elapsed":19,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available()\n","                      else 'cpu')"],"metadata":{"id":"HNMUVyBpRGw8","executionInfo":{"status":"ok","timestamp":1649310910709,"user_tz":240,"elapsed":7,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/huggingface/transformers.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUVkgX-IQIiR","executionInfo":{"status":"ok","timestamp":1649310918924,"user_tz":240,"elapsed":8221,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"8b51840e-ea71-4695-9c96-ad2376a3c81d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 108786, done.\u001b[K\n","remote: Total 108786 (delta 0), reused 0 (delta 0), pack-reused 108786\u001b[K\n","Receiving objects: 100% (108786/108786), 95.51 MiB | 28.09 MiB/s, done.\n","Resolving deltas: 100% (79274/79274), done.\n"]}]},{"cell_type":"code","source":["dataset = load_dataset('/content/drive/MyDrive/QA/squad_v2_back_trans_synonym_possib_aug.py')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["130016c34d454517b87deef82e93803f","d7454ee55cbf4439a65b0cb65316d541","6bbca153740246439ca678d57876d700","fab8f5e2022a48ae9601b2fce17d3d11","6a9583cef5e44fc59e63cb1b47e61987","e53e9e4dce434968876e61eee05d7f98","454701725d1c4a66a7886bfe86019ab7","443b11740e2d43729c5129374c194987","9be92769f4cd486c88b91716373675cf","ef5a2d7d059345fda0f12ecfafdd1745","10152dfaa04944cca2e0d3069a06072b","48fb0df9f87d484aa2c6878978a4ace7","7e69e762199a4860932f5729a60a4a68","943f8a1121fa43059fddfd13819e397d","8b729efc0be941f9944b3949200cc541","b8bbaa91caae45ee83789acd64a7a24b","4c41ea972232482f954657751b618477","98b3ca9162d34ebabedf567b23aa86c8","bc25ce5007cb416391ad195ef0ca6e2e","535be5a2c0e54d23a638d370f7093b20","31aaca35806b428a86ca1318c2116c4b","81d93d42dd6e4fd8a88fb56836272381","3cb01caa5aad43a88f9b0364255f6495","11fa8561a58147c78ef30841c6cfbaf1","5f3266f879c7479d9fe6f58eabd917b9","66369b216be34e83be90f76b4a6719b3","6d4402f4b7c54d4aac00ea4b8f34cde8","d6e9165b3c104133ae9c09ee36f9992a","270f8303230e42ac8011dacc0c2e79a9","40507ff95a50480ba0435974b2aa75ef","05864f77bde44def8df23cf9ce736993","ad58ad88b14f41e09ad13b59740a80c8","aaf5c18e1d064544913951888dee2d41","21ebf9b95bab496097cc40e6d2668c67","978741d3c8b148c683f83da748082c23","fa2414abeb2f4a7ea7067721aaa0cd31","38626ce976fd4a2f8404431e2d426f52","33b522486f5a47c295ef8ed0a6b59d30","e5adbdb85b98407eae6097c3a25ae24a","8215287950d44d68993d0d5bbbdef033","5de71fddc78a479fb234325b7dee7357","8717c556487f431dba2221ac3f8bf53b","48e06be5db2142e1861986223f349877","9582bedcd3154bb89ea8a295494dc14b","969ae9f3c853434584b0de2db01936f5","e5c58fdb9cda4ff8bbb18924abc729cb","53cd6faffb4045aaa5055d3b046e6b60","b2c51fe13c5142e79ec509d7f57581d4","924e49bd16934da382ecb505806a1c3c","1f8741c34f4e46a78f974fb9629fb3d4","2264896b951d4f8396b0c788ce1c4f91","a8100ef87d2a4c5c8136387eb143164d","406a4fc6345b43b7b2f7a846d0925d91","4bb3d9e541894cd688c5677873e3863e","badc6b98185441d6a0239ad4b4b0f78c"]},"id":"A2gdlPTvcmfL","executionInfo":{"status":"ok","timestamp":1648782923409,"user_tz":240,"elapsed":16772,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"4ccb1132-cffd-4c2f-843c-d701095b5d62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset squad_v2_aug/squad_v2 to /root/.cache/huggingface/datasets/squad_v2_aug/squad_v2/2.0.0/84c134de7d4903651e59406b4e2bb5233fe8c842a4bb567981a35309318a9bb1...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"130016c34d454517b87deef82e93803f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48fb0df9f87d484aa2c6878978a4ace7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3cb01caa5aad43a88f9b0364255f6495"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21ebf9b95bab496097cc40e6d2668c67"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset squad_v2_aug downloaded and prepared to /root/.cache/huggingface/datasets/squad_v2_aug/squad_v2/2.0.0/84c134de7d4903651e59406b4e2bb5233fe8c842a4bb567981a35309318a9bb1. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"969ae9f3c853434584b0de2db01936f5"}},"metadata":{}}]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttpAfwxBWdR0","executionInfo":{"status":"ok","timestamp":1648782931332,"user_tz":240,"elapsed":7926,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"fa5ae0c6-04a9-4a51-cca5-3f932cad0030"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/token.\n","        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n","        \n","Token: \n","Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}]},{"cell_type":"code","source":["dataset.push_to_hub(\"sichenzhong/squad_v2_back_trans_synonym_possib_aug\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":150,"referenced_widgets":["7b64b657aa4344d9b81ee4e99782fa47","6864904d54fe47bcbe451901fa521c53","fc0079bdd4dc47c4b4b2073ccb8673fa","15fcf29f4d6b4e0fa85be7a18e07791e","526dafe5cf2d4610b0cf00df61313bae","06c8925799404135857b90bbe08c6de1","9c757523e1564cab8e94c209d5508f88","778c302e39754baeabb5c50076cc6715","26c5f26ace7240d084d4cca9d0abedf1","b4530bdcc3b24c7bb7d18e0d1e67dec6","ba43630f161f4a978ebbe15279db46a9","36fe2ad2022847e2a1f82347c1ea3d81","b87532a012d74305a1e6ecc7a54aaafc","00ea330766c041ed8f483d160533c35c","6639b526eec945e494736905a400f834","229e5bb366204a6e825e526eb450da28","24e8ceca88de43f9875d94229078de92","198ec4114a2b4981ba1d2aca21f1a8e4","fdc862b8ccb54ae59c954622a54ce4c2","d92d0afdcf1747a7ac6df6c9fa412c15","4c89acd153e747f9bbe48692ed170587","ee29a6a23f68430a92f96b32934d5079"]},"id":"WGAeWENJWR_F","executionInfo":{"status":"ok","timestamp":1648782943846,"user_tz":240,"elapsed":11308,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"bf6ce473-928e-4cb4-aa05-3eab279a021b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Pushing split train to the Hub.\n","The repository already exists: the `private` keyword argument will be ignored.\n"]},{"output_type":"display_data","data":{"text/plain":["Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b64b657aa4344d9b81ee4e99782fa47"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Pushing split validation to the Hub.\n","The repository already exists: the `private` keyword argument will be ignored.\n"]},{"output_type":"display_data","data":{"text/plain":["Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36fe2ad2022847e2a1f82347c1ea3d81"}},"metadata":{}}]},{"cell_type":"code","source":["%cd /content/transformers/examples/pytorch/question-answering/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uLaizsXQrk9","executionInfo":{"status":"ok","timestamp":1649310918925,"user_tz":240,"elapsed":7,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"e9e6169e-8f3c-48b2-e90f-74110411f8b6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/transformers/examples/pytorch/question-answering\n"]}]},{"cell_type":"code","source":["!python run_qa.py \\\n","  --model_name_or_path bert-base-cased \\\n","  --dataset_name sichenzhong/squad_v2_back_trans_synonym_possib_aug \\\n","  --do_train \\\n","  --do_eval \\\n","  --per_device_train_batch_size 16 \\\n","  --learning_rate 4e-5 \\\n","  --num_train_epochs 3 \\\n","  --max_seq_length 384 \\\n","  --doc_stride 128 \\\n","  --version_2_with_negative \\\n","  --output_dir /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aI-ipSbaHqF6","executionInfo":{"status":"ok","timestamp":1649327630538,"user_tz":240,"elapsed":16691528,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"478e274c-4e6b-407f-ac2d-d30ec4af915d"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["04/07/2022 05:55:42 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","04/07/2022 05:55:42 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.NO,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=4e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/runs/Apr07_05-55-42_1877836f64d8,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=OptimizerNames.ADAMW_HF,\n","output_dir=/content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=16,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","04/07/2022 05:55:44 - WARNING - datasets.builder - Using custom data configuration sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a\n","04/07/2022 05:55:44 - INFO - datasets.builder - Generating dataset parquet (/root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n","Downloading and preparing dataset squad_v2_aug/squad_v2 (download: 19.96 MiB, generated: 123.83 MiB, post-processed: Unknown size, total: 143.78 MiB) to /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n","04/07/2022 05:55:44 - INFO - datasets.builder - Dataset not on Hf google storage. Downloading and preparing it from source\n","Downloading data files:   0% 0/2 [00:00<?, ?it/s]04/07/2022 05:55:44 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_possib_aug/resolve/228e22f4230e6f7ea6aae00a0f74218ec91f5ac5/data/train-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp9ywc5zup\n","\n","Downloading data:   0% 0.00/19.7M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   0% 54.3k/19.7M [00:00<01:03, 311kB/s]\u001b[A\n","Downloading data:   2% 297k/19.7M [00:00<00:20, 930kB/s] \u001b[A\n","Downloading data:   5% 974k/19.7M [00:00<00:06, 2.81MB/s]\u001b[A\n","Downloading data:  10% 2.02M/19.7M [00:00<00:03, 5.22MB/s]\u001b[A\n","Downloading data:  20% 3.90M/19.7M [00:00<00:01, 9.43MB/s]\u001b[A\n","Downloading data:  37% 7.21M/19.7M [00:00<00:00, 16.7MB/s]\u001b[A\n","Downloading data:  53% 10.4M/19.7M [00:00<00:00, 21.4MB/s]\u001b[A\n","Downloading data:  68% 13.3M/19.7M [00:00<00:00, 22.0MB/s]\u001b[A\n","Downloading data: 100% 19.7M/19.7M [00:01<00:00, 16.8MB/s]\n","04/07/2022 05:55:46 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_possib_aug/resolve/228e22f4230e6f7ea6aae00a0f74218ec91f5ac5/data/train-00000-of-00001.parquet in cache at /root/.cache/huggingface/datasets/downloads/34f3d756050e734f058b03f08a18d3fbd6879814329b630f9e8f8417046f7422\n","04/07/2022 05:55:46 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/34f3d756050e734f058b03f08a18d3fbd6879814329b630f9e8f8417046f7422\n","Downloading data files:  50% 1/2 [00:02<00:02,  2.44s/it]04/07/2022 05:55:47 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_possib_aug/resolve/228e22f4230e6f7ea6aae00a0f74218ec91f5ac5/data/validation-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmph20lbmc9\n","\n","Downloading data:   0% 0.00/1.26M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   4% 53.2k/1.26M [00:00<00:03, 303kB/s]\u001b[A\n","Downloading data:  21% 262k/1.26M [00:00<00:01, 817kB/s] \u001b[A\n","Downloading data: 100% 1.26M/1.26M [00:00<00:00, 2.35MB/s]\n","04/07/2022 05:55:48 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_possib_aug/resolve/228e22f4230e6f7ea6aae00a0f74218ec91f5ac5/data/validation-00000-of-00001.parquet in cache at /root/.cache/huggingface/datasets/downloads/1a261e4eac272a75e2ca98ebede60eeb2e7dbfe0fa25f1875654dc145ea14b63\n","04/07/2022 05:55:48 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/1a261e4eac272a75e2ca98ebede60eeb2e7dbfe0fa25f1875654dc145ea14b63\n","Downloading data files: 100% 2/2 [00:04<00:00,  2.17s/it]\n","04/07/2022 05:55:48 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n","04/07/2022 05:55:48 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n","Extracting data files: 100% 2/2 [00:00<00:00, 1048.18it/s]\n","04/07/2022 05:55:48 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n","04/07/2022 05:55:48 - INFO - datasets.builder - Generating train split\n","04/07/2022 05:55:49 - INFO - datasets.builder - Generating validation split\n","04/07/2022 05:55:49 - INFO - datasets.utils.info_utils - All the splits matched successfully.\n","Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n","100% 2/2 [00:00<00:00, 229.52it/s]\n","[INFO|hub.py:583] 2022-04-07 05:55:49,408 >> https://huggingface.co/bert-base-cased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpd73dy4im\n","Downloading: 100% 570/570 [00:00<00:00, 427kB/s]\n","[INFO|hub.py:587] 2022-04-07 05:55:49,758 >> storing https://huggingface.co/bert-base-cased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","[INFO|hub.py:595] 2022-04-07 05:55:49,758 >> creating metadata file for /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","[INFO|configuration_utils.py:654] 2022-04-07 05:55:49,758 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","[INFO|configuration_utils.py:690] 2022-04-07 05:55:49,759 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","[INFO|hub.py:583] 2022-04-07 05:55:50,105 >> https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2r77ets8\n","Downloading: 100% 29.0/29.0 [00:00<00:00, 21.8kB/s]\n","[INFO|hub.py:587] 2022-04-07 05:55:50,454 >> storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","[INFO|hub.py:595] 2022-04-07 05:55:50,454 >> creating metadata file for /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","[INFO|configuration_utils.py:654] 2022-04-07 05:55:50,802 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","[INFO|configuration_utils.py:690] 2022-04-07 05:55:50,803 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","[INFO|hub.py:583] 2022-04-07 05:55:51,502 >> https://huggingface.co/bert-base-cased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpe4t_xy22\n","Downloading: 100% 208k/208k [00:00<00:00, 660kB/s]\n","[INFO|hub.py:587] 2022-04-07 05:55:52,173 >> storing https://huggingface.co/bert-base-cased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","[INFO|hub.py:595] 2022-04-07 05:55:52,173 >> creating metadata file for /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","[INFO|hub.py:583] 2022-04-07 05:55:52,529 >> https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpq696tds6\n","Downloading: 100% 426k/426k [00:00<00:00, 1.07MB/s]\n","[INFO|hub.py:587] 2022-04-07 05:55:53,288 >> storing https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","[INFO|hub.py:595] 2022-04-07 05:55:53,288 >> creating metadata file for /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 05:55:54,357 >> loading file https://huggingface.co/bert-base-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/6508e60ab3c1200bffa26c95f4b58ac6b6d95fba4db1f195f632fa3cd7bc64cc.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 05:55:54,357 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/226a307193a9f4344264cdc76a12988448a25345ba172f2c7421f3b6810fddad.3dab63143af66769bbb35e3811f75f7e16b2320e12b7935e216bd6159ce6d9a6\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 05:55:54,357 >> loading file https://huggingface.co/bert-base-cased/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 05:55:54,358 >> loading file https://huggingface.co/bert-base-cased/resolve/main/special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 05:55:54,358 >> loading file https://huggingface.co/bert-base-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/ec84e86ee39bfe112543192cf981deebf7e6cbe8c91b8f7f8f63c9be44366158.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n","[INFO|configuration_utils.py:654] 2022-04-07 05:55:54,718 >> loading configuration file https://huggingface.co/bert-base-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a803e0468a8fe090683bdc453f4fac622804f49de86d7cecaee92365d4a0f829.a64a22196690e0e82ead56f388a3ef3a50de93335926ccfa20610217db589307\n","[INFO|configuration_utils.py:690] 2022-04-07 05:55:54,719 >> Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","[INFO|hub.py:583] 2022-04-07 05:55:55,129 >> https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp52e4hm0c\n","Downloading: 100% 416M/416M [00:08<00:00, 51.9MB/s]\n","[INFO|hub.py:587] 2022-04-07 05:56:03,577 >> storing https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","[INFO|hub.py:595] 2022-04-07 05:56:03,577 >> creating metadata file for /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","[INFO|modeling_utils.py:1772] 2022-04-07 05:56:03,578 >> loading weights file https://huggingface.co/bert-base-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/092cc582560fc3833e556b3f833695c26343cb54b7e88cd02d40821462a74999.1f48cab6c959fc6c360d22bea39d06959e90f5b002e77e836d2da45464875cda\n","[WARNING|modeling_utils.py:2049] 2022-04-07 05:56:05,482 >> Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:2060] 2022-04-07 05:56:05,482 >> Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Running tokenizer on train dataset:   0% 0/131 [00:00<?, ?ba/s]04/07/2022 05:56:06 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-c70828dbf0206d39.arrow\n","Running tokenizer on train dataset: 100% 131/131 [00:52<00:00,  2.52ba/s]\n","Running tokenizer on validation dataset:   0% 0/12 [00:00<?, ?ba/s]04/07/2022 05:56:57 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-f6aafdfe218b674c.arrow\n","Running tokenizer on validation dataset: 100% 12/12 [01:16<00:00,  6.34s/ba]\n","04/07/2022 05:58:14 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/2.0.0/metrics/squad_v2/squad_v2.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp0ewc_3d1\n","Downloading builder script: 6.46kB [00:00, 6.16MB/s]       \n","04/07/2022 05:58:14 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/2.0.0/metrics/squad_v2/squad_v2.py in cache at /root/.cache/huggingface/datasets/downloads/28e260e79373763d7435864d09ebeccbfa7b9903d7901d5283b0d6b7265e34c7.20ffda40aa962d94515737edbb5a7eda5c13e771416809a70e82ce2aee1820fd.py\n","04/07/2022 05:58:14 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/28e260e79373763d7435864d09ebeccbfa7b9903d7901d5283b0d6b7265e34c7.20ffda40aa962d94515737edbb5a7eda5c13e771416809a70e82ce2aee1820fd.py\n","04/07/2022 05:58:14 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/2.0.0/metrics/squad_v2/evaluate.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp3r1_vk2i\n","Downloading extra modules: 11.3kB [00:00, 7.56MB/s]       \n","04/07/2022 05:58:14 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/2.0.0/metrics/squad_v2/evaluate.py in cache at /root/.cache/huggingface/datasets/downloads/a1b3f17173d6daeea11b56052a09e38922a52847495c5c51da69b6024f7bc6c5.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n","04/07/2022 05:58:14 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/a1b3f17173d6daeea11b56052a09e38922a52847495c5c51da69b6024f7bc6c5.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","[INFO|trainer.py:1290] 2022-04-07 05:58:30,385 >> ***** Running training *****\n","[INFO|trainer.py:1291] 2022-04-07 05:58:30,385 >>   Num examples = 132127\n","[INFO|trainer.py:1292] 2022-04-07 05:58:30,385 >>   Num Epochs = 3\n","[INFO|trainer.py:1293] 2022-04-07 05:58:30,385 >>   Instantaneous batch size per device = 16\n","[INFO|trainer.py:1294] 2022-04-07 05:58:30,385 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:1295] 2022-04-07 05:58:30,385 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1296] 2022-04-07 05:58:30,385 >>   Total optimization steps = 24774\n","{'loss': 2.4288, 'learning_rate': 3.919270202631792e-05, 'epoch': 0.06}\n","  2% 500/24774 [05:24<4:21:50,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 06:03:54,741 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:03:54,747 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:03:55,897 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:03:55,901 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:03:55,904 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-500/special_tokens_map.json\n","{'loss': 1.8312, 'learning_rate': 3.838540405263583e-05, 'epoch': 0.12}\n","  4% 1000/24774 [10:55<4:17:53,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:09:26,148 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:09:26,154 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:09:27,299 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:09:27,304 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:09:27,307 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1000/special_tokens_map.json\n","{'loss': 1.7076, 'learning_rate': 3.7578106078953745e-05, 'epoch': 0.18}\n","  6% 1500/24774 [16:23<4:11:38,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:14:54,144 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:14:54,150 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:14:55,296 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:14:55,301 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:14:55,305 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-1500/special_tokens_map.json\n","{'loss': 1.6028, 'learning_rate': 3.677080810527166e-05, 'epoch': 0.24}\n","  8% 2000/24774 [21:51<4:05:50,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:20:21,987 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:20:21,993 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:20:23,134 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:20:23,140 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:20:23,144 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2000/special_tokens_map.json\n","{'loss': 1.5594, 'learning_rate': 3.596351013158957e-05, 'epoch': 0.3}\n"," 10% 2500/24774 [27:19<4:00:26,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:25:49,684 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:25:49,691 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:25:50,844 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:25:50,849 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:25:50,852 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-2500/special_tokens_map.json\n","{'loss': 1.498, 'learning_rate': 3.515621215790749e-05, 'epoch': 0.36}\n"," 12% 3000/24774 [32:46<3:55:10,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:31:17,340 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:31:17,347 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:31:18,500 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:31:18,504 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:31:18,509 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3000/special_tokens_map.json\n","{'loss': 1.4561, 'learning_rate': 3.43489141842254e-05, 'epoch': 0.42}\n"," 14% 3500/24774 [38:14<3:49:45,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:36:45,068 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:36:45,074 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:36:46,227 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:36:46,232 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:36:46,235 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-3500/special_tokens_map.json\n","{'loss': 1.4158, 'learning_rate': 3.3541616210543315e-05, 'epoch': 0.48}\n"," 16% 4000/24774 [43:42<3:44:37,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:42:12,914 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:42:12,919 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:42:14,063 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:42:14,068 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:42:14,071 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4000/special_tokens_map.json\n","{'loss': 1.4018, 'learning_rate': 3.273431823686123e-05, 'epoch': 0.54}\n"," 18% 4500/24774 [49:09<3:38:48,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:47:40,405 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:47:40,412 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:47:41,575 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:47:41,579 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:47:41,583 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-4500/special_tokens_map.json\n","{'loss': 1.3891, 'learning_rate': 3.192702026317914e-05, 'epoch': 0.61}\n"," 20% 5000/24774 [54:37<3:33:20,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:53:08,254 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:53:08,259 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:53:09,393 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:53:09,397 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:53:09,400 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5000/special_tokens_map.json\n","{'loss': 1.334, 'learning_rate': 3.111972228949706e-05, 'epoch': 0.67}\n"," 22% 5500/24774 [1:00:08<3:28:09,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 06:58:38,715 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:58:38,721 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:58:39,868 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:58:39,873 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:58:39,877 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-5500/special_tokens_map.json\n","{'loss': 1.3603, 'learning_rate': 3.0312424315814968e-05, 'epoch': 0.73}\n"," 24% 6000/24774 [1:05:38<3:22:27,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 07:04:09,069 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:04:09,076 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:04:10,199 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:04:10,204 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:04:10,209 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6000/special_tokens_map.json\n","{'loss': 1.3031, 'learning_rate': 2.950512634213288e-05, 'epoch': 0.79}\n"," 26% 6500/24774 [1:11:08<3:16:53,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 07:09:39,310 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:09:39,316 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:09:40,463 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:09:40,467 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:09:40,471 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-6500/special_tokens_map.json\n","{'loss': 1.2999, 'learning_rate': 2.86978283684508e-05, 'epoch': 0.85}\n"," 28% 7000/24774 [1:16:38<3:11:40,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 07:15:09,296 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:15:09,303 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:15:10,461 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:15:10,466 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:15:10,470 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7000/special_tokens_map.json\n","{'loss': 1.2705, 'learning_rate': 2.7890530394768713e-05, 'epoch': 0.91}\n"," 30% 7500/24774 [1:22:06<3:06:30,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 07:20:37,147 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:20:37,154 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:20:38,312 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:20:38,317 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:20:38,321 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-7500/special_tokens_map.json\n","{'loss': 1.2723, 'learning_rate': 2.7083232421086627e-05, 'epoch': 0.97}\n"," 32% 8000/24774 [1:27:34<3:01:05,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 07:26:05,103 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:26:05,109 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:26:06,260 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:26:06,265 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:26:06,296 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8000/special_tokens_map.json\n","{'loss': 1.1027, 'learning_rate': 2.627593444740454e-05, 'epoch': 1.03}\n"," 34% 8500/24774 [1:33:02<2:55:33,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 07:31:32,916 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:31:32,922 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:31:34,098 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:31:34,102 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:31:34,126 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-8500/special_tokens_map.json\n","{'loss': 0.9401, 'learning_rate': 2.5468636473722455e-05, 'epoch': 1.09}\n"," 36% 9000/24774 [1:38:30<2:50:06,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 07:37:00,718 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:37:00,725 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:37:01,969 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:37:01,974 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:37:01,997 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9000/special_tokens_map.json\n","{'loss': 0.9589, 'learning_rate': 2.466133850004037e-05, 'epoch': 1.15}\n"," 38% 9500/24774 [1:43:58<2:44:58,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 07:42:29,183 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:42:29,195 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:42:30,398 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:42:30,402 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:42:30,406 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-9500/special_tokens_map.json\n","{'loss': 0.9545, 'learning_rate': 2.3854040526358283e-05, 'epoch': 1.21}\n"," 40% 10000/24774 [1:49:26<2:39:33,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 07:47:57,206 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:47:57,218 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:47:58,400 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:47:58,405 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:47:58,408 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10000/special_tokens_map.json\n","{'loss': 0.9503, 'learning_rate': 2.3046742552676197e-05, 'epoch': 1.27}\n"," 42% 10500/24774 [1:54:54<2:34:04,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 07:53:24,762 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:53:24,770 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:53:25,921 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:53:25,926 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:53:25,930 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-10500/special_tokens_map.json\n","{'loss': 0.9113, 'learning_rate': 2.223944457899411e-05, 'epoch': 1.33}\n"," 44% 11000/24774 [2:00:22<2:28:43,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 07:58:52,503 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:58:52,508 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:58:53,697 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:58:53,701 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:58:53,705 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11000/special_tokens_map.json\n","{'loss': 0.9408, 'learning_rate': 2.1432146605312025e-05, 'epoch': 1.39}\n"," 46% 11500/24774 [2:05:49<2:23:23,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 08:04:20,435 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11500\n","[INFO|configuration_utils.py:441] 2022-04-07 08:04:20,441 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:04:21,610 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:04:21,615 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:04:21,619 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-11500/special_tokens_map.json\n","{'loss': 0.9341, 'learning_rate': 2.0624848631629935e-05, 'epoch': 1.45}\n"," 48% 12000/24774 [2:11:18<2:17:48,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 08:09:48,466 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12000\n","[INFO|configuration_utils.py:441] 2022-04-07 08:09:48,473 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:09:49,650 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:09:49,655 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:09:49,659 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12000/special_tokens_map.json\n","{'loss': 0.9212, 'learning_rate': 1.981755065794785e-05, 'epoch': 1.51}\n"," 50% 12500/24774 [2:16:45<2:12:39,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 08:15:16,228 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12500\n","[INFO|configuration_utils.py:441] 2022-04-07 08:15:16,234 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:15:17,411 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:15:17,416 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:15:17,419 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-12500/special_tokens_map.json\n","{'loss': 0.9294, 'learning_rate': 1.9010252684265763e-05, 'epoch': 1.57}\n"," 52% 13000/24774 [2:22:13<2:06:56,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 08:20:44,031 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13000\n","[INFO|configuration_utils.py:441] 2022-04-07 08:20:44,036 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:20:45,185 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:20:45,189 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:20:45,193 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13000/special_tokens_map.json\n","{'loss': 0.9081, 'learning_rate': 1.8202954710583677e-05, 'epoch': 1.63}\n"," 54% 13500/24774 [2:27:41<2:01:36,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 08:26:11,669 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13500\n","[INFO|configuration_utils.py:441] 2022-04-07 08:26:11,676 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:26:12,857 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:26:12,861 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:26:12,865 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-13500/special_tokens_map.json\n","{'loss': 0.9102, 'learning_rate': 1.739565673690159e-05, 'epoch': 1.7}\n"," 57% 14000/24774 [2:33:08<1:56:19,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 08:31:39,168 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14000\n","[INFO|configuration_utils.py:441] 2022-04-07 08:31:39,174 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:31:40,341 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:31:40,368 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:31:40,372 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14000/special_tokens_map.json\n","{'loss': 0.9141, 'learning_rate': 1.6588358763219505e-05, 'epoch': 1.76}\n"," 59% 14500/24774 [2:38:36<1:50:49,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 08:37:06,880 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14500\n","[INFO|configuration_utils.py:441] 2022-04-07 08:37:06,886 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:37:08,039 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:37:08,043 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:37:08,047 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-14500/special_tokens_map.json\n","{'loss': 0.9145, 'learning_rate': 1.578106078953742e-05, 'epoch': 1.82}\n"," 61% 15000/24774 [2:44:04<1:45:21,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 08:42:34,453 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15000\n","[INFO|configuration_utils.py:441] 2022-04-07 08:42:34,458 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:42:35,600 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:42:35,604 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:42:35,608 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15000/special_tokens_map.json\n","{'loss': 0.8919, 'learning_rate': 1.4973762815855333e-05, 'epoch': 1.88}\n"," 63% 15500/24774 [2:49:31<1:40:05,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 08:48:01,960 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15500\n","[INFO|configuration_utils.py:441] 2022-04-07 08:48:01,966 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:48:03,140 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:48:03,145 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:48:03,149 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-15500/special_tokens_map.json\n","{'loss': 0.9003, 'learning_rate': 1.4166464842173247e-05, 'epoch': 1.94}\n"," 65% 16000/24774 [2:54:59<1:34:49,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 08:53:29,611 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16000\n","[INFO|configuration_utils.py:441] 2022-04-07 08:53:29,616 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:53:30,808 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:53:30,812 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:53:30,816 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16000/special_tokens_map.json\n","{'loss': 0.8931, 'learning_rate': 1.3359166868491161e-05, 'epoch': 2.0}\n"," 67% 16500/24774 [3:00:29<1:29:03,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 08:59:00,363 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16500\n","[INFO|configuration_utils.py:441] 2022-04-07 08:59:00,369 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:59:01,553 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:59:01,558 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:59:01,562 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-16500/special_tokens_map.json\n","{'loss': 0.6046, 'learning_rate': 1.2551868894809077e-05, 'epoch': 2.06}\n"," 69% 17000/24774 [3:06:00<1:23:42,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 09:04:31,129 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17000\n","[INFO|configuration_utils.py:441] 2022-04-07 09:04:31,136 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:04:32,330 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:04:32,335 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:04:32,339 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17000/special_tokens_map.json\n","{'loss': 0.5946, 'learning_rate': 1.174457092112699e-05, 'epoch': 2.12}\n"," 71% 17500/24774 [3:11:28<1:18:38,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 09:09:58,821 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17500\n","[INFO|configuration_utils.py:441] 2022-04-07 09:09:58,827 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:09:59,989 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:09:59,994 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:09:59,998 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-17500/special_tokens_map.json\n","{'loss': 0.5802, 'learning_rate': 1.0937272947444903e-05, 'epoch': 2.18}\n"," 73% 18000/24774 [3:16:56<1:13:05,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 09:15:26,627 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18000\n","[INFO|configuration_utils.py:441] 2022-04-07 09:15:26,633 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:15:27,802 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:15:27,807 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:15:27,812 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18000/special_tokens_map.json\n","{'loss': 0.5976, 'learning_rate': 1.0129974973762817e-05, 'epoch': 2.24}\n"," 75% 18500/24774 [3:22:26<1:07:45,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 09:20:57,075 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18500\n","[INFO|configuration_utils.py:441] 2022-04-07 09:20:57,083 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:20:58,318 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:20:58,323 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:20:58,326 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-18500/special_tokens_map.json\n","{'loss': 0.5912, 'learning_rate': 9.32267700008073e-06, 'epoch': 2.3}\n"," 77% 19000/24774 [3:27:54<1:02:16,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 09:26:24,631 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19000\n","[INFO|configuration_utils.py:441] 2022-04-07 09:26:24,638 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:26:25,847 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:26:25,852 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:26:25,856 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19000/special_tokens_map.json\n","{'loss': 0.5961, 'learning_rate': 8.515379026398645e-06, 'epoch': 2.36}\n"," 79% 19500/24774 [3:33:21<56:52,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 09:31:52,407 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19500\n","[INFO|configuration_utils.py:441] 2022-04-07 09:31:52,414 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:31:53,638 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:31:53,644 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:31:53,648 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-19500/special_tokens_map.json\n","{'loss': 0.5699, 'learning_rate': 7.708081052716559e-06, 'epoch': 2.42}\n"," 81% 20000/24774 [3:38:49<51:29,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 09:37:20,258 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20000\n","[INFO|configuration_utils.py:441] 2022-04-07 09:37:20,265 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:37:21,435 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:37:21,440 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:37:21,445 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20000/special_tokens_map.json\n","{'loss': 0.5891, 'learning_rate': 6.900783079034472e-06, 'epoch': 2.48}\n"," 83% 20500/24774 [3:44:17<46:13,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 09:42:48,097 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20500\n","[INFO|configuration_utils.py:441] 2022-04-07 09:42:48,103 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:42:49,270 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:42:49,276 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:42:49,280 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-20500/special_tokens_map.json\n","{'loss': 0.5753, 'learning_rate': 6.093485105352386e-06, 'epoch': 2.54}\n"," 85% 21000/24774 [3:49:45<40:45,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 09:48:15,874 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21000\n","[INFO|configuration_utils.py:441] 2022-04-07 09:48:15,880 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:48:17,054 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:48:17,059 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:48:17,063 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21000/special_tokens_map.json\n","{'loss': 0.58, 'learning_rate': 5.2861871316703e-06, 'epoch': 2.6}\n"," 87% 21500/24774 [3:55:16<35:20,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 09:53:46,655 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21500\n","[INFO|configuration_utils.py:441] 2022-04-07 09:53:46,662 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:53:47,843 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:53:47,848 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:53:47,852 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-21500/special_tokens_map.json\n","{'loss': 0.5857, 'learning_rate': 4.478889157988214e-06, 'epoch': 2.66}\n"," 89% 22000/24774 [4:00:47<29:54,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 09:59:17,522 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22000\n","[INFO|configuration_utils.py:441] 2022-04-07 09:59:17,527 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 09:59:18,711 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 09:59:18,716 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 09:59:18,720 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22000/special_tokens_map.json\n","{'loss': 0.5706, 'learning_rate': 3.6715911843061274e-06, 'epoch': 2.72}\n"," 91% 22500/24774 [4:06:14<24:32,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 10:04:45,232 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22500\n","[INFO|configuration_utils.py:441] 2022-04-07 10:04:45,237 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 10:04:46,411 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 10:04:46,416 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 10:04:46,420 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-22500/special_tokens_map.json\n","{'loss': 0.5725, 'learning_rate': 2.8642932106240418e-06, 'epoch': 2.79}\n"," 93% 23000/24774 [4:11:42<19:08,  1.55it/s][INFO|trainer.py:2166] 2022-04-07 10:10:13,179 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23000\n","[INFO|configuration_utils.py:441] 2022-04-07 10:10:13,185 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 10:10:14,348 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 10:10:14,353 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 10:10:14,357 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23000/special_tokens_map.json\n","{'loss': 0.5676, 'learning_rate': 2.0569952369419553e-06, 'epoch': 2.85}\n"," 95% 23500/24774 [4:17:10<13:46,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 10:15:41,315 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23500\n","[INFO|configuration_utils.py:441] 2022-04-07 10:15:41,321 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 10:15:42,518 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 10:15:42,524 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 10:15:42,529 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-23500/special_tokens_map.json\n","{'loss': 0.559, 'learning_rate': 1.2496972632598693e-06, 'epoch': 2.91}\n"," 97% 24000/24774 [4:22:38<08:22,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 10:21:09,400 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24000\n","[INFO|configuration_utils.py:441] 2022-04-07 10:21:09,407 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 10:21:10,611 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 10:21:10,617 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 10:21:10,622 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24000/special_tokens_map.json\n","{'loss': 0.5564, 'learning_rate': 4.4239928957778315e-07, 'epoch': 2.97}\n"," 99% 24500/24774 [4:28:06<02:57,  1.54it/s][INFO|trainer.py:2166] 2022-04-07 10:26:37,352 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24500\n","[INFO|configuration_utils.py:441] 2022-04-07 10:26:37,358 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 10:26:38,563 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 10:26:38,568 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 10:26:38,572 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/checkpoint-24500/special_tokens_map.json\n","100% 24774/24774 [4:31:08<00:00,  1.56it/s][INFO|trainer.py:1530] 2022-04-07 10:29:38,841 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 16268.4556, 'train_samples_per_second': 24.365, 'train_steps_per_second': 1.523, 'train_loss': 1.000983216894003, 'epoch': 3.0}\n","100% 24774/24774 [4:31:08<00:00,  1.52it/s]\n","[INFO|trainer.py:2166] 2022-04-07 10:29:38,847 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug\n","[INFO|configuration_utils.py:441] 2022-04-07 10:29:38,853 >> Configuration saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 10:29:40,183 >> Model weights saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 10:29:40,189 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 10:29:40,193 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =        3.0\n","  train_loss               =      1.001\n","  train_runtime            = 4:31:08.45\n","  train_samples            =     132127\n","  train_samples_per_second =     24.365\n","  train_steps_per_second   =      1.523\n","04/07/2022 10:29:40 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:567] 2022-04-07 10:29:40,992 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:2416] 2022-04-07 10:29:41,022 >> ***** Running Evaluation *****\n","[INFO|trainer.py:2418] 2022-04-07 10:29:41,022 >>   Num examples = 12199\n","[INFO|trainer.py:2421] 2022-04-07 10:29:41,023 >>   Batch size = 8\n","100% 1525/1525 [03:00<00:00,  8.63it/s]04/07/2022 10:32:56 - INFO - utils_qa - Post-processing 11873 example predictions split into 12199 features.\n","\n","  0% 0/11873 [00:00<?, ?it/s]\u001b[A\n","  0% 18/11873 [00:00<01:06, 179.07it/s]\u001b[A\n","  0% 54/11873 [00:00<00:41, 282.75it/s]\u001b[A\n","  1% 83/11873 [00:00<00:42, 279.36it/s]\u001b[A\n","  1% 118/11873 [00:00<00:38, 304.96it/s]\u001b[A\n","  1% 153/11873 [00:00<00:36, 320.84it/s]\u001b[A\n","  2% 189/11873 [00:00<00:35, 332.50it/s]\u001b[A\n","  2% 225/11873 [00:00<00:34, 340.91it/s]\u001b[A\n","  2% 261/11873 [00:00<00:33, 345.89it/s]\u001b[A\n","  3% 299/11873 [00:00<00:32, 353.55it/s]\u001b[A\n","  3% 335/11873 [00:01<00:33, 347.56it/s]\u001b[A\n","  3% 371/11873 [00:01<00:32, 349.28it/s]\u001b[A\n","  3% 407/11873 [00:01<00:32, 351.09it/s]\u001b[A\n","  4% 444/11873 [00:01<00:32, 356.00it/s]\u001b[A\n","  4% 480/11873 [00:01<00:32, 345.62it/s]\u001b[A\n","  4% 515/11873 [00:01<00:32, 345.94it/s]\u001b[A\n","  5% 550/11873 [00:01<00:32, 343.30it/s]\u001b[A\n","  5% 585/11873 [00:01<00:32, 344.00it/s]\u001b[A\n","  5% 623/11873 [00:01<00:31, 352.83it/s]\u001b[A\n","  6% 660/11873 [00:01<00:31, 355.37it/s]\u001b[A\n","  6% 696/11873 [00:02<00:31, 354.56it/s]\u001b[A\n","  6% 732/11873 [00:02<00:31, 352.94it/s]\u001b[A\n","  6% 768/11873 [00:02<00:32, 346.81it/s]\u001b[A\n","  7% 806/11873 [00:02<00:31, 354.47it/s]\u001b[A\n","  7% 843/11873 [00:02<00:30, 357.13it/s]\u001b[A\n","  7% 880/11873 [00:02<00:30, 357.16it/s]\u001b[A\n","  8% 917/11873 [00:02<00:30, 359.42it/s]\u001b[A\n","  8% 956/11873 [00:02<00:29, 366.70it/s]\u001b[A\n","  8% 993/11873 [00:02<00:30, 357.48it/s]\u001b[A\n","  9% 1029/11873 [00:02<00:31, 339.22it/s]\u001b[A\n","  9% 1064/11873 [00:03<00:33, 320.27it/s]\u001b[A\n","  9% 1097/11873 [00:03<00:34, 309.41it/s]\u001b[A\n"," 10% 1129/11873 [00:03<00:35, 302.11it/s]\u001b[A\n"," 10% 1160/11873 [00:03<00:35, 297.72it/s]\u001b[A\n"," 10% 1190/11873 [00:03<00:36, 295.59it/s]\u001b[A\n"," 10% 1220/11873 [00:03<00:36, 294.54it/s]\u001b[A\n"," 11% 1250/11873 [00:03<00:36, 290.24it/s]\u001b[A\n"," 11% 1280/11873 [00:03<00:36, 290.22it/s]\u001b[A\n"," 11% 1310/11873 [00:03<00:36, 287.59it/s]\u001b[A\n"," 11% 1339/11873 [00:04<00:36, 287.11it/s]\u001b[A\n"," 12% 1368/11873 [00:04<00:36, 287.06it/s]\u001b[A\n"," 12% 1397/11873 [00:04<00:36, 284.15it/s]\u001b[A\n"," 12% 1426/11873 [00:04<00:36, 284.08it/s]\u001b[A\n"," 12% 1456/11873 [00:04<00:36, 287.02it/s]\u001b[A\n"," 13% 1485/11873 [00:04<00:36, 286.17it/s]\u001b[A\n"," 13% 1515/11873 [00:04<00:36, 287.55it/s]\u001b[A\n"," 13% 1545/11873 [00:04<00:35, 288.83it/s]\u001b[A\n"," 13% 1574/11873 [00:04<00:35, 287.08it/s]\u001b[A\n"," 14% 1603/11873 [00:05<00:35, 287.54it/s]\u001b[A\n"," 14% 1632/11873 [00:05<00:35, 285.70it/s]\u001b[A\n"," 14% 1661/11873 [00:05<00:35, 285.63it/s]\u001b[A\n"," 14% 1690/11873 [00:05<00:35, 285.22it/s]\u001b[A\n"," 14% 1719/11873 [00:05<00:35, 285.51it/s]\u001b[A\n"," 15% 1748/11873 [00:05<00:35, 283.37it/s]\u001b[A\n"," 15% 1777/11873 [00:05<00:35, 282.86it/s]\u001b[A\n"," 15% 1806/11873 [00:05<00:35, 281.96it/s]\u001b[A\n"," 15% 1835/11873 [00:05<00:35, 279.70it/s]\u001b[A\n"," 16% 1864/11873 [00:05<00:35, 282.49it/s]\u001b[A\n"," 16% 1893/11873 [00:06<00:35, 279.11it/s]\u001b[A\n"," 16% 1923/11873 [00:06<00:35, 282.55it/s]\u001b[A\n"," 16% 1953/11873 [00:06<00:34, 285.08it/s]\u001b[A\n"," 17% 1982/11873 [00:06<00:34, 285.70it/s]\u001b[A\n"," 17% 2011/11873 [00:06<00:34, 283.00it/s]\u001b[A\n"," 17% 2041/11873 [00:06<00:34, 285.15it/s]\u001b[A\n"," 17% 2070/11873 [00:06<00:34, 285.42it/s]\u001b[A\n"," 18% 2099/11873 [00:06<00:34, 284.20it/s]\u001b[A\n"," 18% 2128/11873 [00:06<00:34, 283.52it/s]\u001b[A\n"," 18% 2157/11873 [00:06<00:34, 283.92it/s]\u001b[A\n"," 18% 2186/11873 [00:07<00:34, 283.67it/s]\u001b[A\n"," 19% 2216/11873 [00:07<00:33, 286.50it/s]\u001b[A\n"," 19% 2245/11873 [00:07<00:33, 287.27it/s]\u001b[A\n"," 19% 2274/11873 [00:07<00:33, 287.14it/s]\u001b[A\n"," 19% 2303/11873 [00:07<00:33, 287.23it/s]\u001b[A\n"," 20% 2332/11873 [00:07<00:33, 286.74it/s]\u001b[A\n"," 20% 2362/11873 [00:07<00:32, 289.59it/s]\u001b[A\n"," 20% 2391/11873 [00:07<00:32, 289.23it/s]\u001b[A\n"," 20% 2420/11873 [00:07<00:32, 286.70it/s]\u001b[A\n"," 21% 2449/11873 [00:07<00:32, 286.44it/s]\u001b[A\n"," 21% 2479/11873 [00:08<00:32, 287.66it/s]\u001b[A\n"," 21% 2508/11873 [00:08<00:32, 287.16it/s]\u001b[A\n"," 21% 2538/11873 [00:08<00:32, 289.26it/s]\u001b[A\n"," 22% 2568/11873 [00:08<00:32, 289.53it/s]\u001b[A\n"," 22% 2597/11873 [00:08<00:32, 287.02it/s]\u001b[A\n"," 22% 2626/11873 [00:08<00:32, 287.81it/s]\u001b[A\n"," 22% 2655/11873 [00:08<00:32, 285.69it/s]\u001b[A\n"," 23% 2685/11873 [00:08<00:31, 287.25it/s]\u001b[A\n"," 23% 2714/11873 [00:08<00:31, 287.84it/s]\u001b[A\n"," 23% 2743/11873 [00:09<00:32, 284.96it/s]\u001b[A\n"," 23% 2772/11873 [00:09<00:32, 283.38it/s]\u001b[A\n"," 24% 2801/11873 [00:09<00:31, 284.00it/s]\u001b[A\n"," 24% 2831/11873 [00:09<00:31, 286.19it/s]\u001b[A\n"," 24% 2861/11873 [00:09<00:31, 287.12it/s]\u001b[A\n"," 24% 2890/11873 [00:09<00:31, 283.36it/s]\u001b[A\n"," 25% 2920/11873 [00:09<00:31, 286.32it/s]\u001b[A\n"," 25% 2949/11873 [00:09<00:31, 285.33it/s]\u001b[A\n"," 25% 2979/11873 [00:09<00:30, 287.24it/s]\u001b[A\n"," 25% 3008/11873 [00:09<00:35, 249.26it/s]\u001b[A\n"," 26% 3037/11873 [00:10<00:34, 258.21it/s]\u001b[A\n"," 26% 3064/11873 [00:10<00:33, 259.58it/s]\u001b[A\n"," 26% 3091/11873 [00:10<00:33, 262.26it/s]\u001b[A\n"," 26% 3118/11873 [00:10<00:38, 226.67it/s]\u001b[A\n"," 26% 3142/11873 [00:10<00:41, 211.51it/s]\u001b[A\n"," 27% 3164/11873 [00:10<00:42, 205.68it/s]\u001b[A\n"," 27% 3192/11873 [00:10<00:38, 224.56it/s]\u001b[A\n"," 27% 3221/11873 [00:10<00:35, 241.67it/s]\u001b[A\n"," 27% 3250/11873 [00:10<00:33, 254.65it/s]\u001b[A\n"," 28% 3277/11873 [00:11<00:38, 225.87it/s]\u001b[A\n"," 28% 3301/11873 [00:11<00:48, 175.40it/s]\u001b[A\n"," 28% 3321/11873 [00:11<00:54, 155.67it/s]\u001b[A\n"," 28% 3340/11873 [00:11<00:52, 162.37it/s]\u001b[A\n"," 28% 3358/11873 [00:11<00:55, 153.72it/s]\u001b[A\n"," 28% 3378/11873 [00:11<00:51, 164.12it/s]\u001b[A\n"," 29% 3407/11873 [00:11<00:43, 194.70it/s]\u001b[A\n"," 29% 3437/11873 [00:12<00:38, 220.95it/s]\u001b[A\n"," 29% 3467/11873 [00:12<00:34, 240.36it/s]\u001b[A\n"," 29% 3494/11873 [00:12<00:33, 248.18it/s]\u001b[A\n"," 30% 3523/11873 [00:12<00:32, 259.87it/s]\u001b[A\n"," 30% 3551/11873 [00:12<00:31, 264.47it/s]\u001b[A\n"," 30% 3580/11873 [00:12<00:30, 270.40it/s]\u001b[A\n"," 30% 3609/11873 [00:12<00:30, 274.94it/s]\u001b[A\n"," 31% 3638/11873 [00:12<00:29, 277.97it/s]\u001b[A\n"," 31% 3667/11873 [00:12<00:29, 279.39it/s]\u001b[A\n"," 31% 3696/11873 [00:13<00:29, 277.15it/s]\u001b[A\n"," 31% 3724/11873 [00:13<00:29, 277.59it/s]\u001b[A\n"," 32% 3753/11873 [00:13<00:28, 281.04it/s]\u001b[A\n"," 32% 3782/11873 [00:13<00:29, 278.80it/s]\u001b[A\n"," 32% 3811/11873 [00:13<00:28, 280.40it/s]\u001b[A\n"," 32% 3840/11873 [00:13<00:31, 257.54it/s]\u001b[A\n"," 33% 3869/11873 [00:13<00:30, 264.67it/s]\u001b[A\n"," 33% 3898/11873 [00:13<00:29, 270.87it/s]\u001b[A\n"," 33% 3926/11873 [00:13<00:31, 251.24it/s]\u001b[A\n"," 33% 3954/11873 [00:13<00:30, 257.24it/s]\u001b[A\n"," 34% 3981/11873 [00:14<00:31, 249.65it/s]\u001b[A\n"," 34% 4011/11873 [00:14<00:30, 261.30it/s]\u001b[A\n"," 34% 4041/11873 [00:14<00:29, 269.75it/s]\u001b[A\n"," 34% 4070/11873 [00:14<00:28, 275.40it/s]\u001b[A\n"," 35% 4100/11873 [00:14<00:27, 280.06it/s]\u001b[A\n"," 35% 4129/11873 [00:14<00:27, 279.57it/s]\u001b[A\n"," 35% 4158/11873 [00:14<00:30, 250.49it/s]\u001b[A\n"," 35% 4185/11873 [00:14<00:30, 254.87it/s]\u001b[A\n"," 35% 4213/11873 [00:14<00:29, 261.69it/s]\u001b[A\n"," 36% 4242/11873 [00:15<00:28, 269.05it/s]\u001b[A\n"," 36% 4272/11873 [00:15<00:27, 275.44it/s]\u001b[A\n"," 36% 4302/11873 [00:15<00:26, 281.76it/s]\u001b[A\n"," 36% 4332/11873 [00:15<00:26, 284.64it/s]\u001b[A\n"," 37% 4362/11873 [00:15<00:26, 286.74it/s]\u001b[A\n"," 37% 4391/11873 [00:15<00:26, 285.47it/s]\u001b[A\n"," 37% 4420/11873 [00:15<00:31, 236.38it/s]\u001b[A\n"," 37% 4446/11873 [00:15<00:32, 230.67it/s]\u001b[A\n"," 38% 4476/11873 [00:15<00:29, 247.48it/s]\u001b[A\n"," 38% 4505/11873 [00:16<00:28, 257.83it/s]\u001b[A\n"," 38% 4533/11873 [00:16<00:28, 260.50it/s]\u001b[A\n"," 38% 4562/11873 [00:16<00:27, 268.18it/s]\u001b[A\n"," 39% 4592/11873 [00:16<00:26, 274.80it/s]\u001b[A\n"," 39% 4620/11873 [00:16<00:26, 272.17it/s]\u001b[A\n"," 39% 4649/11873 [00:16<00:26, 276.16it/s]\u001b[A\n"," 39% 4677/11873 [00:16<00:26, 275.02it/s]\u001b[A\n"," 40% 4706/11873 [00:16<00:25, 277.36it/s]\u001b[A\n"," 40% 4735/11873 [00:16<00:25, 278.26it/s]\u001b[A\n"," 40% 4764/11873 [00:16<00:25, 280.70it/s]\u001b[A\n"," 40% 4793/11873 [00:17<00:26, 271.39it/s]\u001b[A\n"," 41% 4822/11873 [00:17<00:25, 274.78it/s]\u001b[A\n"," 41% 4851/11873 [00:17<00:25, 278.31it/s]\u001b[A\n"," 41% 4879/11873 [00:17<00:25, 278.70it/s]\u001b[A\n"," 41% 4908/11873 [00:17<00:24, 280.28it/s]\u001b[A\n"," 42% 4937/11873 [00:17<00:24, 279.55it/s]\u001b[A\n"," 42% 4966/11873 [00:17<00:24, 280.58it/s]\u001b[A\n"," 42% 4995/11873 [00:17<00:24, 280.55it/s]\u001b[A\n"," 42% 5024/11873 [00:17<00:24, 279.21it/s]\u001b[A\n"," 43% 5052/11873 [00:18<00:24, 279.26it/s]\u001b[A\n"," 43% 5082/11873 [00:18<00:23, 283.82it/s]\u001b[A\n"," 43% 5112/11873 [00:18<00:23, 286.27it/s]\u001b[A\n"," 43% 5141/11873 [00:18<00:23, 285.72it/s]\u001b[A\n"," 44% 5170/11873 [00:18<00:23, 282.53it/s]\u001b[A\n"," 44% 5200/11873 [00:18<00:23, 285.01it/s]\u001b[A\n"," 44% 5229/11873 [00:18<00:23, 283.49it/s]\u001b[A\n"," 44% 5258/11873 [00:18<00:24, 266.01it/s]\u001b[A\n"," 45% 5285/11873 [00:18<00:25, 263.27it/s]\u001b[A\n"," 45% 5315/11873 [00:18<00:24, 271.73it/s]\u001b[A\n"," 45% 5345/11873 [00:19<00:23, 278.20it/s]\u001b[A\n"," 45% 5375/11873 [00:19<00:23, 282.13it/s]\u001b[A\n"," 46% 5405/11873 [00:19<00:22, 286.30it/s]\u001b[A\n"," 46% 5434/11873 [00:19<00:22, 285.38it/s]\u001b[A\n"," 46% 5463/11873 [00:19<00:22, 283.73it/s]\u001b[A\n"," 46% 5492/11873 [00:19<00:22, 284.70it/s]\u001b[A\n"," 47% 5522/11873 [00:19<00:22, 287.41it/s]\u001b[A\n"," 47% 5551/11873 [00:19<00:22, 286.25it/s]\u001b[A\n"," 47% 5580/11873 [00:19<00:22, 284.45it/s]\u001b[A\n"," 47% 5609/11873 [00:20<00:22, 283.51it/s]\u001b[A\n"," 47% 5638/11873 [00:20<00:22, 281.26it/s]\u001b[A\n"," 48% 5667/11873 [00:20<00:21, 282.67it/s]\u001b[A\n"," 48% 5696/11873 [00:20<00:21, 281.41it/s]\u001b[A\n"," 48% 5725/11873 [00:20<00:21, 282.84it/s]\u001b[A\n"," 48% 5754/11873 [00:20<00:21, 282.76it/s]\u001b[A\n"," 49% 5783/11873 [00:20<00:21, 280.81it/s]\u001b[A\n"," 49% 5813/11873 [00:20<00:21, 285.26it/s]\u001b[A\n"," 49% 5843/11873 [00:20<00:20, 287.66it/s]\u001b[A\n"," 49% 5872/11873 [00:20<00:20, 286.94it/s]\u001b[A\n"," 50% 5901/11873 [00:21<00:20, 286.49it/s]\u001b[A\n"," 50% 5931/11873 [00:21<00:20, 287.65it/s]\u001b[A\n"," 50% 5960/11873 [00:21<00:20, 288.34it/s]\u001b[A\n"," 50% 5989/11873 [00:21<00:20, 286.31it/s]\u001b[A\n"," 51% 6018/11873 [00:21<00:20, 285.63it/s]\u001b[A\n"," 51% 6047/11873 [00:21<00:20, 285.96it/s]\u001b[A\n"," 51% 6076/11873 [00:21<00:20, 283.96it/s]\u001b[A\n"," 51% 6105/11873 [00:21<00:20, 278.13it/s]\u001b[A\n"," 52% 6134/11873 [00:21<00:20, 280.59it/s]\u001b[A\n"," 52% 6163/11873 [00:21<00:20, 278.45it/s]\u001b[A\n"," 52% 6193/11873 [00:22<00:20, 282.65it/s]\u001b[A\n"," 52% 6222/11873 [00:22<00:20, 281.20it/s]\u001b[A\n"," 53% 6252/11873 [00:22<00:19, 283.93it/s]\u001b[A\n"," 53% 6281/11873 [00:22<00:19, 284.68it/s]\u001b[A\n"," 53% 6310/11873 [00:22<00:19, 283.20it/s]\u001b[A\n"," 53% 6340/11873 [00:22<00:19, 286.24it/s]\u001b[A\n"," 54% 6369/11873 [00:22<00:19, 287.15it/s]\u001b[A\n"," 54% 6398/11873 [00:22<00:19, 286.49it/s]\u001b[A\n"," 54% 6427/11873 [00:22<00:19, 284.31it/s]\u001b[A\n"," 54% 6456/11873 [00:22<00:19, 281.06it/s]\u001b[A\n"," 55% 6485/11873 [00:23<00:19, 283.46it/s]\u001b[A\n"," 55% 6514/11873 [00:23<00:18, 284.02it/s]\u001b[A\n"," 55% 6543/11873 [00:23<00:18, 285.67it/s]\u001b[A\n"," 55% 6573/11873 [00:23<00:18, 287.48it/s]\u001b[A\n"," 56% 6602/11873 [00:23<00:18, 287.80it/s]\u001b[A\n"," 56% 6631/11873 [00:23<00:18, 286.51it/s]\u001b[A\n"," 56% 6661/11873 [00:23<00:18, 288.12it/s]\u001b[A\n"," 56% 6691/11873 [00:23<00:17, 289.26it/s]\u001b[A\n"," 57% 6720/11873 [00:23<00:20, 252.44it/s]\u001b[A\n"," 57% 6750/11873 [00:24<00:19, 264.36it/s]\u001b[A\n"," 57% 6779/11873 [00:24<00:18, 270.19it/s]\u001b[A\n"," 57% 6808/11873 [00:24<00:18, 275.09it/s]\u001b[A\n"," 58% 6837/11873 [00:24<00:18, 279.15it/s]\u001b[A\n"," 58% 6866/11873 [00:24<00:17, 281.51it/s]\u001b[A\n"," 58% 6895/11873 [00:24<00:17, 283.22it/s]\u001b[A\n"," 58% 6924/11873 [00:24<00:17, 282.63it/s]\u001b[A\n"," 59% 6954/11873 [00:24<00:17, 286.82it/s]\u001b[A\n"," 59% 6983/11873 [00:24<00:17, 287.48it/s]\u001b[A\n"," 59% 7012/11873 [00:24<00:16, 287.89it/s]\u001b[A\n"," 59% 7041/11873 [00:25<00:16, 286.37it/s]\u001b[A\n"," 60% 7070/11873 [00:25<00:16, 284.65it/s]\u001b[A\n"," 60% 7099/11873 [00:25<00:16, 284.72it/s]\u001b[A\n"," 60% 7128/11873 [00:25<00:16, 284.92it/s]\u001b[A\n"," 60% 7157/11873 [00:25<00:16, 285.96it/s]\u001b[A\n"," 61% 7186/11873 [00:25<00:16, 283.75it/s]\u001b[A\n"," 61% 7215/11873 [00:25<00:16, 280.32it/s]\u001b[A\n"," 61% 7244/11873 [00:25<00:16, 282.98it/s]\u001b[A\n"," 61% 7273/11873 [00:25<00:16, 281.92it/s]\u001b[A\n"," 62% 7302/11873 [00:25<00:16, 282.12it/s]\u001b[A\n"," 62% 7331/11873 [00:26<00:16, 281.26it/s]\u001b[A\n"," 62% 7360/11873 [00:26<00:16, 280.97it/s]\u001b[A\n"," 62% 7389/11873 [00:26<00:15, 282.44it/s]\u001b[A\n"," 62% 7418/11873 [00:26<00:16, 266.03it/s]\u001b[A\n"," 63% 7445/11873 [00:26<00:16, 265.12it/s]\u001b[A\n"," 63% 7474/11873 [00:26<00:16, 272.06it/s]\u001b[A\n"," 63% 7503/11873 [00:26<00:15, 276.99it/s]\u001b[A\n"," 63% 7532/11873 [00:26<00:15, 279.55it/s]\u001b[A\n"," 64% 7562/11873 [00:26<00:15, 283.42it/s]\u001b[A\n"," 64% 7591/11873 [00:27<00:15, 283.65it/s]\u001b[A\n"," 64% 7620/11873 [00:27<00:15, 280.22it/s]\u001b[A\n"," 64% 7649/11873 [00:27<00:15, 279.48it/s]\u001b[A\n"," 65% 7678/11873 [00:27<00:14, 280.65it/s]\u001b[A\n"," 65% 7707/11873 [00:27<00:16, 257.93it/s]\u001b[A\n"," 65% 7735/11873 [00:27<00:15, 262.44it/s]\u001b[A\n"," 65% 7763/11873 [00:27<00:15, 265.80it/s]\u001b[A\n"," 66% 7792/11873 [00:27<00:15, 270.33it/s]\u001b[A\n"," 66% 7821/11873 [00:27<00:14, 274.52it/s]\u001b[A\n"," 66% 7849/11873 [00:27<00:14, 271.48it/s]\u001b[A\n"," 66% 7877/11873 [00:28<00:15, 253.33it/s]\u001b[A\n"," 67% 7906/11873 [00:28<00:15, 263.39it/s]\u001b[A\n"," 67% 7936/11873 [00:28<00:14, 273.03it/s]\u001b[A\n"," 67% 7964/11873 [00:28<00:14, 274.73it/s]\u001b[A\n"," 67% 7993/11873 [00:28<00:13, 278.43it/s]\u001b[A\n"," 68% 8022/11873 [00:28<00:13, 279.23it/s]\u001b[A\n"," 68% 8051/11873 [00:28<00:13, 279.86it/s]\u001b[A\n"," 68% 8081/11873 [00:28<00:13, 283.09it/s]\u001b[A\n"," 68% 8110/11873 [00:28<00:13, 280.33it/s]\u001b[A\n"," 69% 8139/11873 [00:29<00:13, 275.10it/s]\u001b[A\n"," 69% 8168/11873 [00:29<00:13, 277.78it/s]\u001b[A\n"," 69% 8196/11873 [00:29<00:13, 277.79it/s]\u001b[A\n"," 69% 8224/11873 [00:29<00:13, 278.10it/s]\u001b[A\n"," 70% 8253/11873 [00:29<00:12, 281.48it/s]\u001b[A\n"," 70% 8282/11873 [00:29<00:12, 280.92it/s]\u001b[A\n"," 70% 8311/11873 [00:29<00:12, 282.02it/s]\u001b[A\n"," 70% 8340/11873 [00:29<00:12, 283.27it/s]\u001b[A\n"," 70% 8369/11873 [00:29<00:12, 283.54it/s]\u001b[A\n"," 71% 8398/11873 [00:29<00:12, 284.18it/s]\u001b[A\n"," 71% 8427/11873 [00:30<00:12, 277.73it/s]\u001b[A\n"," 71% 8455/11873 [00:30<00:12, 276.11it/s]\u001b[A\n"," 71% 8483/11873 [00:30<00:12, 276.69it/s]\u001b[A\n"," 72% 8513/11873 [00:30<00:11, 281.66it/s]\u001b[A\n"," 72% 8542/11873 [00:30<00:11, 279.51it/s]\u001b[A\n"," 72% 8571/11873 [00:30<00:11, 281.78it/s]\u001b[A\n"," 72% 8600/11873 [00:30<00:11, 283.17it/s]\u001b[A\n"," 73% 8629/11873 [00:30<00:11, 278.61it/s]\u001b[A\n"," 73% 8659/11873 [00:30<00:11, 282.17it/s]\u001b[A\n"," 73% 8688/11873 [00:31<00:11, 280.38it/s]\u001b[A\n"," 73% 8717/11873 [00:31<00:11, 282.24it/s]\u001b[A\n"," 74% 8747/11873 [00:31<00:10, 286.59it/s]\u001b[A\n"," 74% 8776/11873 [00:31<00:10, 285.69it/s]\u001b[A\n"," 74% 8805/11873 [00:31<00:10, 283.22it/s]\u001b[A\n"," 74% 8834/11873 [00:31<00:10, 284.48it/s]\u001b[A\n"," 75% 8863/11873 [00:31<00:10, 284.60it/s]\u001b[A\n"," 75% 8892/11873 [00:31<00:10, 284.23it/s]\u001b[A\n"," 75% 8921/11873 [00:31<00:10, 284.39it/s]\u001b[A\n"," 75% 8950/11873 [00:31<00:10, 284.02it/s]\u001b[A\n"," 76% 8980/11873 [00:32<00:10, 287.25it/s]\u001b[A\n"," 76% 9009/11873 [00:32<00:09, 287.06it/s]\u001b[A\n"," 76% 9038/11873 [00:32<00:09, 285.05it/s]\u001b[A\n"," 76% 9067/11873 [00:32<00:09, 284.20it/s]\u001b[A\n"," 77% 9096/11873 [00:32<00:09, 282.51it/s]\u001b[A\n"," 77% 9125/11873 [00:32<00:09, 283.52it/s]\u001b[A\n"," 77% 9154/11873 [00:32<00:09, 285.29it/s]\u001b[A\n"," 77% 9183/11873 [00:32<00:09, 285.05it/s]\u001b[A\n"," 78% 9212/11873 [00:32<00:09, 286.44it/s]\u001b[A\n"," 78% 9241/11873 [00:32<00:09, 286.38it/s]\u001b[A\n"," 78% 9270/11873 [00:33<00:09, 285.39it/s]\u001b[A\n"," 78% 9299/11873 [00:33<00:09, 283.87it/s]\u001b[A\n"," 79% 9328/11873 [00:33<00:09, 281.60it/s]\u001b[A\n"," 79% 9357/11873 [00:33<00:08, 282.78it/s]\u001b[A\n"," 79% 9386/11873 [00:33<00:08, 284.00it/s]\u001b[A\n"," 79% 9415/11873 [00:33<00:08, 283.60it/s]\u001b[A\n"," 80% 9444/11873 [00:33<00:08, 283.87it/s]\u001b[A\n"," 80% 9473/11873 [00:33<00:08, 283.65it/s]\u001b[A\n"," 80% 9503/11873 [00:33<00:08, 286.39it/s]\u001b[A\n"," 80% 9532/11873 [00:33<00:08, 286.87it/s]\u001b[A\n"," 81% 9561/11873 [00:34<00:08, 280.81it/s]\u001b[A\n"," 81% 9590/11873 [00:34<00:08, 283.23it/s]\u001b[A\n"," 81% 9619/11873 [00:34<00:07, 283.99it/s]\u001b[A\n"," 81% 9648/11873 [00:34<00:07, 284.06it/s]\u001b[A\n"," 82% 9677/11873 [00:34<00:07, 284.10it/s]\u001b[A\n"," 82% 9708/11873 [00:34<00:07, 288.91it/s]\u001b[A\n"," 82% 9737/11873 [00:34<00:07, 288.41it/s]\u001b[A\n"," 82% 9767/11873 [00:34<00:07, 289.85it/s]\u001b[A\n"," 83% 9796/11873 [00:34<00:07, 288.16it/s]\u001b[A\n"," 83% 9825/11873 [00:34<00:07, 285.62it/s]\u001b[A\n"," 83% 9855/11873 [00:35<00:07, 288.11it/s]\u001b[A\n"," 83% 9884/11873 [00:35<00:06, 286.80it/s]\u001b[A\n"," 83% 9913/11873 [00:35<00:06, 285.55it/s]\u001b[A\n"," 84% 9943/11873 [00:35<00:06, 287.73it/s]\u001b[A\n"," 84% 9973/11873 [00:35<00:06, 289.02it/s]\u001b[A\n"," 84% 10002/11873 [00:35<00:06, 286.32it/s]\u001b[A\n"," 84% 10032/11873 [00:35<00:06, 287.67it/s]\u001b[A\n"," 85% 10062/11873 [00:35<00:06, 290.68it/s]\u001b[A\n"," 85% 10092/11873 [00:35<00:06, 290.62it/s]\u001b[A\n"," 85% 10122/11873 [00:36<00:06, 290.23it/s]\u001b[A\n"," 86% 10152/11873 [00:36<00:05, 289.38it/s]\u001b[A\n"," 86% 10181/11873 [00:36<00:05, 287.99it/s]\u001b[A\n"," 86% 10210/11873 [00:36<00:05, 287.25it/s]\u001b[A\n"," 86% 10239/11873 [00:36<00:05, 287.68it/s]\u001b[A\n"," 86% 10268/11873 [00:36<00:08, 180.75it/s]\u001b[A\n"," 87% 10296/11873 [00:36<00:07, 200.51it/s]\u001b[A\n"," 87% 10324/11873 [00:36<00:07, 217.87it/s]\u001b[A\n"," 87% 10353/11873 [00:37<00:06, 234.75it/s]\u001b[A\n"," 87% 10382/11873 [00:37<00:06, 248.05it/s]\u001b[A\n"," 88% 10411/11873 [00:37<00:05, 257.18it/s]\u001b[A\n"," 88% 10439/11873 [00:37<00:05, 239.92it/s]\u001b[A\n"," 88% 10469/11873 [00:37<00:05, 253.93it/s]\u001b[A\n"," 88% 10497/11873 [00:37<00:05, 260.84it/s]\u001b[A\n"," 89% 10525/11873 [00:37<00:05, 265.02it/s]\u001b[A\n"," 89% 10553/11873 [00:37<00:05, 251.39it/s]\u001b[A\n"," 89% 10581/11873 [00:37<00:04, 259.16it/s]\u001b[A\n"," 89% 10610/11873 [00:38<00:04, 266.65it/s]\u001b[A\n"," 90% 10638/11873 [00:38<00:04, 267.57it/s]\u001b[A\n"," 90% 10666/11873 [00:38<00:04, 269.22it/s]\u001b[A\n"," 90% 10695/11873 [00:38<00:04, 273.54it/s]\u001b[A\n"," 90% 10723/11873 [00:38<00:04, 272.82it/s]\u001b[A\n"," 91% 10751/11873 [00:38<00:04, 274.62it/s]\u001b[A\n"," 91% 10780/11873 [00:38<00:03, 277.01it/s]\u001b[A\n"," 91% 10808/11873 [00:38<00:03, 277.70it/s]\u001b[A\n"," 91% 10836/11873 [00:38<00:04, 253.68it/s]\u001b[A\n"," 92% 10865/11873 [00:38<00:03, 261.53it/s]\u001b[A\n"," 92% 10893/11873 [00:39<00:03, 266.69it/s]\u001b[A\n"," 92% 10921/11873 [00:39<00:03, 269.17it/s]\u001b[A\n"," 92% 10949/11873 [00:39<00:03, 270.66it/s]\u001b[A\n"," 92% 10978/11873 [00:39<00:03, 276.09it/s]\u001b[A\n"," 93% 11008/11873 [00:39<00:03, 280.05it/s]\u001b[A\n"," 93% 11037/11873 [00:39<00:02, 281.54it/s]\u001b[A\n"," 93% 11066/11873 [00:39<00:02, 283.01it/s]\u001b[A\n"," 93% 11095/11873 [00:39<00:02, 284.49it/s]\u001b[A\n"," 94% 11124/11873 [00:39<00:02, 283.27it/s]\u001b[A\n"," 94% 11154/11873 [00:39<00:02, 285.81it/s]\u001b[A\n"," 94% 11184/11873 [00:40<00:02, 287.27it/s]\u001b[A\n"," 94% 11213/11873 [00:40<00:02, 285.89it/s]\u001b[A\n"," 95% 11242/11873 [00:40<00:02, 284.13it/s]\u001b[A\n"," 95% 11271/11873 [00:40<00:02, 281.41it/s]\u001b[A\n"," 95% 11301/11873 [00:40<00:02, 283.92it/s]\u001b[A\n"," 95% 11331/11873 [00:40<00:01, 286.76it/s]\u001b[A\n"," 96% 11360/11873 [00:40<00:01, 285.29it/s]\u001b[A\n"," 96% 11389/11873 [00:40<00:01, 286.29it/s]\u001b[A\n"," 96% 11418/11873 [00:40<00:01, 285.51it/s]\u001b[A\n"," 96% 11447/11873 [00:40<00:01, 286.11it/s]\u001b[A\n"," 97% 11476/11873 [00:41<00:01, 286.16it/s]\u001b[A\n"," 97% 11505/11873 [00:41<00:01, 284.86it/s]\u001b[A\n"," 97% 11534/11873 [00:41<00:01, 284.55it/s]\u001b[A\n"," 97% 11563/11873 [00:41<00:01, 282.04it/s]\u001b[A\n"," 98% 11593/11873 [00:41<00:00, 285.02it/s]\u001b[A\n"," 98% 11622/11873 [00:41<00:00, 283.88it/s]\u001b[A\n"," 98% 11651/11873 [00:41<00:00, 283.32it/s]\u001b[A\n"," 98% 11680/11873 [00:41<00:00, 280.60it/s]\u001b[A\n"," 99% 11709/11873 [00:41<00:00, 280.76it/s]\u001b[A\n"," 99% 11738/11873 [00:42<00:00, 282.16it/s]\u001b[A\n"," 99% 11767/11873 [00:42<00:00, 284.42it/s]\u001b[A\n"," 99% 11796/11873 [00:42<00:00, 285.87it/s]\u001b[A\n","100% 11825/11873 [00:42<00:00, 285.28it/s]\u001b[A\n","100% 11873/11873 [00:42<00:00, 279.30it/s]\n","04/07/2022 10:33:39 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/eval_predictions.json.\n","04/07/2022 10:33:39 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/eval_nbest_predictions.json.\n","04/07/2022 10:33:42 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/QA/model_results/bert-base-case/back-trans-synonym-possible-aug/eval_null_odds.json.\n","04/07/2022 10:33:46 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n","100% 1525/1525 [04:04<00:00,  6.23it/s]\n","***** eval metrics *****\n","  epoch                  =     3.0\n","  eval_HasAns_exact      = 72.4359\n","  eval_HasAns_f1         = 79.0347\n","  eval_HasAns_total      =    5928\n","  eval_NoAns_exact       = 62.5399\n","  eval_NoAns_f1          = 62.5399\n","  eval_NoAns_total       =    5945\n","  eval_best_exact        = 67.4808\n","  eval_best_exact_thresh =     0.0\n","  eval_best_f1           = 70.7755\n","  eval_best_f1_thresh    =     0.0\n","  eval_exact             = 67.4808\n","  eval_f1                = 70.7755\n","  eval_samples           =   12199\n","  eval_total             =   11873\n","[INFO|modelcard.py:460] 2022-04-07 10:33:46,565 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'sichenzhong/squad_v2_back_trans_synonym_possib_aug', 'type': 'sichenzhong/squad_v2_back_trans_synonym_possib_aug', 'args': 'squad_v2'}}\n"]}]},{"cell_type":"code","source":["!python run_qa.py \\\n","  --model_name_or_path albert-base-v2 \\\n","  --dataset_name sichenzhong/squad_v2_back_trans_synonym_possib_aug \\\n","  --do_train \\\n","  --do_eval \\\n","  --per_device_train_batch_size 16 \\\n","  --learning_rate 2e-5 \\\n","  --num_train_epochs 2 \\\n","  --max_seq_length 512 \\\n","  --doc_stride 128 \\\n","  --version_2_with_negative \\\n","  --output_dir /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YC1SX-FRTOxk","executionInfo":{"status":"ok","timestamp":1649343119003,"user_tz":240,"elapsed":15487460,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"6b49fe6e-50f5-47b2-a513-58e3bf572819"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["04/07/2022 10:33:59 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","04/07/2022 10:33:59 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.NO,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=2e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/runs/Apr07_10-33-59_1877836f64d8,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=2.0,\n","optim=OptimizerNames.ADAMW_HF,\n","output_dir=/content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=16,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","04/07/2022 10:34:01 - WARNING - datasets.builder - Using custom data configuration sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a\n","04/07/2022 10:34:01 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n","04/07/2022 10:34:01 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901\n","04/07/2022 10:34:01 - WARNING - datasets.builder - Reusing dataset parquet (/root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n","04/07/2022 10:34:01 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901\n","100% 2/2 [00:00<00:00, 16.30it/s]\n","[INFO|hub.py:583] 2022-04-07 10:34:01,844 >> https://huggingface.co/albert-base-v2/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpyob6fcd1\n","Downloading: 100% 684/684 [00:00<00:00, 580kB/s]\n","[INFO|hub.py:587] 2022-04-07 10:34:02,197 >> storing https://huggingface.co/albert-base-v2/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|hub.py:595] 2022-04-07 10:34:02,198 >> creating metadata file for /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|configuration_utils.py:654] 2022-04-07 10:34:02,198 >> loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|configuration_utils.py:690] 2022-04-07 10:34:02,201 >> Model config AlbertConfig {\n","  \"_name_or_path\": \"albert-base-v2\",\n","  \"architectures\": [\n","    \"AlbertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","[INFO|tokenization_auto.py:344] 2022-04-07 10:34:02,559 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n","[INFO|configuration_utils.py:654] 2022-04-07 10:34:02,910 >> loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|configuration_utils.py:690] 2022-04-07 10:34:02,911 >> Model config AlbertConfig {\n","  \"_name_or_path\": \"albert-base-v2\",\n","  \"architectures\": [\n","    \"AlbertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","[INFO|hub.py:583] 2022-04-07 10:34:03,625 >> https://huggingface.co/albert-base-v2/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2gcmw2ms\n","Downloading: 100% 742k/742k [00:00<00:00, 1.84MB/s]\n","[INFO|hub.py:587] 2022-04-07 10:34:04,413 >> storing https://huggingface.co/albert-base-v2/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/10be6ce6d3508f1fdce98a57a574283b47c055228c1235f8686f039287ff8174.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d\n","[INFO|hub.py:595] 2022-04-07 10:34:04,413 >> creating metadata file for /root/.cache/huggingface/transformers/10be6ce6d3508f1fdce98a57a574283b47c055228c1235f8686f039287ff8174.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d\n","[INFO|hub.py:583] 2022-04-07 10:34:04,780 >> https://huggingface.co/albert-base-v2/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmphjfdsw5z\n","Downloading: 100% 1.25M/1.25M [00:00<00:00, 2.65MB/s]\n","[INFO|hub.py:587] 2022-04-07 10:34:05,675 >> storing https://huggingface.co/albert-base-v2/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/828a43aa4b9d07e2b7d3be7c6bc10a3ae6e16e8d9c3a0c557783639de9eaeb1b.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74\n","[INFO|hub.py:595] 2022-04-07 10:34:05,675 >> creating metadata file for /root/.cache/huggingface/transformers/828a43aa4b9d07e2b7d3be7c6bc10a3ae6e16e8d9c3a0c557783639de9eaeb1b.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 10:34:06,742 >> loading file https://huggingface.co/albert-base-v2/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/10be6ce6d3508f1fdce98a57a574283b47c055228c1235f8686f039287ff8174.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 10:34:06,743 >> loading file https://huggingface.co/albert-base-v2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/828a43aa4b9d07e2b7d3be7c6bc10a3ae6e16e8d9c3a0c557783639de9eaeb1b.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 10:34:06,743 >> loading file https://huggingface.co/albert-base-v2/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 10:34:06,743 >> loading file https://huggingface.co/albert-base-v2/resolve/main/special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 10:34:06,743 >> loading file https://huggingface.co/albert-base-v2/resolve/main/tokenizer_config.json from cache at None\n","[INFO|configuration_utils.py:654] 2022-04-07 10:34:07,093 >> loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|configuration_utils.py:690] 2022-04-07 10:34:07,094 >> Model config AlbertConfig {\n","  \"_name_or_path\": \"albert-base-v2\",\n","  \"architectures\": [\n","    \"AlbertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","[INFO|hub.py:583] 2022-04-07 10:34:07,618 >> https://huggingface.co/albert-base-v2/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpd52wjxha\n","Downloading: 100% 45.2M/45.2M [00:00<00:00, 47.5MB/s]\n","[INFO|hub.py:587] 2022-04-07 10:34:09,006 >> storing https://huggingface.co/albert-base-v2/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/bf1986d976e9a8320cbd3a0597e610bf299d639ce31b7ca581cbf54be3aaa6d3.d6d54047dfe6ae844e3bf6e7a7d0aff71cb598d3df019361e076ba7639b1da9b\n","[INFO|hub.py:595] 2022-04-07 10:34:09,006 >> creating metadata file for /root/.cache/huggingface/transformers/bf1986d976e9a8320cbd3a0597e610bf299d639ce31b7ca581cbf54be3aaa6d3.d6d54047dfe6ae844e3bf6e7a7d0aff71cb598d3df019361e076ba7639b1da9b\n","[INFO|modeling_utils.py:1772] 2022-04-07 10:34:09,006 >> loading weights file https://huggingface.co/albert-base-v2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/bf1986d976e9a8320cbd3a0597e610bf299d639ce31b7ca581cbf54be3aaa6d3.d6d54047dfe6ae844e3bf6e7a7d0aff71cb598d3df019361e076ba7639b1da9b\n","[WARNING|modeling_utils.py:2049] 2022-04-07 10:34:09,145 >> Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForQuestionAnswering: ['predictions.LayerNorm.weight', 'predictions.decoder.weight', 'predictions.decoder.bias', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.dense.weight']\n","- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:2060] 2022-04-07 10:34:09,145 >> Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Running tokenizer on train dataset:   0% 0/131 [00:00<?, ?ba/s]04/07/2022 10:34:09 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-48f1eebd477d5027.arrow\n","Running tokenizer on train dataset: 100% 131/131 [01:08<00:00,  1.90ba/s]\n","Running tokenizer on validation dataset:   0% 0/12 [00:00<?, ?ba/s]04/07/2022 10:35:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-f9530e8a3852af76.arrow\n","Running tokenizer on validation dataset: 100% 12/12 [01:29<00:00,  7.46s/ba]\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","[INFO|trainer.py:1290] 2022-04-07 10:36:52,279 >> ***** Running training *****\n","[INFO|trainer.py:1291] 2022-04-07 10:36:52,279 >>   Num examples = 130551\n","[INFO|trainer.py:1292] 2022-04-07 10:36:52,279 >>   Num Epochs = 2\n","[INFO|trainer.py:1293] 2022-04-07 10:36:52,279 >>   Instantaneous batch size per device = 16\n","[INFO|trainer.py:1294] 2022-04-07 10:36:52,279 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:1295] 2022-04-07 10:36:52,280 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1296] 2022-04-07 10:36:52,280 >>   Total optimization steps = 16320\n","{'loss': 1.9441, 'learning_rate': 1.9387254901960785e-05, 'epoch': 0.06}\n","  3% 500/16320 [07:37<4:01:17,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 10:44:29,899 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-500\n","[INFO|configuration_utils.py:441] 2022-04-07 10:44:29,905 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 10:44:30,033 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 10:44:30,038 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 10:44:30,041 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-500/special_tokens_map.json\n","{'loss': 1.5002, 'learning_rate': 1.877450980392157e-05, 'epoch': 0.12}\n","  6% 1000/16320 [15:15<3:53:31,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 10:52:07,970 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1000\n","[INFO|configuration_utils.py:441] 2022-04-07 10:52:07,977 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 10:52:08,109 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 10:52:08,113 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 10:52:08,117 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1000/special_tokens_map.json\n","{'loss': 1.44, 'learning_rate': 1.8161764705882355e-05, 'epoch': 0.18}\n","  9% 1500/16320 [22:53<3:46:00,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 10:59:46,186 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1500\n","[INFO|configuration_utils.py:441] 2022-04-07 10:59:46,192 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 10:59:46,329 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 10:59:46,334 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 10:59:46,339 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-1500/special_tokens_map.json\n","{'loss': 1.3362, 'learning_rate': 1.7549019607843138e-05, 'epoch': 0.25}\n"," 12% 2000/16320 [30:32<3:38:18,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 11:07:24,402 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2000\n","[INFO|configuration_utils.py:441] 2022-04-07 11:07:24,408 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 11:07:24,544 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 11:07:24,549 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 11:07:24,553 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2000/special_tokens_map.json\n","{'loss': 1.3302, 'learning_rate': 1.693627450980392e-05, 'epoch': 0.31}\n"," 15% 2500/16320 [38:10<3:31:12,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 11:15:02,754 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2500\n","[INFO|configuration_utils.py:441] 2022-04-07 11:15:02,760 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 11:15:02,890 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 11:15:02,896 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 11:15:02,899 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-2500/special_tokens_map.json\n","{'loss': 1.305, 'learning_rate': 1.6323529411764708e-05, 'epoch': 0.37}\n"," 18% 3000/16320 [45:48<3:23:11,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 11:22:41,205 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3000\n","[INFO|configuration_utils.py:441] 2022-04-07 11:22:41,211 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 11:22:41,344 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 11:22:41,349 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 11:22:41,369 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3000/special_tokens_map.json\n","{'loss': 1.2387, 'learning_rate': 1.571078431372549e-05, 'epoch': 0.43}\n"," 21% 3500/16320 [53:27<3:15:49,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 11:30:19,930 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3500\n","[INFO|configuration_utils.py:441] 2022-04-07 11:30:19,937 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 11:30:20,071 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 11:30:20,076 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 11:30:20,079 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-3500/special_tokens_map.json\n","{'loss': 1.2154, 'learning_rate': 1.5098039215686276e-05, 'epoch': 0.49}\n"," 25% 4000/16320 [1:01:06<3:08:18,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 11:37:58,656 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4000\n","[INFO|configuration_utils.py:441] 2022-04-07 11:37:58,663 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 11:37:58,797 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 11:37:58,803 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 11:37:58,806 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4000/special_tokens_map.json\n","{'loss': 1.1957, 'learning_rate': 1.448529411764706e-05, 'epoch': 0.55}\n"," 28% 4500/16320 [1:08:45<3:00:08,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 11:45:37,407 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4500\n","[INFO|configuration_utils.py:441] 2022-04-07 11:45:37,413 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 11:45:37,546 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 11:45:37,566 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 11:45:37,572 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-4500/special_tokens_map.json\n","{'loss': 1.1794, 'learning_rate': 1.3872549019607844e-05, 'epoch': 0.61}\n"," 31% 5000/16320 [1:16:23<2:52:54,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 11:53:16,190 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5000\n","[INFO|configuration_utils.py:441] 2022-04-07 11:53:16,197 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 11:53:16,343 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 11:53:16,348 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 11:53:16,351 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5000/special_tokens_map.json\n","{'loss': 1.1546, 'learning_rate': 1.3259803921568627e-05, 'epoch': 0.67}\n"," 34% 5500/16320 [1:24:02<2:45:26,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 12:00:54,931 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5500\n","[INFO|configuration_utils.py:441] 2022-04-07 12:00:54,937 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 12:00:55,073 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 12:00:55,079 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 12:00:55,083 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-5500/special_tokens_map.json\n","{'loss': 1.1369, 'learning_rate': 1.2647058823529412e-05, 'epoch': 0.74}\n"," 37% 6000/16320 [1:31:41<2:37:37,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 12:08:33,586 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6000\n","[INFO|configuration_utils.py:441] 2022-04-07 12:08:33,592 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 12:08:33,726 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 12:08:33,746 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 12:08:33,751 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6000/special_tokens_map.json\n","{'loss': 1.1359, 'learning_rate': 1.2034313725490197e-05, 'epoch': 0.8}\n"," 40% 6500/16320 [1:39:19<2:29:51,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 12:16:12,290 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6500\n","[INFO|configuration_utils.py:441] 2022-04-07 12:16:12,296 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 12:16:12,429 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 12:16:12,433 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 12:16:12,437 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-6500/special_tokens_map.json\n","{'loss': 1.0987, 'learning_rate': 1.142156862745098e-05, 'epoch': 0.86}\n"," 43% 7000/16320 [1:46:58<2:22:19,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 12:23:50,733 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7000\n","[INFO|configuration_utils.py:441] 2022-04-07 12:23:50,740 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 12:23:50,870 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 12:23:50,876 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 12:23:50,880 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7000/special_tokens_map.json\n","{'loss': 1.0824, 'learning_rate': 1.0808823529411765e-05, 'epoch': 0.92}\n"," 46% 7500/16320 [1:54:37<2:14:51,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 12:31:29,383 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7500\n","[INFO|configuration_utils.py:441] 2022-04-07 12:31:29,389 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 12:31:29,520 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 12:31:29,544 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 12:31:29,548 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-7500/special_tokens_map.json\n","{'loss': 1.0942, 'learning_rate': 1.0196078431372549e-05, 'epoch': 0.98}\n"," 49% 8000/16320 [2:02:15<2:07:07,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 12:39:08,270 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8000\n","[INFO|configuration_utils.py:441] 2022-04-07 12:39:08,276 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 12:39:08,412 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 12:39:08,417 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 12:39:08,421 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8000/special_tokens_map.json\n","{'loss': 0.9467, 'learning_rate': 9.583333333333335e-06, 'epoch': 1.04}\n"," 52% 8500/16320 [2:09:54<1:59:11,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 12:46:46,481 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8500\n","[INFO|configuration_utils.py:441] 2022-04-07 12:46:46,488 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 12:46:46,618 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 12:46:46,624 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 12:46:46,628 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-8500/special_tokens_map.json\n","{'loss': 0.8655, 'learning_rate': 8.970588235294119e-06, 'epoch': 1.1}\n"," 55% 9000/16320 [2:17:32<1:51:35,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 12:54:25,240 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9000\n","[INFO|configuration_utils.py:441] 2022-04-07 12:54:25,261 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 12:54:25,401 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 12:54:25,406 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 12:54:25,409 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9000/special_tokens_map.json\n","{'loss': 0.8649, 'learning_rate': 8.357843137254903e-06, 'epoch': 1.16}\n"," 58% 9500/16320 [2:25:11<1:44:13,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 13:02:04,082 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9500\n","[INFO|configuration_utils.py:441] 2022-04-07 13:02:04,088 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 13:02:04,219 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 13:02:04,224 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 13:02:04,227 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-9500/special_tokens_map.json\n","{'loss': 0.8617, 'learning_rate': 7.745098039215687e-06, 'epoch': 1.23}\n"," 61% 10000/16320 [2:32:50<1:36:37,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 13:09:42,756 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10000\n","[INFO|configuration_utils.py:441] 2022-04-07 13:09:42,762 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 13:09:42,890 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 13:09:42,895 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 13:09:42,899 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10000/special_tokens_map.json\n","{'loss': 0.8542, 'learning_rate': 7.132352941176472e-06, 'epoch': 1.29}\n"," 64% 10500/16320 [2:40:29<1:28:51,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 13:17:21,531 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10500\n","[INFO|configuration_utils.py:441] 2022-04-07 13:17:21,537 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 13:17:21,665 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 13:17:21,670 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 13:17:21,674 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-10500/special_tokens_map.json\n","{'loss': 0.8557, 'learning_rate': 6.519607843137256e-06, 'epoch': 1.35}\n"," 67% 11000/16320 [2:48:08<1:21:13,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 13:25:00,376 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11000\n","[INFO|configuration_utils.py:441] 2022-04-07 13:25:00,382 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 13:25:00,516 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 13:25:00,522 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 13:25:00,526 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11000/special_tokens_map.json\n","{'loss': 0.8584, 'learning_rate': 5.90686274509804e-06, 'epoch': 1.41}\n"," 70% 11500/16320 [2:55:46<1:13:35,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 13:32:39,274 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11500\n","[INFO|configuration_utils.py:441] 2022-04-07 13:32:39,281 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 13:32:39,411 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 13:32:39,418 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 13:32:39,422 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-11500/special_tokens_map.json\n","{'loss': 0.8639, 'learning_rate': 5.294117647058824e-06, 'epoch': 1.47}\n"," 74% 12000/16320 [3:03:25<1:05:56,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 13:40:18,089 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12000\n","[INFO|configuration_utils.py:441] 2022-04-07 13:40:18,095 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 13:40:18,228 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 13:40:18,234 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 13:40:18,238 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12000/special_tokens_map.json\n","{'loss': 0.8508, 'learning_rate': 4.681372549019608e-06, 'epoch': 1.53}\n"," 77% 12500/16320 [3:11:04<58:16,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 13:47:56,897 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12500\n","[INFO|configuration_utils.py:441] 2022-04-07 13:47:56,903 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 13:47:57,034 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 13:47:57,039 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 13:47:57,042 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-12500/special_tokens_map.json\n","{'loss': 0.8251, 'learning_rate': 4.068627450980392e-06, 'epoch': 1.59}\n"," 80% 13000/16320 [3:18:43<50:40,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 13:55:35,691 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13000\n","[INFO|configuration_utils.py:441] 2022-04-07 13:55:35,700 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 13:55:35,837 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 13:55:35,842 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 13:55:35,846 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13000/special_tokens_map.json\n","{'loss': 0.8286, 'learning_rate': 3.4558823529411766e-06, 'epoch': 1.65}\n"," 83% 13500/16320 [3:26:22<43:05,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 14:03:14,571 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13500\n","[INFO|configuration_utils.py:441] 2022-04-07 14:03:14,577 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 14:03:14,718 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 14:03:14,723 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 14:03:14,727 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-13500/special_tokens_map.json\n","{'loss': 0.8207, 'learning_rate': 2.843137254901961e-06, 'epoch': 1.72}\n"," 86% 14000/16320 [3:34:01<35:29,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 14:10:53,509 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14000\n","[INFO|configuration_utils.py:441] 2022-04-07 14:10:53,516 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 14:10:53,651 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 14:10:53,656 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 14:10:53,660 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14000/special_tokens_map.json\n","{'loss': 0.8232, 'learning_rate': 2.2303921568627456e-06, 'epoch': 1.78}\n"," 89% 14500/16320 [3:41:39<27:44,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 14:18:32,298 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14500\n","[INFO|configuration_utils.py:441] 2022-04-07 14:18:32,303 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 14:18:32,449 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 14:18:32,454 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 14:18:32,458 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-14500/special_tokens_map.json\n","{'loss': 0.8025, 'learning_rate': 1.6176470588235297e-06, 'epoch': 1.84}\n"," 92% 15000/16320 [3:49:18<20:10,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 14:26:11,063 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15000\n","[INFO|configuration_utils.py:441] 2022-04-07 14:26:11,070 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 14:26:11,203 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 14:26:11,209 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 14:26:11,213 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15000/special_tokens_map.json\n","{'loss': 0.8042, 'learning_rate': 1.0049019607843138e-06, 'epoch': 1.9}\n"," 95% 15500/16320 [3:56:57<12:31,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 14:33:49,899 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15500\n","[INFO|configuration_utils.py:441] 2022-04-07 14:33:49,905 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 14:33:50,038 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 14:33:50,061 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 14:33:50,067 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-15500/special_tokens_map.json\n","{'loss': 0.8045, 'learning_rate': 3.921568627450981e-07, 'epoch': 1.96}\n"," 98% 16000/16320 [4:04:36<04:53,  1.09it/s][INFO|trainer.py:2166] 2022-04-07 14:41:28,637 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-16000\n","[INFO|configuration_utils.py:441] 2022-04-07 14:41:28,644 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-16000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 14:41:28,776 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-16000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 14:41:28,782 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-16000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 14:41:28,787 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/checkpoint-16000/special_tokens_map.json\n","100% 16320/16320 [4:09:29<00:00,  1.30it/s][INFO|trainer.py:1530] 2022-04-07 14:46:21,986 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 14969.7067, 'train_samples_per_second': 17.442, 'train_steps_per_second': 1.09, 'train_loss': 1.0550937465592927, 'epoch': 2.0}\n","100% 16320/16320 [4:09:29<00:00,  1.09it/s]\n","[INFO|trainer.py:2166] 2022-04-07 14:46:21,991 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug\n","[INFO|configuration_utils.py:441] 2022-04-07 14:46:21,997 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 14:46:22,128 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 14:46:22,133 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 14:46:22,136 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =        2.0\n","  train_loss               =     1.0551\n","  train_runtime            = 4:09:29.70\n","  train_samples            =     130551\n","  train_samples_per_second =     17.442\n","  train_steps_per_second   =       1.09\n","04/07/2022 14:46:22 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:567] 2022-04-07 14:46:22,168 >> The following columns in the evaluation set  don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:2416] 2022-04-07 14:46:22,171 >> ***** Running Evaluation *****\n","[INFO|trainer.py:2418] 2022-04-07 14:46:22,171 >>   Num examples = 11968\n","[INFO|trainer.py:2421] 2022-04-07 14:46:22,171 >>   Batch size = 8\n","100% 1496/1496 [04:21<00:00,  5.70it/s]04/07/2022 14:51:01 - INFO - utils_qa - Post-processing 11873 example predictions split into 11968 features.\n","\n","  0% 0/11873 [00:00<?, ?it/s]\u001b[A\n","  0% 31/11873 [00:00<00:38, 307.09it/s]\u001b[A\n","  1% 64/11873 [00:00<00:37, 316.45it/s]\u001b[A\n","  1% 96/11873 [00:00<00:37, 311.67it/s]\u001b[A\n","  1% 128/11873 [00:00<00:37, 314.88it/s]\u001b[A\n","  1% 162/11873 [00:00<00:36, 321.32it/s]\u001b[A\n","  2% 195/11873 [00:00<00:36, 321.36it/s]\u001b[A\n","  2% 229/11873 [00:00<00:35, 324.67it/s]\u001b[A\n","  2% 262/11873 [00:00<00:35, 324.47it/s]\u001b[A\n","  2% 296/11873 [00:00<00:35, 327.36it/s]\u001b[A\n","  3% 329/11873 [00:01<00:35, 324.35it/s]\u001b[A\n","  3% 362/11873 [00:01<00:35, 322.57it/s]\u001b[A\n","  3% 396/11873 [00:01<00:35, 326.72it/s]\u001b[A\n","  4% 430/11873 [00:01<00:34, 329.17it/s]\u001b[A\n","  4% 463/11873 [00:01<00:34, 328.32it/s]\u001b[A\n","  4% 496/11873 [00:01<00:34, 325.88it/s]\u001b[A\n","  4% 529/11873 [00:01<00:35, 318.23it/s]\u001b[A\n","  5% 561/11873 [00:01<00:35, 315.94it/s]\u001b[A\n","  5% 595/11873 [00:01<00:35, 320.19it/s]\u001b[A\n","  5% 628/11873 [00:01<00:34, 322.18it/s]\u001b[A\n","  6% 662/11873 [00:02<00:34, 325.71it/s]\u001b[A\n","  6% 695/11873 [00:02<00:34, 325.98it/s]\u001b[A\n","  6% 728/11873 [00:02<00:34, 326.56it/s]\u001b[A\n","  6% 761/11873 [00:02<00:34, 325.91it/s]\u001b[A\n","  7% 796/11873 [00:02<00:33, 330.62it/s]\u001b[A\n","  7% 830/11873 [00:02<00:33, 326.14it/s]\u001b[A\n","  7% 864/11873 [00:02<00:33, 329.68it/s]\u001b[A\n","  8% 899/11873 [00:02<00:32, 333.70it/s]\u001b[A\n","  8% 933/11873 [00:02<00:32, 333.05it/s]\u001b[A\n","  8% 969/11873 [00:02<00:32, 338.03it/s]\u001b[A\n","  8% 1003/11873 [00:03<00:33, 325.87it/s]\u001b[A\n","  9% 1036/11873 [00:03<00:35, 301.73it/s]\u001b[A\n","  9% 1067/11873 [00:03<00:38, 281.73it/s]\u001b[A\n","  9% 1096/11873 [00:03<00:39, 272.39it/s]\u001b[A\n","  9% 1124/11873 [00:03<00:40, 264.83it/s]\u001b[A\n"," 10% 1151/11873 [00:03<00:40, 262.15it/s]\u001b[A\n"," 10% 1178/11873 [00:03<00:40, 260.98it/s]\u001b[A\n"," 10% 1205/11873 [00:03<00:41, 257.55it/s]\u001b[A\n"," 10% 1231/11873 [00:03<00:41, 255.49it/s]\u001b[A\n"," 11% 1257/11873 [00:04<00:41, 253.51it/s]\u001b[A\n"," 11% 1283/11873 [00:04<00:42, 252.10it/s]\u001b[A\n"," 11% 1309/11873 [00:04<00:41, 253.10it/s]\u001b[A\n"," 11% 1335/11873 [00:04<00:41, 251.79it/s]\u001b[A\n"," 11% 1361/11873 [00:04<00:41, 250.59it/s]\u001b[A\n"," 12% 1387/11873 [00:04<00:41, 251.67it/s]\u001b[A\n"," 12% 1413/11873 [00:04<00:41, 252.58it/s]\u001b[A\n"," 12% 1439/11873 [00:04<00:43, 241.55it/s]\u001b[A\n"," 12% 1465/11873 [00:04<00:42, 244.80it/s]\u001b[A\n"," 13% 1490/11873 [00:05<00:42, 245.23it/s]\u001b[A\n"," 13% 1516/11873 [00:05<00:41, 247.79it/s]\u001b[A\n"," 13% 1542/11873 [00:05<00:41, 249.77it/s]\u001b[A\n"," 13% 1568/11873 [00:05<00:41, 249.79it/s]\u001b[A\n"," 13% 1594/11873 [00:05<00:41, 249.34it/s]\u001b[A\n"," 14% 1619/11873 [00:05<00:41, 248.39it/s]\u001b[A\n"," 14% 1645/11873 [00:05<00:40, 251.10it/s]\u001b[A\n"," 14% 1671/11873 [00:05<00:40, 251.63it/s]\u001b[A\n"," 14% 1697/11873 [00:05<00:40, 249.16it/s]\u001b[A\n"," 15% 1723/11873 [00:05<00:40, 252.06it/s]\u001b[A\n"," 15% 1749/11873 [00:06<00:41, 244.14it/s]\u001b[A\n"," 15% 1775/11873 [00:06<00:41, 245.92it/s]\u001b[A\n"," 15% 1801/11873 [00:06<00:40, 247.45it/s]\u001b[A\n"," 15% 1826/11873 [00:06<00:40, 246.34it/s]\u001b[A\n"," 16% 1852/11873 [00:06<00:40, 248.79it/s]\u001b[A\n"," 16% 1877/11873 [00:06<00:40, 247.59it/s]\u001b[A\n"," 16% 1902/11873 [00:06<00:41, 242.48it/s]\u001b[A\n"," 16% 1928/11873 [00:06<00:40, 245.42it/s]\u001b[A\n"," 16% 1954/11873 [00:06<00:39, 248.37it/s]\u001b[A\n"," 17% 1980/11873 [00:07<00:39, 249.41it/s]\u001b[A\n"," 17% 2006/11873 [00:07<00:39, 251.59it/s]\u001b[A\n"," 17% 2032/11873 [00:07<00:38, 253.21it/s]\u001b[A\n"," 17% 2058/11873 [00:07<00:38, 251.69it/s]\u001b[A\n"," 18% 2084/11873 [00:07<00:38, 252.27it/s]\u001b[A\n"," 18% 2110/11873 [00:07<00:39, 250.28it/s]\u001b[A\n"," 18% 2136/11873 [00:07<00:38, 250.21it/s]\u001b[A\n"," 18% 2162/11873 [00:07<00:38, 251.46it/s]\u001b[A\n"," 18% 2188/11873 [00:07<00:38, 250.97it/s]\u001b[A\n"," 19% 2214/11873 [00:07<00:38, 253.06it/s]\u001b[A\n"," 19% 2240/11873 [00:08<00:38, 250.85it/s]\u001b[A\n"," 19% 2266/11873 [00:08<00:38, 252.20it/s]\u001b[A\n"," 19% 2292/11873 [00:08<00:37, 252.85it/s]\u001b[A\n"," 20% 2318/11873 [00:08<00:38, 251.00it/s]\u001b[A\n"," 20% 2344/11873 [00:08<00:37, 252.67it/s]\u001b[A\n"," 20% 2370/11873 [00:08<00:37, 253.07it/s]\u001b[A\n"," 20% 2396/11873 [00:08<00:37, 252.60it/s]\u001b[A\n"," 20% 2422/11873 [00:08<00:37, 249.04it/s]\u001b[A\n"," 21% 2448/11873 [00:08<00:37, 250.33it/s]\u001b[A\n"," 21% 2474/11873 [00:08<00:37, 253.14it/s]\u001b[A\n"," 21% 2500/11873 [00:09<00:37, 253.21it/s]\u001b[A\n"," 21% 2526/11873 [00:09<00:36, 254.06it/s]\u001b[A\n"," 21% 2552/11873 [00:09<00:36, 253.19it/s]\u001b[A\n"," 22% 2578/11873 [00:09<00:36, 252.00it/s]\u001b[A\n"," 22% 2604/11873 [00:09<00:36, 250.76it/s]\u001b[A\n"," 22% 2630/11873 [00:09<00:36, 249.98it/s]\u001b[A\n"," 22% 2656/11873 [00:09<00:37, 248.62it/s]\u001b[A\n"," 23% 2681/11873 [00:09<00:37, 247.62it/s]\u001b[A\n"," 23% 2707/11873 [00:09<00:36, 250.12it/s]\u001b[A\n"," 23% 2733/11873 [00:10<00:36, 249.07it/s]\u001b[A\n"," 23% 2758/11873 [00:10<00:36, 248.97it/s]\u001b[A\n"," 23% 2784/11873 [00:10<00:36, 249.92it/s]\u001b[A\n"," 24% 2810/11873 [00:10<00:35, 252.41it/s]\u001b[A\n"," 24% 2836/11873 [00:10<00:36, 246.17it/s]\u001b[A\n"," 24% 2863/11873 [00:10<00:35, 250.84it/s]\u001b[A\n"," 24% 2889/11873 [00:10<00:36, 249.20it/s]\u001b[A\n"," 25% 2915/11873 [00:10<00:35, 250.47it/s]\u001b[A\n"," 25% 2941/11873 [00:10<00:36, 245.09it/s]\u001b[A\n"," 25% 2967/11873 [00:10<00:35, 248.14it/s]\u001b[A\n"," 25% 2992/11873 [00:11<00:36, 241.15it/s]\u001b[A\n"," 25% 3017/11873 [00:11<00:37, 237.71it/s]\u001b[A\n"," 26% 3042/11873 [00:11<00:36, 240.39it/s]\u001b[A\n"," 26% 3067/11873 [00:11<00:36, 238.53it/s]\u001b[A\n"," 26% 3091/11873 [00:11<00:37, 233.56it/s]\u001b[A\n"," 26% 3115/11873 [00:11<00:41, 210.05it/s]\u001b[A\n"," 26% 3138/11873 [00:11<00:40, 213.22it/s]\u001b[A\n"," 27% 3160/11873 [00:11<00:44, 197.32it/s]\u001b[A\n"," 27% 3184/11873 [00:11<00:41, 208.44it/s]\u001b[A\n"," 27% 3209/11873 [00:12<00:39, 219.08it/s]\u001b[A\n"," 27% 3235/11873 [00:12<00:37, 229.76it/s]\u001b[A\n"," 27% 3260/11873 [00:12<00:37, 232.72it/s]\u001b[A\n"," 28% 3284/11873 [00:12<00:41, 208.39it/s]\u001b[A\n"," 28% 3306/11873 [00:12<00:45, 187.45it/s]\u001b[A\n"," 28% 3326/11873 [00:12<00:47, 179.24it/s]\u001b[A\n"," 28% 3349/11873 [00:12<00:45, 189.01it/s]\u001b[A\n"," 28% 3369/11873 [00:12<00:51, 165.70it/s]\u001b[A\n"," 29% 3393/11873 [00:13<00:46, 183.66it/s]\u001b[A\n"," 29% 3419/11873 [00:13<00:41, 202.70it/s]\u001b[A\n"," 29% 3445/11873 [00:13<00:38, 216.90it/s]\u001b[A\n"," 29% 3470/11873 [00:13<00:37, 224.62it/s]\u001b[A\n"," 29% 3496/11873 [00:13<00:36, 232.53it/s]\u001b[A\n"," 30% 3522/11873 [00:13<00:34, 238.94it/s]\u001b[A\n"," 30% 3548/11873 [00:13<00:34, 242.88it/s]\u001b[A\n"," 30% 3574/11873 [00:13<00:33, 246.47it/s]\u001b[A\n"," 30% 3600/11873 [00:13<00:33, 248.46it/s]\u001b[A\n"," 31% 3627/11873 [00:13<00:32, 253.00it/s]\u001b[A\n"," 31% 3653/11873 [00:14<00:33, 242.68it/s]\u001b[A\n"," 31% 3678/11873 [00:14<00:33, 242.54it/s]\u001b[A\n"," 31% 3703/11873 [00:14<00:33, 241.69it/s]\u001b[A\n"," 31% 3728/11873 [00:14<00:33, 242.20it/s]\u001b[A\n"," 32% 3754/11873 [00:14<00:32, 247.12it/s]\u001b[A\n"," 32% 3779/11873 [00:14<00:32, 247.64it/s]\u001b[A\n"," 32% 3804/11873 [00:14<00:32, 248.02it/s]\u001b[A\n"," 32% 3829/11873 [00:14<00:32, 244.53it/s]\u001b[A\n"," 32% 3854/11873 [00:14<00:32, 245.90it/s]\u001b[A\n"," 33% 3879/11873 [00:15<00:32, 245.45it/s]\u001b[A\n"," 33% 3904/11873 [00:15<00:32, 244.27it/s]\u001b[A\n"," 33% 3929/11873 [00:15<00:32, 241.79it/s]\u001b[A\n"," 33% 3955/11873 [00:15<00:32, 244.26it/s]\u001b[A\n"," 34% 3980/11873 [00:15<00:32, 242.30it/s]\u001b[A\n"," 34% 4007/11873 [00:15<00:31, 247.97it/s]\u001b[A\n"," 34% 4032/11873 [00:15<00:31, 246.80it/s]\u001b[A\n"," 34% 4058/11873 [00:15<00:31, 249.70it/s]\u001b[A\n"," 34% 4084/11873 [00:15<00:31, 251.05it/s]\u001b[A\n"," 35% 4110/11873 [00:15<00:30, 250.97it/s]\u001b[A\n"," 35% 4136/11873 [00:16<00:31, 248.95it/s]\u001b[A\n"," 35% 4161/11873 [00:16<00:31, 242.41it/s]\u001b[A\n"," 35% 4186/11873 [00:16<00:31, 240.94it/s]\u001b[A\n"," 35% 4211/11873 [00:16<00:31, 242.29it/s]\u001b[A\n"," 36% 4237/11873 [00:16<00:31, 245.76it/s]\u001b[A\n"," 36% 4263/11873 [00:16<00:30, 246.81it/s]\u001b[A\n"," 36% 4289/11873 [00:16<00:30, 248.49it/s]\u001b[A\n"," 36% 4315/11873 [00:16<00:30, 249.99it/s]\u001b[A\n"," 37% 4341/11873 [00:16<00:30, 248.33it/s]\u001b[A\n"," 37% 4367/11873 [00:16<00:30, 249.67it/s]\u001b[A\n"," 37% 4392/11873 [00:17<00:30, 249.36it/s]\u001b[A\n"," 37% 4417/11873 [00:17<00:32, 230.69it/s]\u001b[A\n"," 37% 4441/11873 [00:17<00:33, 219.24it/s]\u001b[A\n"," 38% 4468/11873 [00:17<00:31, 232.34it/s]\u001b[A\n"," 38% 4493/11873 [00:17<00:31, 235.04it/s]\u001b[A\n"," 38% 4518/11873 [00:17<00:30, 237.81it/s]\u001b[A\n"," 38% 4543/11873 [00:17<00:30, 240.44it/s]\u001b[A\n"," 38% 4569/11873 [00:17<00:29, 244.69it/s]\u001b[A\n"," 39% 4595/11873 [00:17<00:29, 248.17it/s]\u001b[A\n"," 39% 4621/11873 [00:18<00:28, 250.99it/s]\u001b[A\n"," 39% 4647/11873 [00:18<00:29, 248.54it/s]\u001b[A\n"," 39% 4673/11873 [00:18<00:28, 250.40it/s]\u001b[A\n"," 40% 4699/11873 [00:18<00:29, 245.14it/s]\u001b[A\n"," 40% 4724/11873 [00:18<00:29, 245.13it/s]\u001b[A\n"," 40% 4749/11873 [00:18<00:28, 246.05it/s]\u001b[A\n"," 40% 4774/11873 [00:18<00:28, 245.94it/s]\u001b[A\n"," 40% 4799/11873 [00:18<00:29, 243.50it/s]\u001b[A\n"," 41% 4824/11873 [00:18<00:29, 242.99it/s]\u001b[A\n"," 41% 4849/11873 [00:18<00:28, 244.48it/s]\u001b[A\n"," 41% 4874/11873 [00:19<00:28, 244.73it/s]\u001b[A\n"," 41% 4899/11873 [00:19<00:28, 245.56it/s]\u001b[A\n"," 41% 4924/11873 [00:19<00:28, 245.88it/s]\u001b[A\n"," 42% 4949/11873 [00:19<00:28, 245.90it/s]\u001b[A\n"," 42% 4975/11873 [00:19<00:27, 249.00it/s]\u001b[A\n"," 42% 5000/11873 [00:19<00:27, 247.09it/s]\u001b[A\n"," 42% 5025/11873 [00:19<00:27, 245.69it/s]\u001b[A\n"," 43% 5050/11873 [00:19<00:27, 243.85it/s]\u001b[A\n"," 43% 5076/11873 [00:19<00:27, 247.50it/s]\u001b[A\n"," 43% 5101/11873 [00:20<00:27, 247.85it/s]\u001b[A\n"," 43% 5127/11873 [00:20<00:27, 248.56it/s]\u001b[A\n"," 43% 5152/11873 [00:20<00:27, 247.81it/s]\u001b[A\n"," 44% 5178/11873 [00:20<00:26, 250.89it/s]\u001b[A\n"," 44% 5204/11873 [00:20<00:26, 250.01it/s]\u001b[A\n"," 44% 5230/11873 [00:20<00:26, 250.64it/s]\u001b[A\n"," 44% 5256/11873 [00:20<00:27, 239.87it/s]\u001b[A\n"," 44% 5281/11873 [00:20<00:28, 233.31it/s]\u001b[A\n"," 45% 5307/11873 [00:20<00:27, 239.75it/s]\u001b[A\n"," 45% 5333/11873 [00:20<00:26, 244.31it/s]\u001b[A\n"," 45% 5359/11873 [00:21<00:26, 246.24it/s]\u001b[A\n"," 45% 5385/11873 [00:21<00:26, 249.00it/s]\u001b[A\n"," 46% 5411/11873 [00:21<00:25, 250.07it/s]\u001b[A\n"," 46% 5437/11873 [00:21<00:25, 250.01it/s]\u001b[A\n"," 46% 5463/11873 [00:21<00:26, 244.42it/s]\u001b[A\n"," 46% 5488/11873 [00:21<00:26, 245.36it/s]\u001b[A\n"," 46% 5514/11873 [00:21<00:25, 247.42it/s]\u001b[A\n"," 47% 5540/11873 [00:21<00:25, 248.61it/s]\u001b[A\n"," 47% 5565/11873 [00:21<00:25, 244.73it/s]\u001b[A\n"," 47% 5590/11873 [00:21<00:25, 245.02it/s]\u001b[A\n"," 47% 5615/11873 [00:22<00:25, 241.79it/s]\u001b[A\n"," 48% 5640/11873 [00:22<00:25, 243.24it/s]\u001b[A\n"," 48% 5666/11873 [00:22<00:25, 247.33it/s]\u001b[A\n"," 48% 5691/11873 [00:22<00:25, 246.87it/s]\u001b[A\n"," 48% 5717/11873 [00:22<00:24, 248.78it/s]\u001b[A\n"," 48% 5743/11873 [00:22<00:24, 249.60it/s]\u001b[A\n"," 49% 5768/11873 [00:22<00:24, 248.11it/s]\u001b[A\n"," 49% 5794/11873 [00:22<00:24, 250.53it/s]\u001b[A\n"," 49% 5820/11873 [00:22<00:24, 251.58it/s]\u001b[A\n"," 49% 5846/11873 [00:23<00:24, 250.75it/s]\u001b[A\n"," 49% 5872/11873 [00:23<00:23, 252.49it/s]\u001b[A\n"," 50% 5898/11873 [00:23<00:23, 250.90it/s]\u001b[A\n"," 50% 5924/11873 [00:23<00:23, 252.88it/s]\u001b[A\n"," 50% 5950/11873 [00:23<00:23, 253.39it/s]\u001b[A\n"," 50% 5976/11873 [00:23<00:23, 252.68it/s]\u001b[A\n"," 51% 6002/11873 [00:23<00:23, 252.28it/s]\u001b[A\n"," 51% 6028/11873 [00:23<00:23, 252.90it/s]\u001b[A\n"," 51% 6054/11873 [00:23<00:23, 251.76it/s]\u001b[A\n"," 51% 6080/11873 [00:23<00:23, 251.40it/s]\u001b[A\n"," 51% 6106/11873 [00:24<00:23, 246.58it/s]\u001b[A\n"," 52% 6131/11873 [00:24<00:23, 247.10it/s]\u001b[A\n"," 52% 6156/11873 [00:24<00:23, 245.97it/s]\u001b[A\n"," 52% 6181/11873 [00:24<00:23, 246.12it/s]\u001b[A\n"," 52% 6206/11873 [00:24<00:22, 246.80it/s]\u001b[A\n"," 52% 6231/11873 [00:24<00:22, 245.94it/s]\u001b[A\n"," 53% 6256/11873 [00:24<00:22, 246.68it/s]\u001b[A\n"," 53% 6281/11873 [00:24<00:22, 247.09it/s]\u001b[A\n"," 53% 6307/11873 [00:24<00:22, 248.38it/s]\u001b[A\n"," 53% 6332/11873 [00:24<00:22, 247.79it/s]\u001b[A\n"," 54% 6357/11873 [00:25<00:22, 248.11it/s]\u001b[A\n"," 54% 6382/11873 [00:25<00:22, 248.43it/s]\u001b[A\n"," 54% 6407/11873 [00:25<00:21, 248.84it/s]\u001b[A\n"," 54% 6432/11873 [00:25<00:22, 246.63it/s]\u001b[A\n"," 54% 6458/11873 [00:25<00:21, 248.08it/s]\u001b[A\n"," 55% 6484/11873 [00:25<00:21, 249.11it/s]\u001b[A\n"," 55% 6509/11873 [00:25<00:21, 244.94it/s]\u001b[A\n"," 55% 6535/11873 [00:25<00:21, 247.50it/s]\u001b[A\n"," 55% 6561/11873 [00:25<00:21, 248.29it/s]\u001b[A\n"," 55% 6586/11873 [00:26<00:21, 247.19it/s]\u001b[A\n"," 56% 6611/11873 [00:26<00:21, 247.62it/s]\u001b[A\n"," 56% 6636/11873 [00:26<00:21, 248.27it/s]\u001b[A\n"," 56% 6662/11873 [00:26<00:20, 251.62it/s]\u001b[A\n"," 56% 6688/11873 [00:26<00:20, 248.46it/s]\u001b[A\n"," 57% 6713/11873 [00:26<00:20, 246.58it/s]\u001b[A\n"," 57% 6738/11873 [00:26<00:21, 239.25it/s]\u001b[A\n"," 57% 6764/11873 [00:26<00:20, 243.84it/s]\u001b[A\n"," 57% 6789/11873 [00:26<00:20, 242.67it/s]\u001b[A\n"," 57% 6814/11873 [00:26<00:20, 243.26it/s]\u001b[A\n"," 58% 6840/11873 [00:27<00:20, 246.49it/s]\u001b[A\n"," 58% 6865/11873 [00:27<00:20, 246.92it/s]\u001b[A\n"," 58% 6891/11873 [00:27<00:20, 247.80it/s]\u001b[A\n"," 58% 6916/11873 [00:27<00:20, 247.45it/s]\u001b[A\n"," 58% 6941/11873 [00:27<00:19, 247.88it/s]\u001b[A\n"," 59% 6966/11873 [00:27<00:19, 246.85it/s]\u001b[A\n"," 59% 6992/11873 [00:27<00:19, 248.64it/s]\u001b[A\n"," 59% 7017/11873 [00:27<00:19, 248.25it/s]\u001b[A\n"," 59% 7042/11873 [00:27<00:19, 248.38it/s]\u001b[A\n"," 60% 7067/11873 [00:27<00:19, 248.71it/s]\u001b[A\n"," 60% 7092/11873 [00:28<00:19, 249.00it/s]\u001b[A\n"," 60% 7117/11873 [00:28<00:19, 246.40it/s]\u001b[A\n"," 60% 7142/11873 [00:28<00:19, 244.95it/s]\u001b[A\n"," 60% 7167/11873 [00:28<00:19, 245.51it/s]\u001b[A\n"," 61% 7192/11873 [00:28<00:19, 245.70it/s]\u001b[A\n"," 61% 7217/11873 [00:28<00:18, 245.92it/s]\u001b[A\n"," 61% 7243/11873 [00:28<00:18, 249.43it/s]\u001b[A\n"," 61% 7268/11873 [00:28<00:18, 246.35it/s]\u001b[A\n"," 61% 7294/11873 [00:28<00:18, 248.03it/s]\u001b[A\n"," 62% 7319/11873 [00:28<00:18, 248.28it/s]\u001b[A\n"," 62% 7344/11873 [00:29<00:18, 247.58it/s]\u001b[A\n"," 62% 7369/11873 [00:29<00:18, 246.55it/s]\u001b[A\n"," 62% 7395/11873 [00:29<00:17, 249.25it/s]\u001b[A\n"," 62% 7420/11873 [00:29<00:18, 245.81it/s]\u001b[A\n"," 63% 7445/11873 [00:29<00:17, 246.58it/s]\u001b[A\n"," 63% 7470/11873 [00:29<00:17, 247.44it/s]\u001b[A\n"," 63% 7496/11873 [00:29<00:17, 249.42it/s]\u001b[A\n"," 63% 7521/11873 [00:29<00:17, 249.17it/s]\u001b[A\n"," 64% 7547/11873 [00:29<00:17, 249.95it/s]\u001b[A\n"," 64% 7573/11873 [00:29<00:17, 250.90it/s]\u001b[A\n"," 64% 7599/11873 [00:30<00:17, 243.54it/s]\u001b[A\n"," 64% 7624/11873 [00:30<00:17, 242.78it/s]\u001b[A\n"," 64% 7649/11873 [00:30<00:17, 243.34it/s]\u001b[A\n"," 65% 7674/11873 [00:30<00:17, 242.59it/s]\u001b[A\n"," 65% 7699/11873 [00:30<00:17, 242.79it/s]\u001b[A\n"," 65% 7724/11873 [00:30<00:17, 241.51it/s]\u001b[A\n"," 65% 7749/11873 [00:30<00:17, 240.69it/s]\u001b[A\n"," 65% 7774/11873 [00:30<00:16, 242.24it/s]\u001b[A\n"," 66% 7799/11873 [00:30<00:16, 241.66it/s]\u001b[A\n"," 66% 7824/11873 [00:31<00:16, 242.66it/s]\u001b[A\n"," 66% 7849/11873 [00:31<00:16, 237.64it/s]\u001b[A\n"," 66% 7873/11873 [00:31<00:16, 238.27it/s]\u001b[A\n"," 67% 7898/11873 [00:31<00:16, 241.55it/s]\u001b[A\n"," 67% 7923/11873 [00:31<00:16, 236.41it/s]\u001b[A\n"," 67% 7949/11873 [00:31<00:16, 241.29it/s]\u001b[A\n"," 67% 7974/11873 [00:31<00:16, 239.78it/s]\u001b[A\n"," 67% 7999/11873 [00:31<00:16, 241.73it/s]\u001b[A\n"," 68% 8024/11873 [00:31<00:16, 237.06it/s]\u001b[A\n"," 68% 8049/11873 [00:31<00:15, 239.12it/s]\u001b[A\n"," 68% 8074/11873 [00:32<00:15, 241.73it/s]\u001b[A\n"," 68% 8099/11873 [00:32<00:15, 240.85it/s]\u001b[A\n"," 68% 8124/11873 [00:32<00:15, 242.79it/s]\u001b[A\n"," 69% 8149/11873 [00:32<00:15, 241.83it/s]\u001b[A\n"," 69% 8175/11873 [00:32<00:15, 245.55it/s]\u001b[A\n"," 69% 8200/11873 [00:32<00:15, 243.71it/s]\u001b[A\n"," 69% 8225/11873 [00:32<00:14, 244.46it/s]\u001b[A\n"," 69% 8251/11873 [00:32<00:14, 247.34it/s]\u001b[A\n"," 70% 8277/11873 [00:32<00:14, 248.92it/s]\u001b[A\n"," 70% 8302/11873 [00:33<00:14, 248.75it/s]\u001b[A\n"," 70% 8328/11873 [00:33<00:14, 249.89it/s]\u001b[A\n"," 70% 8353/11873 [00:33<00:14, 247.79it/s]\u001b[A\n"," 71% 8378/11873 [00:33<00:14, 247.73it/s]\u001b[A\n"," 71% 8404/11873 [00:33<00:13, 248.30it/s]\u001b[A\n"," 71% 8429/11873 [00:33<00:13, 248.50it/s]\u001b[A\n"," 71% 8454/11873 [00:33<00:13, 245.91it/s]\u001b[A\n"," 71% 8480/11873 [00:33<00:13, 247.39it/s]\u001b[A\n"," 72% 8506/11873 [00:33<00:13, 247.55it/s]\u001b[A\n"," 72% 8531/11873 [00:33<00:13, 247.18it/s]\u001b[A\n"," 72% 8556/11873 [00:34<00:13, 245.14it/s]\u001b[A\n"," 72% 8581/11873 [00:34<00:13, 245.21it/s]\u001b[A\n"," 72% 8606/11873 [00:34<00:13, 244.66it/s]\u001b[A\n"," 73% 8631/11873 [00:34<00:13, 242.60it/s]\u001b[A\n"," 73% 8656/11873 [00:34<00:13, 244.73it/s]\u001b[A\n"," 73% 8682/11873 [00:34<00:12, 247.29it/s]\u001b[A\n"," 73% 8707/11873 [00:34<00:12, 247.80it/s]\u001b[A\n"," 74% 8733/11873 [00:34<00:12, 250.98it/s]\u001b[A\n"," 74% 8759/11873 [00:34<00:12, 251.85it/s]\u001b[A\n"," 74% 8785/11873 [00:34<00:12, 249.99it/s]\u001b[A\n"," 74% 8811/11873 [00:35<00:12, 249.43it/s]\u001b[A\n"," 74% 8837/11873 [00:35<00:12, 250.63it/s]\u001b[A\n"," 75% 8863/11873 [00:35<00:12, 247.94it/s]\u001b[A\n"," 75% 8888/11873 [00:35<00:12, 247.96it/s]\u001b[A\n"," 75% 8914/11873 [00:35<00:11, 250.58it/s]\u001b[A\n"," 75% 8940/11873 [00:35<00:11, 250.39it/s]\u001b[A\n"," 76% 8966/11873 [00:35<00:11, 250.29it/s]\u001b[A\n"," 76% 8992/11873 [00:35<00:11, 248.83it/s]\u001b[A\n"," 76% 9018/11873 [00:35<00:11, 249.23it/s]\u001b[A\n"," 76% 9043/11873 [00:35<00:11, 247.20it/s]\u001b[A\n"," 76% 9068/11873 [00:36<00:11, 247.43it/s]\u001b[A\n"," 77% 9094/11873 [00:36<00:11, 249.64it/s]\u001b[A\n"," 77% 9119/11873 [00:36<00:11, 248.96it/s]\u001b[A\n"," 77% 9144/11873 [00:36<00:10, 248.20it/s]\u001b[A\n"," 77% 9171/11873 [00:36<00:10, 252.46it/s]\u001b[A\n"," 77% 9197/11873 [00:36<00:10, 247.75it/s]\u001b[A\n"," 78% 9223/11873 [00:36<00:10, 248.51it/s]\u001b[A\n"," 78% 9248/11873 [00:36<00:10, 248.07it/s]\u001b[A\n"," 78% 9274/11873 [00:36<00:10, 249.60it/s]\u001b[A\n"," 78% 9299/11873 [00:37<00:10, 249.29it/s]\u001b[A\n"," 79% 9324/11873 [00:37<00:10, 244.89it/s]\u001b[A\n"," 79% 9349/11873 [00:37<00:10, 245.15it/s]\u001b[A\n"," 79% 9374/11873 [00:37<00:10, 244.87it/s]\u001b[A\n"," 79% 9399/11873 [00:37<00:10, 245.56it/s]\u001b[A\n"," 79% 9424/11873 [00:37<00:09, 245.59it/s]\u001b[A\n"," 80% 9450/11873 [00:37<00:09, 248.47it/s]\u001b[A\n"," 80% 9476/11873 [00:37<00:09, 249.94it/s]\u001b[A\n"," 80% 9502/11873 [00:37<00:09, 252.13it/s]\u001b[A\n"," 80% 9528/11873 [00:37<00:09, 251.93it/s]\u001b[A\n"," 80% 9554/11873 [00:38<00:09, 251.45it/s]\u001b[A\n"," 81% 9580/11873 [00:38<00:09, 251.83it/s]\u001b[A\n"," 81% 9606/11873 [00:38<00:08, 251.94it/s]\u001b[A\n"," 81% 9632/11873 [00:38<00:08, 249.57it/s]\u001b[A\n"," 81% 9657/11873 [00:38<00:08, 248.91it/s]\u001b[A\n"," 82% 9683/11873 [00:38<00:08, 250.24it/s]\u001b[A\n"," 82% 9709/11873 [00:38<00:08, 252.08it/s]\u001b[A\n"," 82% 9735/11873 [00:38<00:08, 253.44it/s]\u001b[A\n"," 82% 9761/11873 [00:38<00:08, 253.55it/s]\u001b[A\n"," 82% 9787/11873 [00:38<00:08, 252.66it/s]\u001b[A\n"," 83% 9813/11873 [00:39<00:08, 243.67it/s]\u001b[A\n"," 83% 9840/11873 [00:39<00:08, 248.86it/s]\u001b[A\n"," 83% 9866/11873 [00:39<00:08, 249.82it/s]\u001b[A\n"," 83% 9892/11873 [00:39<00:07, 249.25it/s]\u001b[A\n"," 84% 9918/11873 [00:39<00:07, 252.14it/s]\u001b[A\n"," 84% 9944/11873 [00:39<00:07, 252.68it/s]\u001b[A\n"," 84% 9970/11873 [00:39<00:07, 253.77it/s]\u001b[A\n"," 84% 9996/11873 [00:39<00:07, 253.73it/s]\u001b[A\n"," 84% 10022/11873 [00:39<00:07, 254.90it/s]\u001b[A\n"," 85% 10049/11873 [00:40<00:07, 256.96it/s]\u001b[A\n"," 85% 10075/11873 [00:40<00:07, 255.37it/s]\u001b[A\n"," 85% 10101/11873 [00:40<00:06, 256.18it/s]\u001b[A\n"," 85% 10127/11873 [00:40<00:06, 253.69it/s]\u001b[A\n"," 86% 10153/11873 [00:40<00:06, 253.24it/s]\u001b[A\n"," 86% 10179/11873 [00:40<00:06, 251.72it/s]\u001b[A\n"," 86% 10205/11873 [00:40<00:06, 247.56it/s]\u001b[A\n"," 86% 10232/11873 [00:40<00:06, 251.23it/s]\u001b[A\n"," 86% 10258/11873 [00:40<00:06, 249.04it/s]\u001b[A\n"," 87% 10283/11873 [00:40<00:06, 247.02it/s]\u001b[A\n"," 87% 10308/11873 [00:41<00:06, 244.62it/s]\u001b[A\n"," 87% 10334/11873 [00:41<00:06, 247.95it/s]\u001b[A\n"," 87% 10360/11873 [00:41<00:06, 250.76it/s]\u001b[A\n"," 87% 10386/11873 [00:41<00:05, 250.11it/s]\u001b[A\n"," 88% 10412/11873 [00:41<00:05, 251.74it/s]\u001b[A\n"," 88% 10438/11873 [00:41<00:05, 250.28it/s]\u001b[A\n"," 88% 10464/11873 [00:41<00:05, 251.56it/s]\u001b[A\n"," 88% 10490/11873 [00:41<00:05, 253.01it/s]\u001b[A\n"," 89% 10516/11873 [00:41<00:05, 253.24it/s]\u001b[A\n"," 89% 10542/11873 [00:41<00:05, 251.88it/s]\u001b[A\n"," 89% 10568/11873 [00:42<00:05, 250.75it/s]\u001b[A\n"," 89% 10594/11873 [00:42<00:05, 248.78it/s]\u001b[A\n"," 89% 10620/11873 [00:42<00:04, 251.83it/s]\u001b[A\n"," 90% 10646/11873 [00:42<00:04, 247.59it/s]\u001b[A\n"," 90% 10671/11873 [00:42<00:07, 161.33it/s]\u001b[A\n"," 90% 10696/11873 [00:42<00:06, 179.91it/s]\u001b[A\n"," 90% 10721/11873 [00:42<00:05, 195.04it/s]\u001b[A\n"," 91% 10746/11873 [00:42<00:05, 208.45it/s]\u001b[A\n"," 91% 10771/11873 [00:43<00:05, 218.63it/s]\u001b[A\n"," 91% 10796/11873 [00:43<00:04, 225.88it/s]\u001b[A\n"," 91% 10821/11873 [00:43<00:04, 231.69it/s]\u001b[A\n"," 91% 10846/11873 [00:43<00:04, 232.84it/s]\u001b[A\n"," 92% 10871/11873 [00:43<00:04, 237.07it/s]\u001b[A\n"," 92% 10896/11873 [00:43<00:04, 234.71it/s]\u001b[A\n"," 92% 10921/11873 [00:43<00:03, 239.02it/s]\u001b[A\n"," 92% 10946/11873 [00:43<00:03, 236.20it/s]\u001b[A\n"," 92% 10972/11873 [00:43<00:03, 241.72it/s]\u001b[A\n"," 93% 10997/11873 [00:44<00:03, 243.91it/s]\u001b[A\n"," 93% 11022/11873 [00:44<00:03, 245.16it/s]\u001b[A\n"," 93% 11048/11873 [00:44<00:03, 248.92it/s]\u001b[A\n"," 93% 11074/11873 [00:44<00:03, 250.11it/s]\u001b[A\n"," 93% 11100/11873 [00:44<00:03, 247.52it/s]\u001b[A\n"," 94% 11125/11873 [00:44<00:03, 246.95it/s]\u001b[A\n"," 94% 11150/11873 [00:44<00:02, 247.65it/s]\u001b[A\n"," 94% 11176/11873 [00:44<00:02, 248.56it/s]\u001b[A\n"," 94% 11201/11873 [00:44<00:02, 248.74it/s]\u001b[A\n"," 95% 11226/11873 [00:44<00:02, 248.95it/s]\u001b[A\n"," 95% 11251/11873 [00:45<00:02, 247.02it/s]\u001b[A\n"," 95% 11276/11873 [00:45<00:02, 247.71it/s]\u001b[A\n"," 95% 11302/11873 [00:45<00:02, 250.13it/s]\u001b[A\n"," 95% 11328/11873 [00:45<00:02, 249.58it/s]\u001b[A\n"," 96% 11353/11873 [00:45<00:02, 246.25it/s]\u001b[A\n"," 96% 11378/11873 [00:45<00:02, 247.03it/s]\u001b[A\n"," 96% 11403/11873 [00:45<00:01, 242.42it/s]\u001b[A\n"," 96% 11429/11873 [00:45<00:01, 245.59it/s]\u001b[A\n"," 96% 11455/11873 [00:45<00:01, 247.14it/s]\u001b[A\n"," 97% 11480/11873 [00:45<00:01, 247.74it/s]\u001b[A\n"," 97% 11505/11873 [00:46<00:01, 245.72it/s]\u001b[A\n"," 97% 11531/11873 [00:46<00:01, 247.81it/s]\u001b[A\n"," 97% 11556/11873 [00:46<00:01, 246.27it/s]\u001b[A\n"," 98% 11581/11873 [00:46<00:01, 246.91it/s]\u001b[A\n"," 98% 11606/11873 [00:46<00:01, 245.90it/s]\u001b[A\n"," 98% 11632/11873 [00:46<00:00, 247.77it/s]\u001b[A\n"," 98% 11657/11873 [00:46<00:00, 246.97it/s]\u001b[A\n"," 98% 11682/11873 [00:46<00:00, 245.82it/s]\u001b[A\n"," 99% 11707/11873 [00:46<00:00, 245.13it/s]\u001b[A\n"," 99% 11733/11873 [00:46<00:00, 246.63it/s]\u001b[A\n"," 99% 11758/11873 [00:47<00:00, 246.23it/s]\u001b[A\n"," 99% 11784/11873 [00:47<00:00, 248.90it/s]\u001b[A\n"," 99% 11810/11873 [00:47<00:00, 250.57it/s]\u001b[A\n","100% 11836/11873 [00:47<00:00, 242.39it/s]\u001b[A\n","100% 11873/11873 [00:47<00:00, 249.60it/s]\n","04/07/2022 14:51:49 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/eval_predictions.json.\n","04/07/2022 14:51:49 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/eval_nbest_predictions.json.\n","04/07/2022 14:51:52 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-possible-aug/eval_null_odds.json.\n","04/07/2022 14:51:56 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n","100% 1496/1496 [05:33<00:00,  4.48it/s]\n","***** eval metrics *****\n","  epoch                  =     2.0\n","  eval_HasAns_exact      = 77.1592\n","  eval_HasAns_f1         = 83.2056\n","  eval_HasAns_total      =    5928\n","  eval_NoAns_exact       = 74.9706\n","  eval_NoAns_f1          = 74.9706\n","  eval_NoAns_total       =    5945\n","  eval_best_exact        = 76.0718\n","  eval_best_exact_thresh =     0.0\n","  eval_best_f1           = 79.0906\n","  eval_best_f1_thresh    =     0.0\n","  eval_exact             = 76.0633\n","  eval_f1                = 79.0822\n","  eval_samples           =   11968\n","  eval_total             =   11873\n","[INFO|modelcard.py:460] 2022-04-07 14:51:56,514 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'sichenzhong/squad_v2_back_trans_synonym_possib_aug', 'type': 'sichenzhong/squad_v2_back_trans_synonym_possib_aug', 'args': 'squad_v2'}}\n"]}]},{"cell_type":"code","source":["!python run_qa.py \\\n","  --model_name_or_path roberta-base \\\n","  --dataset_name sichenzhong/squad_v2_back_trans_synonym_possib_aug \\\n","  --do_train \\\n","  --do_eval \\\n","  --per_device_train_batch_size 16 \\\n","  --learning_rate 2e-5 \\\n","  --num_train_epochs 2 \\\n","  --max_seq_length 512 \\\n","  --doc_stride 128 \\\n","  --version_2_with_negative \\\n","  --output_dir /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-zY4lv3mACY","executionInfo":{"status":"ok","timestamp":1649374181799,"user_tz":240,"elapsed":14878410,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"9436a4ff-97e9-4b62-9555-4a193e11cc76"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["04/07/2022 19:21:45 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","04/07/2022 19:21:45 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.NO,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=2e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/runs/Apr07_19-21-45_1877836f64d8,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=2.0,\n","optim=OptimizerNames.ADAMW_HF,\n","output_dir=/content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=16,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","04/07/2022 19:21:47 - WARNING - datasets.builder - Using custom data configuration sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a\n","04/07/2022 19:21:47 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n","04/07/2022 19:21:47 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901\n","04/07/2022 19:21:47 - WARNING - datasets.builder - Reusing dataset parquet (/root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n","04/07/2022 19:21:47 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901\n","100% 2/2 [00:00<00:00, 555.21it/s]\n","[INFO|configuration_utils.py:654] 2022-04-07 19:21:47,856 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","[INFO|configuration_utils.py:690] 2022-04-07 19:21:47,858 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|tokenization_auto.py:344] 2022-04-07 19:21:48,215 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n","[INFO|configuration_utils.py:654] 2022-04-07 19:21:48,580 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","[INFO|configuration_utils.py:690] 2022-04-07 19:21:48,581 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 19:21:51,081 >> loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 19:21:51,082 >> loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 19:21:51,082 >> loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 19:21:51,082 >> loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 19:21:51,082 >> loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 19:21:51,082 >> loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n","[INFO|configuration_utils.py:654] 2022-04-07 19:21:51,432 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","[INFO|configuration_utils.py:690] 2022-04-07 19:21:51,433 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|modeling_utils.py:1772] 2022-04-07 19:21:51,910 >> loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n","[WARNING|modeling_utils.py:2049] 2022-04-07 19:21:55,074 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n","- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:2060] 2022-04-07 19:21:55,074 >> Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","04/07/2022 19:21:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-4c82c52a90012b69.arrow\n","Running tokenizer on validation dataset:   0% 0/12 [00:00<?, ?ba/s]04/07/2022 19:21:55 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_possib_aug-1b7077d7812c843a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-660f0bb445215688.arrow\n","Running tokenizer on validation dataset: 100% 12/12 [01:28<00:00,  7.38s/ba]\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","[INFO|trainer.py:1290] 2022-04-07 19:23:29,906 >> ***** Running training *****\n","[INFO|trainer.py:1291] 2022-04-07 19:23:29,906 >>   Num examples = 130553\n","[INFO|trainer.py:1292] 2022-04-07 19:23:29,906 >>   Num Epochs = 2\n","[INFO|trainer.py:1293] 2022-04-07 19:23:29,906 >>   Instantaneous batch size per device = 16\n","[INFO|trainer.py:1294] 2022-04-07 19:23:29,906 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:1295] 2022-04-07 19:23:29,906 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1296] 2022-04-07 19:23:29,906 >>   Total optimization steps = 16320\n","{'loss': 2.2939, 'learning_rate': 1.9387254901960785e-05, 'epoch': 0.06}\n","  3% 500/16320 [07:15<3:49:10,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 19:30:45,279 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-500\n","[INFO|configuration_utils.py:441] 2022-04-07 19:30:45,288 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 19:30:46,742 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 19:30:46,748 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 19:30:46,752 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-500/special_tokens_map.json\n","{'loss': 1.5911, 'learning_rate': 1.877450980392157e-05, 'epoch': 0.12}\n","  6% 1000/16320 [14:35<3:42:38,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 19:38:05,731 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1000\n","[INFO|configuration_utils.py:441] 2022-04-07 19:38:05,738 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 19:38:07,201 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 19:38:07,206 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 19:38:07,209 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1000/special_tokens_map.json\n","{'loss': 1.5005, 'learning_rate': 1.8161764705882355e-05, 'epoch': 0.18}\n","  9% 1500/16320 [21:55<3:35:06,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 19:45:25,834 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1500\n","[INFO|configuration_utils.py:441] 2022-04-07 19:45:25,839 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 19:45:27,301 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 19:45:27,307 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 19:45:27,311 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-1500/special_tokens_map.json\n","{'loss': 1.4276, 'learning_rate': 1.7549019607843138e-05, 'epoch': 0.25}\n"," 12% 2000/16320 [29:16<3:27:57,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 19:52:46,178 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2000\n","[INFO|configuration_utils.py:441] 2022-04-07 19:52:46,185 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 19:52:47,610 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 19:52:47,615 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 19:52:47,619 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2000/special_tokens_map.json\n","{'loss': 1.3575, 'learning_rate': 1.693627450980392e-05, 'epoch': 0.31}\n"," 15% 2500/16320 [36:36<3:21:05,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 20:00:06,340 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2500\n","[INFO|configuration_utils.py:441] 2022-04-07 20:00:06,346 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 20:00:07,790 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 20:00:07,794 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 20:00:07,798 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-2500/special_tokens_map.json\n","{'loss': 1.3098, 'learning_rate': 1.6323529411764708e-05, 'epoch': 0.37}\n"," 18% 3000/16320 [43:59<3:13:22,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 20:07:29,425 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3000\n","[INFO|configuration_utils.py:441] 2022-04-07 20:07:29,431 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 20:07:30,849 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 20:07:30,855 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 20:07:30,860 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3000/special_tokens_map.json\n","{'loss': 1.3028, 'learning_rate': 1.571078431372549e-05, 'epoch': 0.43}\n"," 21% 3500/16320 [51:23<3:06:21,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 20:14:53,376 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3500\n","[INFO|configuration_utils.py:441] 2022-04-07 20:14:53,383 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 20:14:54,805 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 20:14:54,810 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 20:14:54,814 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-3500/special_tokens_map.json\n","{'loss': 1.2744, 'learning_rate': 1.5098039215686276e-05, 'epoch': 0.49}\n"," 25% 4000/16320 [58:46<2:58:16,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 20:22:16,789 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4000\n","[INFO|configuration_utils.py:441] 2022-04-07 20:22:16,795 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 20:22:18,217 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 20:22:18,223 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 20:22:18,227 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4000/special_tokens_map.json\n","{'loss': 1.2282, 'learning_rate': 1.448529411764706e-05, 'epoch': 0.55}\n"," 28% 4500/16320 [1:06:10<2:51:46,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 20:29:40,551 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4500\n","[INFO|configuration_utils.py:441] 2022-04-07 20:29:40,557 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 20:29:41,998 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 20:29:42,003 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 20:29:42,007 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-4500/special_tokens_map.json\n","{'loss': 1.2109, 'learning_rate': 1.3872549019607844e-05, 'epoch': 0.61}\n"," 31% 5000/16320 [1:13:34<2:44:26,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 20:37:04,233 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5000\n","[INFO|configuration_utils.py:441] 2022-04-07 20:37:04,239 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 20:37:05,855 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 20:37:05,860 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 20:37:05,864 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5000/special_tokens_map.json\n","{'loss': 1.216, 'learning_rate': 1.3259803921568627e-05, 'epoch': 0.67}\n"," 34% 5500/16320 [1:20:57<2:37:05,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 20:44:27,781 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5500\n","[INFO|configuration_utils.py:441] 2022-04-07 20:44:27,787 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 20:44:29,216 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 20:44:29,221 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 20:44:29,225 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-5500/special_tokens_map.json\n","{'loss': 1.21, 'learning_rate': 1.2647058823529412e-05, 'epoch': 0.74}\n"," 37% 6000/16320 [1:28:21<2:29:47,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 20:51:51,586 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6000\n","[INFO|configuration_utils.py:441] 2022-04-07 20:51:51,594 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 20:51:52,980 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 20:51:52,987 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 20:51:52,991 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6000/special_tokens_map.json\n","{'loss': 1.1661, 'learning_rate': 1.2034313725490197e-05, 'epoch': 0.8}\n"," 40% 6500/16320 [1:35:45<2:22:33,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 20:59:15,309 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6500\n","[INFO|configuration_utils.py:441] 2022-04-07 20:59:15,315 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 20:59:16,741 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 20:59:16,748 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 20:59:16,752 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-6500/special_tokens_map.json\n","{'loss': 1.1583, 'learning_rate': 1.142156862745098e-05, 'epoch': 0.86}\n"," 43% 7000/16320 [1:43:09<2:15:12,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 21:06:39,246 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7000\n","[INFO|configuration_utils.py:441] 2022-04-07 21:06:39,252 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 21:06:40,677 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 21:06:40,687 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 21:06:40,698 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7000/special_tokens_map.json\n","{'loss': 1.1445, 'learning_rate': 1.0808823529411765e-05, 'epoch': 0.92}\n"," 46% 7500/16320 [1:50:33<2:08:13,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 21:14:03,222 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7500\n","[INFO|configuration_utils.py:441] 2022-04-07 21:14:03,229 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 21:14:04,608 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 21:14:04,613 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 21:14:04,617 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-7500/special_tokens_map.json\n","{'loss': 1.1067, 'learning_rate': 1.0196078431372549e-05, 'epoch': 0.98}\n"," 49% 8000/16320 [1:57:57<2:01:01,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 21:21:27,210 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8000\n","[INFO|configuration_utils.py:441] 2022-04-07 21:21:27,216 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 21:21:28,586 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 21:21:28,592 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 21:21:28,596 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8000/special_tokens_map.json\n","{'loss': 0.9919, 'learning_rate': 9.583333333333335e-06, 'epoch': 1.04}\n"," 52% 8500/16320 [2:05:18<1:53:33,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 21:28:48,716 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8500\n","[INFO|configuration_utils.py:441] 2022-04-07 21:28:48,722 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 21:28:50,078 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 21:28:50,085 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 21:28:50,094 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-8500/special_tokens_map.json\n","{'loss': 0.9139, 'learning_rate': 8.970588235294119e-06, 'epoch': 1.1}\n"," 55% 9000/16320 [2:12:41<1:46:28,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 21:36:11,883 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9000\n","[INFO|configuration_utils.py:441] 2022-04-07 21:36:11,889 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 21:36:13,259 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 21:36:13,264 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 21:36:13,267 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9000/special_tokens_map.json\n","{'loss': 0.9186, 'learning_rate': 8.357843137254903e-06, 'epoch': 1.16}\n"," 58% 9500/16320 [2:20:05<1:39:05,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 21:43:35,885 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9500\n","[INFO|configuration_utils.py:441] 2022-04-07 21:43:35,891 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 21:43:37,247 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 21:43:37,253 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 21:43:37,258 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-9500/special_tokens_map.json\n","{'loss': 0.9393, 'learning_rate': 7.745098039215687e-06, 'epoch': 1.23}\n"," 61% 10000/16320 [2:27:29<1:31:56,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 21:50:59,429 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10000\n","[INFO|configuration_utils.py:441] 2022-04-07 21:50:59,435 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 21:51:00,803 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 21:51:00,809 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 21:51:00,814 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10000/special_tokens_map.json\n","{'loss': 0.8996, 'learning_rate': 7.132352941176472e-06, 'epoch': 1.29}\n"," 64% 10500/16320 [2:34:53<1:24:44,  1.14it/s][INFO|trainer.py:2166] 2022-04-07 21:58:23,585 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10500\n","[INFO|configuration_utils.py:441] 2022-04-07 21:58:23,591 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 21:58:25,000 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 21:58:25,005 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 21:58:25,010 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-10500/special_tokens_map.json\n","{'loss': 0.9093, 'learning_rate': 6.519607843137256e-06, 'epoch': 1.35}\n"," 67% 11000/16320 [2:42:17<1:17:39,  1.14it/s][INFO|trainer.py:2166] 2022-04-07 22:05:47,372 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11000\n","[INFO|configuration_utils.py:441] 2022-04-07 22:05:47,378 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 22:05:48,760 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 22:05:48,764 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 22:05:48,769 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11000/special_tokens_map.json\n","{'loss': 0.9102, 'learning_rate': 5.90686274509804e-06, 'epoch': 1.41}\n"," 70% 11500/16320 [2:49:41<1:10:08,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 22:13:11,842 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11500\n","[INFO|configuration_utils.py:441] 2022-04-07 22:13:11,848 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 22:13:13,239 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 22:13:13,244 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 22:13:13,247 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-11500/special_tokens_map.json\n","{'loss': 0.8926, 'learning_rate': 5.294117647058824e-06, 'epoch': 1.47}\n"," 74% 12000/16320 [2:57:06<1:02:52,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 22:20:36,165 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12000\n","[INFO|configuration_utils.py:441] 2022-04-07 22:20:36,171 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 22:20:37,560 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 22:20:37,566 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 22:20:37,570 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12000/special_tokens_map.json\n","{'loss': 0.8876, 'learning_rate': 4.681372549019608e-06, 'epoch': 1.53}\n"," 77% 12500/16320 [3:04:30<55:26,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 22:28:00,252 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12500\n","[INFO|configuration_utils.py:441] 2022-04-07 22:28:00,258 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 22:28:01,676 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 22:28:01,681 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 22:28:01,685 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-12500/special_tokens_map.json\n","{'loss': 0.8924, 'learning_rate': 4.068627450980392e-06, 'epoch': 1.59}\n"," 80% 13000/16320 [3:11:54<48:14,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 22:35:24,731 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13000\n","[INFO|configuration_utils.py:441] 2022-04-07 22:35:24,736 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 22:35:26,116 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 22:35:26,122 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 22:35:26,126 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13000/special_tokens_map.json\n","{'loss': 0.8905, 'learning_rate': 3.4558823529411766e-06, 'epoch': 1.65}\n"," 83% 13500/16320 [3:19:19<41:03,  1.14it/s][INFO|trainer.py:2166] 2022-04-07 22:42:49,015 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13500\n","[INFO|configuration_utils.py:441] 2022-04-07 22:42:49,021 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 22:42:50,452 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 22:42:50,458 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 22:42:50,463 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-13500/special_tokens_map.json\n","{'loss': 0.8775, 'learning_rate': 2.843137254901961e-06, 'epoch': 1.72}\n"," 86% 14000/16320 [3:26:43<33:42,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 22:50:13,241 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14000\n","[INFO|configuration_utils.py:441] 2022-04-07 22:50:13,248 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 22:50:14,654 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 22:50:14,659 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 22:50:14,755 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14000/special_tokens_map.json\n","{'loss': 0.8889, 'learning_rate': 2.2303921568627456e-06, 'epoch': 1.78}\n"," 89% 14500/16320 [3:34:07<26:27,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 22:57:37,675 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14500\n","[INFO|configuration_utils.py:441] 2022-04-07 22:57:37,682 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 22:57:39,090 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 22:57:39,097 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 22:57:39,102 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-14500/special_tokens_map.json\n","{'loss': 0.8755, 'learning_rate': 1.6176470588235297e-06, 'epoch': 1.84}\n"," 92% 15000/16320 [3:41:31<19:12,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 23:05:01,632 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15000\n","[INFO|configuration_utils.py:441] 2022-04-07 23:05:01,638 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 23:05:03,157 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 23:05:03,163 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 23:05:03,167 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15000/special_tokens_map.json\n","{'loss': 0.8901, 'learning_rate': 1.0049019607843138e-06, 'epoch': 1.9}\n"," 95% 15500/16320 [3:48:55<11:54,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 23:12:25,770 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15500\n","[INFO|configuration_utils.py:441] 2022-04-07 23:12:25,777 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 23:12:27,271 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 23:12:27,276 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 23:12:27,281 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-15500/special_tokens_map.json\n","{'loss': 0.8676, 'learning_rate': 3.921568627450981e-07, 'epoch': 1.96}\n"," 98% 16000/16320 [3:56:19<04:39,  1.15it/s][INFO|trainer.py:2166] 2022-04-07 23:19:49,260 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-16000\n","[INFO|configuration_utils.py:441] 2022-04-07 23:19:49,266 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-16000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 23:19:50,706 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-16000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 23:19:50,712 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-16000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 23:19:50,716 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/checkpoint-16000/special_tokens_map.json\n","100% 16320/16320 [4:01:04<00:00,  1.31it/s][INFO|trainer.py:1530] 2022-04-07 23:24:34,251 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 14464.3447, 'train_samples_per_second': 18.052, 'train_steps_per_second': 1.128, 'train_loss': 1.117690278969559, 'epoch': 2.0}\n","100% 16320/16320 [4:01:04<00:00,  1.13it/s]\n","[INFO|trainer.py:2166] 2022-04-07 23:24:34,255 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug\n","[INFO|configuration_utils.py:441] 2022-04-07 23:24:34,261 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 23:24:35,651 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 23:24:35,656 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 23:24:35,660 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =        2.0\n","  train_loss               =     1.1177\n","  train_runtime            = 4:01:04.34\n","  train_samples            =     130553\n","  train_samples_per_second =     18.052\n","  train_steps_per_second   =      1.128\n","04/07/2022 23:24:37 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:567] 2022-04-07 23:24:37,105 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:2416] 2022-04-07 23:24:37,108 >> ***** Running Evaluation *****\n","[INFO|trainer.py:2418] 2022-04-07 23:24:37,108 >>   Num examples = 11955\n","[INFO|trainer.py:2421] 2022-04-07 23:24:37,108 >>   Batch size = 8\n","100% 1494/1495 [03:53<00:00,  6.40it/s]04/07/2022 23:28:47 - INFO - utils_qa - Post-processing 11873 example predictions split into 11955 features.\n","\n","  0% 0/11873 [00:00<?, ?it/s]\u001b[A\n","  0% 32/11873 [00:00<00:37, 315.60it/s]\u001b[A\n","  1% 67/11873 [00:00<00:36, 326.79it/s]\u001b[A\n","  1% 102/11873 [00:00<00:35, 334.63it/s]\u001b[A\n","  1% 138/11873 [00:00<00:34, 342.52it/s]\u001b[A\n","  1% 175/11873 [00:00<00:33, 351.25it/s]\u001b[A\n","  2% 212/11873 [00:00<00:32, 355.93it/s]\u001b[A\n","  2% 249/11873 [00:00<00:32, 359.26it/s]\u001b[A\n","  2% 286/11873 [00:00<00:32, 361.76it/s]\u001b[A\n","  3% 323/11873 [00:00<00:32, 357.77it/s]\u001b[A\n","  3% 359/11873 [00:01<00:32, 354.60it/s]\u001b[A\n","  3% 395/11873 [00:01<00:32, 356.09it/s]\u001b[A\n","  4% 434/11873 [00:01<00:31, 364.48it/s]\u001b[A\n","  4% 471/11873 [00:01<00:31, 365.68it/s]\u001b[A\n","  4% 508/11873 [00:01<00:31, 363.99it/s]\u001b[A\n","  5% 545/11873 [00:01<00:31, 355.69it/s]\u001b[A\n","  5% 581/11873 [00:01<00:31, 356.39it/s]\u001b[A\n","  5% 620/11873 [00:01<00:30, 364.22it/s]\u001b[A\n","  6% 657/11873 [00:01<00:30, 364.01it/s]\u001b[A\n","  6% 694/11873 [00:01<00:30, 362.70it/s]\u001b[A\n","  6% 731/11873 [00:02<00:30, 362.25it/s]\u001b[A\n","  6% 768/11873 [00:02<00:31, 357.92it/s]\u001b[A\n","  7% 807/11873 [00:02<00:30, 366.05it/s]\u001b[A\n","  7% 845/11873 [00:02<00:29, 368.41it/s]\u001b[A\n","  7% 885/11873 [00:02<00:29, 376.76it/s]\u001b[A\n","  8% 923/11873 [00:02<00:29, 372.72it/s]\u001b[A\n","  8% 963/11873 [00:02<00:28, 378.56it/s]\u001b[A\n","  8% 1001/11873 [00:02<00:29, 366.16it/s]\u001b[A\n","  9% 1038/11873 [00:02<00:32, 332.91it/s]\u001b[A\n","  9% 1072/11873 [00:03<00:34, 313.90it/s]\u001b[A\n","  9% 1104/11873 [00:03<00:36, 298.97it/s]\u001b[A\n"," 10% 1135/11873 [00:03<00:37, 288.32it/s]\u001b[A\n"," 10% 1165/11873 [00:03<00:37, 282.75it/s]\u001b[A\n"," 10% 1194/11873 [00:03<00:38, 278.15it/s]\u001b[A\n"," 10% 1222/11873 [00:03<00:38, 277.00it/s]\u001b[A\n"," 11% 1250/11873 [00:03<00:38, 274.50it/s]\u001b[A\n"," 11% 1278/11873 [00:03<00:38, 272.32it/s]\u001b[A\n"," 11% 1306/11873 [00:03<00:39, 270.67it/s]\u001b[A\n"," 11% 1334/11873 [00:04<00:40, 260.77it/s]\u001b[A\n"," 11% 1361/11873 [00:04<00:39, 262.97it/s]\u001b[A\n"," 12% 1388/11873 [00:04<00:39, 264.05it/s]\u001b[A\n"," 12% 1416/11873 [00:04<00:38, 268.30it/s]\u001b[A\n"," 12% 1443/11873 [00:04<00:39, 264.33it/s]\u001b[A\n"," 12% 1470/11873 [00:04<00:39, 260.50it/s]\u001b[A\n"," 13% 1498/11873 [00:04<00:39, 264.53it/s]\u001b[A\n"," 13% 1526/11873 [00:04<00:38, 266.46it/s]\u001b[A\n"," 13% 1553/11873 [00:04<00:38, 267.25it/s]\u001b[A\n"," 13% 1580/11873 [00:04<00:39, 259.86it/s]\u001b[A\n"," 14% 1607/11873 [00:05<00:39, 262.65it/s]\u001b[A\n"," 14% 1634/11873 [00:05<00:39, 262.26it/s]\u001b[A\n"," 14% 1661/11873 [00:05<00:38, 263.00it/s]\u001b[A\n"," 14% 1688/11873 [00:05<00:39, 259.40it/s]\u001b[A\n"," 14% 1715/11873 [00:05<00:38, 260.54it/s]\u001b[A\n"," 15% 1743/11873 [00:05<00:38, 263.49it/s]\u001b[A\n"," 15% 1770/11873 [00:05<00:38, 263.07it/s]\u001b[A\n"," 15% 1797/11873 [00:05<00:38, 262.63it/s]\u001b[A\n"," 15% 1824/11873 [00:05<00:38, 262.07it/s]\u001b[A\n"," 16% 1852/11873 [00:05<00:37, 264.66it/s]\u001b[A\n"," 16% 1879/11873 [00:06<00:37, 266.01it/s]\u001b[A\n"," 16% 1906/11873 [00:06<00:37, 264.48it/s]\u001b[A\n"," 16% 1933/11873 [00:06<00:37, 265.49it/s]\u001b[A\n"," 17% 1960/11873 [00:06<00:37, 266.23it/s]\u001b[A\n"," 17% 1988/11873 [00:06<00:36, 267.93it/s]\u001b[A\n"," 17% 2016/11873 [00:06<00:36, 268.92it/s]\u001b[A\n"," 17% 2043/11873 [00:06<00:36, 269.07it/s]\u001b[A\n"," 17% 2070/11873 [00:06<00:36, 268.93it/s]\u001b[A\n"," 18% 2098/11873 [00:06<00:36, 269.79it/s]\u001b[A\n"," 18% 2125/11873 [00:07<00:36, 267.52it/s]\u001b[A\n"," 18% 2153/11873 [00:07<00:35, 270.56it/s]\u001b[A\n"," 18% 2181/11873 [00:07<00:36, 268.55it/s]\u001b[A\n"," 19% 2208/11873 [00:07<00:36, 267.57it/s]\u001b[A\n"," 19% 2236/11873 [00:07<00:35, 268.44it/s]\u001b[A\n"," 19% 2263/11873 [00:07<00:35, 267.27it/s]\u001b[A\n"," 19% 2290/11873 [00:07<00:35, 266.77it/s]\u001b[A\n"," 20% 2317/11873 [00:07<00:35, 266.12it/s]\u001b[A\n"," 20% 2344/11873 [00:07<00:35, 265.84it/s]\u001b[A\n"," 20% 2372/11873 [00:07<00:35, 267.26it/s]\u001b[A\n"," 20% 2399/11873 [00:08<00:35, 265.43it/s]\u001b[A\n"," 20% 2426/11873 [00:08<00:35, 263.70it/s]\u001b[A\n"," 21% 2453/11873 [00:08<00:35, 262.48it/s]\u001b[A\n"," 21% 2480/11873 [00:08<00:35, 262.59it/s]\u001b[A\n"," 21% 2507/11873 [00:08<00:35, 264.28it/s]\u001b[A\n"," 21% 2534/11873 [00:08<00:35, 265.82it/s]\u001b[A\n"," 22% 2562/11873 [00:08<00:34, 267.64it/s]\u001b[A\n"," 22% 2589/11873 [00:08<00:34, 267.61it/s]\u001b[A\n"," 22% 2617/11873 [00:08<00:34, 268.50it/s]\u001b[A\n"," 22% 2644/11873 [00:08<00:34, 268.26it/s]\u001b[A\n"," 22% 2671/11873 [00:09<00:34, 268.37it/s]\u001b[A\n"," 23% 2698/11873 [00:09<00:34, 268.59it/s]\u001b[A\n"," 23% 2725/11873 [00:09<00:34, 267.98it/s]\u001b[A\n"," 23% 2752/11873 [00:09<00:34, 265.45it/s]\u001b[A\n"," 23% 2779/11873 [00:09<00:34, 262.73it/s]\u001b[A\n"," 24% 2807/11873 [00:09<00:34, 265.22it/s]\u001b[A\n"," 24% 2834/11873 [00:09<00:33, 266.02it/s]\u001b[A\n"," 24% 2862/11873 [00:09<00:33, 267.89it/s]\u001b[A\n"," 24% 2889/11873 [00:09<00:33, 264.82it/s]\u001b[A\n"," 25% 2916/11873 [00:09<00:33, 265.23it/s]\u001b[A\n"," 25% 2943/11873 [00:10<00:33, 264.97it/s]\u001b[A\n"," 25% 2971/11873 [00:10<00:33, 267.08it/s]\u001b[A\n"," 25% 2998/11873 [00:10<00:33, 262.29it/s]\u001b[A\n"," 25% 3025/11873 [00:10<00:34, 259.48it/s]\u001b[A\n"," 26% 3051/11873 [00:10<00:34, 256.71it/s]\u001b[A\n"," 26% 3077/11873 [00:10<00:34, 255.35it/s]\u001b[A\n"," 26% 3103/11873 [00:10<00:34, 251.31it/s]\u001b[A\n"," 26% 3129/11873 [00:10<00:38, 226.37it/s]\u001b[A\n"," 27% 3153/11873 [00:10<00:39, 222.55it/s]\u001b[A\n"," 27% 3176/11873 [00:11<00:40, 216.79it/s]\u001b[A\n"," 27% 3203/11873 [00:11<00:37, 228.76it/s]\u001b[A\n"," 27% 3230/11873 [00:11<00:36, 238.66it/s]\u001b[A\n"," 27% 3257/11873 [00:11<00:35, 245.14it/s]\u001b[A\n"," 28% 3282/11873 [00:11<00:37, 226.75it/s]\u001b[A\n"," 28% 3306/11873 [00:11<00:41, 206.97it/s]\u001b[A\n"," 28% 3328/11873 [00:11<00:43, 196.90it/s]\u001b[A\n"," 28% 3350/11873 [00:11<00:42, 202.07it/s]\u001b[A\n"," 28% 3371/11873 [00:12<00:46, 182.62it/s]\u001b[A\n"," 29% 3397/11873 [00:12<00:41, 202.08it/s]\u001b[A\n"," 29% 3425/11873 [00:12<00:38, 221.42it/s]\u001b[A\n"," 29% 3451/11873 [00:12<00:36, 231.26it/s]\u001b[A\n"," 29% 3478/11873 [00:12<00:34, 241.35it/s]\u001b[A\n"," 30% 3504/11873 [00:12<00:34, 245.37it/s]\u001b[A\n"," 30% 3531/11873 [00:12<00:33, 251.49it/s]\u001b[A\n"," 30% 3557/11873 [00:12<00:32, 252.02it/s]\u001b[A\n"," 30% 3585/11873 [00:12<00:32, 257.84it/s]\u001b[A\n"," 30% 3613/11873 [00:12<00:31, 261.62it/s]\u001b[A\n"," 31% 3640/11873 [00:13<00:31, 263.15it/s]\u001b[A\n"," 31% 3667/11873 [00:13<00:31, 260.42it/s]\u001b[A\n"," 31% 3694/11873 [00:13<00:32, 254.60it/s]\u001b[A\n"," 31% 3721/11873 [00:13<00:31, 257.08it/s]\u001b[A\n"," 32% 3748/11873 [00:13<00:31, 260.01it/s]\u001b[A\n"," 32% 3775/11873 [00:13<00:31, 258.52it/s]\u001b[A\n"," 32% 3802/11873 [00:13<00:30, 260.40it/s]\u001b[A\n"," 32% 3829/11873 [00:13<00:31, 258.65it/s]\u001b[A\n"," 32% 3856/11873 [00:13<00:30, 259.67it/s]\u001b[A\n"," 33% 3883/11873 [00:13<00:30, 261.38it/s]\u001b[A\n"," 33% 3910/11873 [00:14<00:30, 262.25it/s]\u001b[A\n"," 33% 3937/11873 [00:14<00:30, 256.03it/s]\u001b[A\n"," 33% 3963/11873 [00:14<00:30, 257.01it/s]\u001b[A\n"," 34% 3989/11873 [00:14<00:30, 257.65it/s]\u001b[A\n"," 34% 4016/11873 [00:14<00:30, 260.92it/s]\u001b[A\n"," 34% 4044/11873 [00:14<00:29, 265.83it/s]\u001b[A\n"," 34% 4071/11873 [00:14<00:29, 264.84it/s]\u001b[A\n"," 35% 4098/11873 [00:14<00:29, 263.39it/s]\u001b[A\n"," 35% 4125/11873 [00:14<00:29, 264.31it/s]\u001b[A\n"," 35% 4152/11873 [00:15<00:29, 259.90it/s]\u001b[A\n"," 35% 4179/11873 [00:15<00:29, 259.12it/s]\u001b[A\n"," 35% 4205/11873 [00:15<00:29, 258.02it/s]\u001b[A\n"," 36% 4232/11873 [00:15<00:29, 261.24it/s]\u001b[A\n"," 36% 4259/11873 [00:15<00:29, 261.43it/s]\u001b[A\n"," 36% 4287/11873 [00:15<00:28, 264.26it/s]\u001b[A\n"," 36% 4315/11873 [00:15<00:28, 266.57it/s]\u001b[A\n"," 37% 4342/11873 [00:15<00:28, 267.47it/s]\u001b[A\n"," 37% 4370/11873 [00:15<00:27, 268.76it/s]\u001b[A\n"," 37% 4397/11873 [00:15<00:28, 266.63it/s]\u001b[A\n"," 37% 4424/11873 [00:16<00:33, 220.46it/s]\u001b[A\n"," 37% 4452/11873 [00:16<00:31, 234.89it/s]\u001b[A\n"," 38% 4479/11873 [00:16<00:30, 244.27it/s]\u001b[A\n"," 38% 4506/11873 [00:16<00:29, 249.02it/s]\u001b[A\n"," 38% 4533/11873 [00:16<00:28, 254.90it/s]\u001b[A\n"," 38% 4559/11873 [00:16<00:28, 254.67it/s]\u001b[A\n"," 39% 4587/11873 [00:16<00:27, 260.95it/s]\u001b[A\n"," 39% 4615/11873 [00:16<00:27, 264.06it/s]\u001b[A\n"," 39% 4642/11873 [00:16<00:27, 264.72it/s]\u001b[A\n"," 39% 4669/11873 [00:17<00:27, 265.55it/s]\u001b[A\n"," 40% 4696/11873 [00:17<00:26, 266.75it/s]\u001b[A\n"," 40% 4723/11873 [00:17<00:27, 263.76it/s]\u001b[A\n"," 40% 4750/11873 [00:17<00:26, 265.54it/s]\u001b[A\n"," 40% 4777/11873 [00:17<00:26, 265.43it/s]\u001b[A\n"," 40% 4804/11873 [00:17<00:26, 262.39it/s]\u001b[A\n"," 41% 4831/11873 [00:17<00:26, 264.01it/s]\u001b[A\n"," 41% 4858/11873 [00:17<00:26, 262.50it/s]\u001b[A\n"," 41% 4886/11873 [00:17<00:26, 265.18it/s]\u001b[A\n"," 41% 4913/11873 [00:17<00:26, 265.18it/s]\u001b[A\n"," 42% 4941/11873 [00:18<00:25, 266.94it/s]\u001b[A\n"," 42% 4969/11873 [00:18<00:25, 268.22it/s]\u001b[A\n"," 42% 4996/11873 [00:18<00:25, 265.30it/s]\u001b[A\n"," 42% 5023/11873 [00:18<00:26, 260.78it/s]\u001b[A\n"," 43% 5050/11873 [00:18<00:26, 258.23it/s]\u001b[A\n"," 43% 5078/11873 [00:18<00:25, 261.85it/s]\u001b[A\n"," 43% 5106/11873 [00:18<00:25, 265.44it/s]\u001b[A\n"," 43% 5133/11873 [00:18<00:25, 263.07it/s]\u001b[A\n"," 43% 5160/11873 [00:18<00:25, 262.16it/s]\u001b[A\n"," 44% 5188/11873 [00:19<00:25, 264.61it/s]\u001b[A\n"," 44% 5215/11873 [00:19<00:25, 265.47it/s]\u001b[A\n"," 44% 5242/11873 [00:19<00:24, 265.86it/s]\u001b[A\n"," 44% 5269/11873 [00:19<00:25, 261.04it/s]\u001b[A\n"," 45% 5296/11873 [00:19<00:25, 262.29it/s]\u001b[A\n"," 45% 5324/11873 [00:19<00:24, 265.22it/s]\u001b[A\n"," 45% 5351/11873 [00:19<00:24, 264.74it/s]\u001b[A\n"," 45% 5379/11873 [00:19<00:24, 266.60it/s]\u001b[A\n"," 46% 5406/11873 [00:19<00:24, 265.73it/s]\u001b[A\n"," 46% 5433/11873 [00:19<00:24, 265.74it/s]\u001b[A\n"," 46% 5460/11873 [00:20<00:24, 264.10it/s]\u001b[A\n"," 46% 5487/11873 [00:20<00:24, 263.06it/s]\u001b[A\n"," 46% 5514/11873 [00:20<00:23, 265.02it/s]\u001b[A\n"," 47% 5541/11873 [00:20<00:23, 266.04it/s]\u001b[A\n"," 47% 5568/11873 [00:20<00:23, 264.88it/s]\u001b[A\n"," 47% 5595/11873 [00:20<00:23, 262.10it/s]\u001b[A\n"," 47% 5622/11873 [00:20<00:23, 261.53it/s]\u001b[A\n"," 48% 5649/11873 [00:20<00:24, 258.89it/s]\u001b[A\n"," 48% 5676/11873 [00:20<00:23, 260.22it/s]\u001b[A\n"," 48% 5703/11873 [00:20<00:23, 260.57it/s]\u001b[A\n"," 48% 5730/11873 [00:21<00:23, 262.55it/s]\u001b[A\n"," 48% 5757/11873 [00:21<00:23, 263.79it/s]\u001b[A\n"," 49% 5784/11873 [00:21<00:23, 262.05it/s]\u001b[A\n"," 49% 5812/11873 [00:21<00:22, 266.34it/s]\u001b[A\n"," 49% 5839/11873 [00:21<00:22, 266.19it/s]\u001b[A\n"," 49% 5866/11873 [00:21<00:22, 263.12it/s]\u001b[A\n"," 50% 5893/11873 [00:21<00:22, 263.77it/s]\u001b[A\n"," 50% 5920/11873 [00:21<00:22, 263.97it/s]\u001b[A\n"," 50% 5948/11873 [00:21<00:22, 265.93it/s]\u001b[A\n"," 50% 5975/11873 [00:21<00:22, 266.25it/s]\u001b[A\n"," 51% 6002/11873 [00:22<00:22, 264.81it/s]\u001b[A\n"," 51% 6029/11873 [00:22<00:22, 264.17it/s]\u001b[A\n"," 51% 6056/11873 [00:22<00:22, 264.03it/s]\u001b[A\n"," 51% 6083/11873 [00:22<00:21, 264.12it/s]\u001b[A\n"," 51% 6110/11873 [00:22<00:21, 263.52it/s]\u001b[A\n"," 52% 6137/11873 [00:22<00:21, 262.30it/s]\u001b[A\n"," 52% 6164/11873 [00:22<00:21, 261.84it/s]\u001b[A\n"," 52% 6192/11873 [00:22<00:21, 264.53it/s]\u001b[A\n"," 52% 6219/11873 [00:22<00:21, 264.77it/s]\u001b[A\n"," 53% 6247/11873 [00:23<00:21, 266.27it/s]\u001b[A\n"," 53% 6274/11873 [00:23<00:21, 264.82it/s]\u001b[A\n"," 53% 6302/11873 [00:23<00:20, 266.53it/s]\u001b[A\n"," 53% 6329/11873 [00:23<00:20, 264.35it/s]\u001b[A\n"," 54% 6356/11873 [00:23<00:20, 264.67it/s]\u001b[A\n"," 54% 6383/11873 [00:23<00:20, 262.09it/s]\u001b[A\n"," 54% 6410/11873 [00:23<00:20, 263.06it/s]\u001b[A\n"," 54% 6437/11873 [00:23<00:20, 263.23it/s]\u001b[A\n"," 54% 6464/11873 [00:23<00:20, 262.04it/s]\u001b[A\n"," 55% 6491/11873 [00:23<00:20, 257.85it/s]\u001b[A\n"," 55% 6517/11873 [00:24<00:20, 258.29it/s]\u001b[A\n"," 55% 6544/11873 [00:24<00:20, 258.83it/s]\u001b[A\n"," 55% 6570/11873 [00:24<00:20, 257.92it/s]\u001b[A\n"," 56% 6596/11873 [00:24<00:20, 257.84it/s]\u001b[A\n"," 56% 6623/11873 [00:24<00:20, 261.37it/s]\u001b[A\n"," 56% 6650/11873 [00:24<00:19, 262.18it/s]\u001b[A\n"," 56% 6677/11873 [00:24<00:19, 263.24it/s]\u001b[A\n"," 56% 6704/11873 [00:24<00:19, 261.74it/s]\u001b[A\n"," 57% 6731/11873 [00:24<00:19, 260.25it/s]\u001b[A\n"," 57% 6759/11873 [00:24<00:19, 263.44it/s]\u001b[A\n"," 57% 6786/11873 [00:25<00:19, 254.78it/s]\u001b[A\n"," 57% 6813/11873 [00:25<00:19, 257.49it/s]\u001b[A\n"," 58% 6840/11873 [00:25<00:19, 259.97it/s]\u001b[A\n"," 58% 6867/11873 [00:25<00:19, 260.09it/s]\u001b[A\n"," 58% 6894/11873 [00:25<00:19, 258.93it/s]\u001b[A\n"," 58% 6920/11873 [00:25<00:19, 255.29it/s]\u001b[A\n"," 59% 6947/11873 [00:25<00:19, 258.21it/s]\u001b[A\n"," 59% 6973/11873 [00:25<00:18, 258.72it/s]\u001b[A\n"," 59% 7001/11873 [00:25<00:18, 262.24it/s]\u001b[A\n"," 59% 7028/11873 [00:26<00:18, 262.85it/s]\u001b[A\n"," 59% 7055/11873 [00:26<00:18, 259.91it/s]\u001b[A\n"," 60% 7082/11873 [00:26<00:18, 262.43it/s]\u001b[A\n"," 60% 7109/11873 [00:26<00:18, 263.32it/s]\u001b[A\n"," 60% 7136/11873 [00:26<00:17, 264.37it/s]\u001b[A\n"," 60% 7164/11873 [00:26<00:17, 266.25it/s]\u001b[A\n"," 61% 7191/11873 [00:26<00:17, 266.52it/s]\u001b[A\n"," 61% 7218/11873 [00:26<00:17, 266.76it/s]\u001b[A\n"," 61% 7246/11873 [00:26<00:17, 267.90it/s]\u001b[A\n"," 61% 7273/11873 [00:26<00:17, 265.11it/s]\u001b[A\n"," 61% 7300/11873 [00:27<00:17, 265.19it/s]\u001b[A\n"," 62% 7327/11873 [00:27<00:17, 265.13it/s]\u001b[A\n"," 62% 7354/11873 [00:27<00:16, 266.05it/s]\u001b[A\n"," 62% 7381/11873 [00:27<00:16, 265.98it/s]\u001b[A\n"," 62% 7408/11873 [00:27<00:16, 264.51it/s]\u001b[A\n"," 63% 7435/11873 [00:27<00:17, 260.94it/s]\u001b[A\n"," 63% 7462/11873 [00:27<00:16, 263.19it/s]\u001b[A\n"," 63% 7489/11873 [00:27<00:16, 260.39it/s]\u001b[A\n"," 63% 7517/11873 [00:27<00:16, 264.60it/s]\u001b[A\n"," 64% 7544/11873 [00:27<00:16, 260.09it/s]\u001b[A\n"," 64% 7571/11873 [00:28<00:16, 262.58it/s]\u001b[A\n"," 64% 7598/11873 [00:28<00:16, 256.87it/s]\u001b[A\n"," 64% 7624/11873 [00:28<00:16, 255.74it/s]\u001b[A\n"," 64% 7651/11873 [00:28<00:16, 257.48it/s]\u001b[A\n"," 65% 7678/11873 [00:28<00:16, 259.72it/s]\u001b[A\n"," 65% 7704/11873 [00:28<00:16, 259.22it/s]\u001b[A\n"," 65% 7730/11873 [00:28<00:16, 258.34it/s]\u001b[A\n"," 65% 7756/11873 [00:28<00:16, 255.60it/s]\u001b[A\n"," 66% 7783/11873 [00:28<00:15, 258.38it/s]\u001b[A\n"," 66% 7810/11873 [00:28<00:15, 259.94it/s]\u001b[A\n"," 66% 7836/11873 [00:29<00:15, 259.28it/s]\u001b[A\n"," 66% 7862/11873 [00:29<00:15, 258.84it/s]\u001b[A\n"," 66% 7888/11873 [00:29<00:15, 257.12it/s]\u001b[A\n"," 67% 7915/11873 [00:29<00:15, 260.56it/s]\u001b[A\n"," 67% 7943/11873 [00:29<00:14, 263.64it/s]\u001b[A\n"," 67% 7970/11873 [00:29<00:14, 260.95it/s]\u001b[A\n"," 67% 7997/11873 [00:29<00:14, 263.21it/s]\u001b[A\n"," 68% 8025/11873 [00:29<00:14, 266.23it/s]\u001b[A\n"," 68% 8052/11873 [00:29<00:14, 266.04it/s]\u001b[A\n"," 68% 8080/11873 [00:30<00:14, 267.22it/s]\u001b[A\n"," 68% 8108/11873 [00:30<00:14, 268.08it/s]\u001b[A\n"," 69% 8135/11873 [00:30<00:14, 266.06it/s]\u001b[A\n"," 69% 8163/11873 [00:30<00:13, 267.46it/s]\u001b[A\n"," 69% 8190/11873 [00:30<00:14, 259.88it/s]\u001b[A\n"," 69% 8217/11873 [00:30<00:14, 257.45it/s]\u001b[A\n"," 69% 8244/11873 [00:30<00:13, 260.00it/s]\u001b[A\n"," 70% 8272/11873 [00:30<00:13, 264.02it/s]\u001b[A\n"," 70% 8299/11873 [00:30<00:13, 263.79it/s]\u001b[A\n"," 70% 8326/11873 [00:30<00:13, 260.92it/s]\u001b[A\n"," 70% 8353/11873 [00:31<00:13, 260.63it/s]\u001b[A\n"," 71% 8380/11873 [00:31<00:13, 262.49it/s]\u001b[A\n"," 71% 8407/11873 [00:31<00:13, 263.33it/s]\u001b[A\n"," 71% 8434/11873 [00:31<00:13, 261.67it/s]\u001b[A\n"," 71% 8461/11873 [00:31<00:13, 259.03it/s]\u001b[A\n"," 71% 8487/11873 [00:31<00:13, 258.81it/s]\u001b[A\n"," 72% 8515/11873 [00:31<00:12, 263.21it/s]\u001b[A\n"," 72% 8542/11873 [00:31<00:12, 263.78it/s]\u001b[A\n"," 72% 8569/11873 [00:31<00:12, 259.24it/s]\u001b[A\n"," 72% 8596/11873 [00:32<00:19, 168.46it/s]\u001b[A\n"," 73% 8621/11873 [00:32<00:17, 185.17it/s]\u001b[A\n"," 73% 8648/11873 [00:32<00:15, 204.57it/s]\u001b[A\n"," 73% 8675/11873 [00:32<00:14, 218.83it/s]\u001b[A\n"," 73% 8703/11873 [00:32<00:13, 232.76it/s]\u001b[A\n"," 74% 8731/11873 [00:32<00:12, 244.20it/s]\u001b[A\n"," 74% 8758/11873 [00:32<00:12, 251.27it/s]\u001b[A\n"," 74% 8785/11873 [00:32<00:12, 255.17it/s]\u001b[A\n"," 74% 8812/11873 [00:32<00:11, 257.43it/s]\u001b[A\n"," 74% 8839/11873 [00:33<00:11, 259.42it/s]\u001b[A\n"," 75% 8867/11873 [00:33<00:11, 262.77it/s]\u001b[A\n"," 75% 8894/11873 [00:33<00:11, 261.13it/s]\u001b[A\n"," 75% 8921/11873 [00:33<00:11, 263.43it/s]\u001b[A\n"," 75% 8948/11873 [00:33<00:11, 258.32it/s]\u001b[A\n"," 76% 8976/11873 [00:33<00:11, 262.35it/s]\u001b[A\n"," 76% 9004/11873 [00:33<00:10, 266.69it/s]\u001b[A\n"," 76% 9031/11873 [00:33<00:10, 263.55it/s]\u001b[A\n"," 76% 9058/11873 [00:33<00:10, 264.88it/s]\u001b[A\n"," 77% 9085/11873 [00:34<00:10, 260.66it/s]\u001b[A\n"," 77% 9112/11873 [00:34<00:10, 260.64it/s]\u001b[A\n"," 77% 9139/11873 [00:34<00:10, 260.63it/s]\u001b[A\n"," 77% 9166/11873 [00:34<00:10, 261.85it/s]\u001b[A\n"," 77% 9193/11873 [00:34<00:10, 263.49it/s]\u001b[A\n"," 78% 9220/11873 [00:34<00:10, 264.32it/s]\u001b[A\n"," 78% 9247/11873 [00:34<00:09, 262.90it/s]\u001b[A\n"," 78% 9274/11873 [00:34<00:09, 264.74it/s]\u001b[A\n"," 78% 9301/11873 [00:34<00:09, 264.19it/s]\u001b[A\n"," 79% 9328/11873 [00:34<00:09, 264.32it/s]\u001b[A\n"," 79% 9355/11873 [00:35<00:09, 264.34it/s]\u001b[A\n"," 79% 9382/11873 [00:35<00:09, 264.06it/s]\u001b[A\n"," 79% 9409/11873 [00:35<00:09, 264.26it/s]\u001b[A\n"," 79% 9436/11873 [00:35<00:09, 264.47it/s]\u001b[A\n"," 80% 9463/11873 [00:35<00:09, 265.37it/s]\u001b[A\n"," 80% 9490/11873 [00:35<00:08, 264.85it/s]\u001b[A\n"," 80% 9518/11873 [00:35<00:08, 266.42it/s]\u001b[A\n"," 80% 9545/11873 [00:35<00:08, 265.95it/s]\u001b[A\n"," 81% 9572/11873 [00:35<00:08, 263.33it/s]\u001b[A\n"," 81% 9599/11873 [00:35<00:08, 264.86it/s]\u001b[A\n"," 81% 9626/11873 [00:36<00:08, 264.92it/s]\u001b[A\n"," 81% 9653/11873 [00:36<00:08, 264.63it/s]\u001b[A\n"," 82% 9680/11873 [00:36<00:08, 261.90it/s]\u001b[A\n"," 82% 9708/11873 [00:36<00:08, 266.64it/s]\u001b[A\n"," 82% 9735/11873 [00:36<00:08, 266.24it/s]\u001b[A\n"," 82% 9763/11873 [00:36<00:07, 267.52it/s]\u001b[A\n"," 82% 9790/11873 [00:36<00:07, 266.64it/s]\u001b[A\n"," 83% 9817/11873 [00:36<00:07, 266.20it/s]\u001b[A\n"," 83% 9845/11873 [00:36<00:07, 267.70it/s]\u001b[A\n"," 83% 9872/11873 [00:37<00:07, 267.17it/s]\u001b[A\n"," 83% 9899/11873 [00:37<00:07, 267.43it/s]\u001b[A\n"," 84% 9926/11873 [00:37<00:07, 268.13it/s]\u001b[A\n"," 84% 9954/11873 [00:37<00:07, 268.29it/s]\u001b[A\n"," 84% 9981/11873 [00:37<00:07, 263.38it/s]\u001b[A\n"," 84% 10009/11873 [00:37<00:07, 265.62it/s]\u001b[A\n"," 85% 10036/11873 [00:37<00:06, 266.78it/s]\u001b[A\n"," 85% 10064/11873 [00:37<00:06, 269.09it/s]\u001b[A\n"," 85% 10092/11873 [00:37<00:06, 270.90it/s]\u001b[A\n"," 85% 10120/11873 [00:37<00:06, 271.03it/s]\u001b[A\n"," 85% 10148/11873 [00:38<00:06, 270.92it/s]\u001b[A\n"," 86% 10176/11873 [00:38<00:06, 271.71it/s]\u001b[A\n"," 86% 10204/11873 [00:38<00:06, 268.18it/s]\u001b[A\n"," 86% 10231/11873 [00:38<00:06, 267.61it/s]\u001b[A\n"," 86% 10258/11873 [00:38<00:06, 267.98it/s]\u001b[A\n"," 87% 10285/11873 [00:38<00:06, 262.58it/s]\u001b[A\n"," 87% 10312/11873 [00:38<00:05, 260.88it/s]\u001b[A\n"," 87% 10340/11873 [00:38<00:05, 264.99it/s]\u001b[A\n"," 87% 10367/11873 [00:38<00:05, 265.61it/s]\u001b[A\n"," 88% 10394/11873 [00:38<00:05, 266.57it/s]\u001b[A\n"," 88% 10421/11873 [00:39<00:05, 265.08it/s]\u001b[A\n"," 88% 10448/11873 [00:39<00:05, 264.91it/s]\u001b[A\n"," 88% 10475/11873 [00:39<00:05, 262.86it/s]\u001b[A\n"," 88% 10503/11873 [00:39<00:05, 265.17it/s]\u001b[A\n"," 89% 10530/11873 [00:39<00:05, 265.17it/s]\u001b[A\n"," 89% 10557/11873 [00:39<00:04, 264.44it/s]\u001b[A\n"," 89% 10584/11873 [00:39<00:04, 264.17it/s]\u001b[A\n"," 89% 10612/11873 [00:39<00:04, 266.67it/s]\u001b[A\n"," 90% 10639/11873 [00:39<00:04, 263.55it/s]\u001b[A\n"," 90% 10666/11873 [00:39<00:04, 263.69it/s]\u001b[A\n"," 90% 10693/11873 [00:40<00:04, 264.89it/s]\u001b[A\n"," 90% 10720/11873 [00:40<00:04, 264.63it/s]\u001b[A\n"," 91% 10747/11873 [00:40<00:04, 265.46it/s]\u001b[A\n"," 91% 10774/11873 [00:40<00:04, 265.30it/s]\u001b[A\n"," 91% 10801/11873 [00:40<00:04, 265.73it/s]\u001b[A\n"," 91% 10828/11873 [00:40<00:03, 264.36it/s]\u001b[A\n"," 91% 10855/11873 [00:40<00:03, 265.08it/s]\u001b[A\n"," 92% 10882/11873 [00:40<00:03, 263.86it/s]\u001b[A\n"," 92% 10909/11873 [00:40<00:03, 263.13it/s]\u001b[A\n"," 92% 10936/11873 [00:41<00:03, 257.92it/s]\u001b[A\n"," 92% 10963/11873 [00:41<00:03, 260.97it/s]\u001b[A\n"," 93% 10990/11873 [00:41<00:03, 262.20it/s]\u001b[A\n"," 93% 11017/11873 [00:41<00:03, 260.38it/s]\u001b[A\n"," 93% 11045/11873 [00:41<00:03, 263.33it/s]\u001b[A\n"," 93% 11072/11873 [00:41<00:03, 264.90it/s]\u001b[A\n"," 93% 11099/11873 [00:41<00:02, 266.34it/s]\u001b[A\n"," 94% 11126/11873 [00:41<00:02, 265.78it/s]\u001b[A\n"," 94% 11154/11873 [00:41<00:02, 267.97it/s]\u001b[A\n"," 94% 11182/11873 [00:41<00:02, 268.73it/s]\u001b[A\n"," 94% 11209/11873 [00:42<00:02, 268.06it/s]\u001b[A\n"," 95% 11236/11873 [00:42<00:02, 265.96it/s]\u001b[A\n"," 95% 11263/11873 [00:42<00:02, 259.67it/s]\u001b[A\n"," 95% 11291/11873 [00:42<00:02, 262.98it/s]\u001b[A\n"," 95% 11319/11873 [00:42<00:02, 265.49it/s]\u001b[A\n"," 96% 11346/11873 [00:42<00:01, 266.40it/s]\u001b[A\n"," 96% 11373/11873 [00:42<00:01, 265.93it/s]\u001b[A\n"," 96% 11400/11873 [00:42<00:01, 264.71it/s]\u001b[A\n"," 96% 11427/11873 [00:42<00:01, 265.45it/s]\u001b[A\n"," 96% 11455/11873 [00:42<00:01, 267.31it/s]\u001b[A\n"," 97% 11482/11873 [00:43<00:01, 266.16it/s]\u001b[A\n"," 97% 11509/11873 [00:43<00:01, 267.05it/s]\u001b[A\n"," 97% 11536/11873 [00:43<00:01, 261.04it/s]\u001b[A\n"," 97% 11563/11873 [00:43<00:01, 260.76it/s]\u001b[A\n"," 98% 11591/11873 [00:43<00:01, 264.25it/s]\u001b[A\n"," 98% 11618/11873 [00:43<00:00, 263.93it/s]\u001b[A\n"," 98% 11645/11873 [00:43<00:00, 265.02it/s]\u001b[A\n"," 98% 11672/11873 [00:43<00:00, 266.10it/s]\u001b[A\n"," 99% 11699/11873 [00:43<00:00, 264.90it/s]\u001b[A\n"," 99% 11726/11873 [00:43<00:00, 265.94it/s]\u001b[A\n"," 99% 11753/11873 [00:44<00:00, 266.76it/s]\u001b[A\n"," 99% 11780/11873 [00:44<00:00, 265.26it/s]\u001b[A\n"," 99% 11807/11873 [00:44<00:00, 264.61it/s]\u001b[A\n","100% 11835/11873 [00:44<00:00, 267.79it/s]\u001b[A\n","100% 11873/11873 [00:44<00:00, 266.55it/s]\n","04/07/2022 23:29:31 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/eval_predictions.json.\n","04/07/2022 23:29:31 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/eval_nbest_predictions.json.\n","04/07/2022 23:29:34 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-possible-aug/eval_null_odds.json.\n","04/07/2022 23:29:38 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n","100% 1495/1495 [05:01<00:00,  4.96it/s]\n","***** eval metrics *****\n","  epoch                  =     2.0\n","  eval_HasAns_exact      = 78.6437\n","  eval_HasAns_f1         = 84.6302\n","  eval_HasAns_total      =    5928\n","  eval_NoAns_exact       = 75.9966\n","  eval_NoAns_f1          = 75.9966\n","  eval_NoAns_total       =    5945\n","  eval_best_exact        = 77.3267\n","  eval_best_exact_thresh =     0.0\n","  eval_best_f1           = 80.3157\n","  eval_best_f1_thresh    =     0.0\n","  eval_exact             = 77.3183\n","  eval_f1                = 80.3072\n","  eval_samples           =   11955\n","  eval_total             =   11873\n","[INFO|modelcard.py:460] 2022-04-07 23:29:38,985 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'sichenzhong/squad_v2_back_trans_synonym_possib_aug', 'type': 'sichenzhong/squad_v2_back_trans_synonym_possib_aug', 'args': 'squad_v2'}}\n"]}]}]}