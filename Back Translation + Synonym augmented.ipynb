{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Back Translation + Synonym augmented.ipynb","provenance":[],"machine_shape":"hm","collapsed_sections":[],"background_execution":"on","mount_file_id":"19A1YW3qO1kEtfTevIN5SyKr_KDqStelv","authorship_tag":"ABX9TyNqail6S+9N83xdlyoh5ql2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"125a1c3b34db4332a28fb5e89585cb71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d96ca07f7ea415fb4b24468f025cab8","IPY_MODEL_6f299e5f70464caba93812bcada928e2","IPY_MODEL_298d3059d080448f97db5c03c6867eba"],"layout":"IPY_MODEL_aac6511fe6ea42afa5d53cb90988a040"}},"2d96ca07f7ea415fb4b24468f025cab8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_738caa95382246b38946ca650e41b6cf","placeholder":"​","style":"IPY_MODEL_02111b6c2ae9464f98ebbd17d828ecaa","value":"Downloading data files: 100%"}},"6f299e5f70464caba93812bcada928e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7047455cedd149beb581cc402ef87ad4","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55811a6df47e43b1ad52f1398fe6dfdd","value":2}},"298d3059d080448f97db5c03c6867eba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab614f94fe53436e8b26ea6af37297d6","placeholder":"​","style":"IPY_MODEL_7ab140e9477e40ffb91799c91b1ada76","value":" 2/2 [00:00&lt;00:00, 51.98it/s]"}},"aac6511fe6ea42afa5d53cb90988a040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"738caa95382246b38946ca650e41b6cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02111b6c2ae9464f98ebbd17d828ecaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7047455cedd149beb581cc402ef87ad4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55811a6df47e43b1ad52f1398fe6dfdd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ab614f94fe53436e8b26ea6af37297d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ab140e9477e40ffb91799c91b1ada76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b02f2c1b279a4f5280b8ad16ea562bb4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_701d8d9f92ed48e5ab9acbb9452510fa","IPY_MODEL_79d0073a63d64c639fbbe2e2cd71e8d4","IPY_MODEL_ae9a26e164ad40e99d1dea5d203c9d32"],"layout":"IPY_MODEL_a8515e1f342a49f78b34424dbcca1e97"}},"701d8d9f92ed48e5ab9acbb9452510fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67dc9eea4715483ea22490b7de2cbbfa","placeholder":"​","style":"IPY_MODEL_0ffbedde9bc942729a70b993aea48ad5","value":"Extracting data files: 100%"}},"79d0073a63d64c639fbbe2e2cd71e8d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9052af6d48047e3b1fb3edebb39e972","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7d4892be8b394f69b72f9c184d99cba9","value":2}},"ae9a26e164ad40e99d1dea5d203c9d32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca88b9cc71de4b4bb324bdffa5b06ccb","placeholder":"​","style":"IPY_MODEL_9669bdda5d824a919def801a45be28a1","value":" 2/2 [00:00&lt;00:00, 48.05it/s]"}},"a8515e1f342a49f78b34424dbcca1e97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67dc9eea4715483ea22490b7de2cbbfa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ffbedde9bc942729a70b993aea48ad5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9052af6d48047e3b1fb3edebb39e972":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d4892be8b394f69b72f9c184d99cba9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca88b9cc71de4b4bb324bdffa5b06ccb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9669bdda5d824a919def801a45be28a1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"568dbd49c6944e5aab7446d5102dc14e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_780bdbc7cf9e4d2f85a8090fd0ec7f9b","IPY_MODEL_350d1be3131a4168aba758b279ed1db4","IPY_MODEL_1743a65a15db4d13b3dd19c2cc3041dd"],"layout":"IPY_MODEL_2bb2e61b4c9c4bcea095ce9cef8c4e56"}},"780bdbc7cf9e4d2f85a8090fd0ec7f9b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d131cd0d01674eadbdbb0ea50ebfbfc4","placeholder":"​","style":"IPY_MODEL_778fa897f6bb4b74aa53d84800012ba8","value":"Generating train split: "}},"350d1be3131a4168aba758b279ed1db4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d9e7d05ebc74cd59bca676a273e33e8","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2688d533371a40038ac117a007a74c3c","value":1}},"1743a65a15db4d13b3dd19c2cc3041dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d11d582739404d0eba003a1b22cc7ae5","placeholder":"​","style":"IPY_MODEL_f9d5df8582b3476e89147cf6fedf2f8f","value":" 129297/0 [00:09&lt;00:00, 14948.24 examples/s]"}},"2bb2e61b4c9c4bcea095ce9cef8c4e56":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d131cd0d01674eadbdbb0ea50ebfbfc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"778fa897f6bb4b74aa53d84800012ba8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d9e7d05ebc74cd59bca676a273e33e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2688d533371a40038ac117a007a74c3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d11d582739404d0eba003a1b22cc7ae5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9d5df8582b3476e89147cf6fedf2f8f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e85e2212b78c4f36a6ff42d57be27665":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_745919b33fcb41ef8e3d12fdb06dac12","IPY_MODEL_6baeec3ad7ac4350af4029f8ed17219d","IPY_MODEL_20fe30c137134efca5d88736460df368"],"layout":"IPY_MODEL_c36afc82914642e39cc4ed99c591fed3"}},"745919b33fcb41ef8e3d12fdb06dac12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f44c90c70eba445789bc551d698f742f","placeholder":"​","style":"IPY_MODEL_8241a2ad3e104a42ae8a24287551c64c","value":"Generating validation split: "}},"6baeec3ad7ac4350af4029f8ed17219d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"info","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f59ed29e8fd4ccda0352a69b9a91473","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6b0cd6c7a52c4c3581dc4b5b899574d2","value":1}},"20fe30c137134efca5d88736460df368":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49eb4518b9d244218ad18f4290289ee2","placeholder":"​","style":"IPY_MODEL_e512d8f7a27b473b9a55fa28d295e8a2","value":" 11859/0 [00:00&lt;00:00, 14263.02 examples/s]"}},"c36afc82914642e39cc4ed99c591fed3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f44c90c70eba445789bc551d698f742f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8241a2ad3e104a42ae8a24287551c64c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9f59ed29e8fd4ccda0352a69b9a91473":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"6b0cd6c7a52c4c3581dc4b5b899574d2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"49eb4518b9d244218ad18f4290289ee2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e512d8f7a27b473b9a55fa28d295e8a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"085888d96c9f439fa31b7ab7f2f16a42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4c2875811fe44bf2b7152b5783a36359","IPY_MODEL_76a6a7a9452d4e51a185fc3fd541a756","IPY_MODEL_d6f600a044da45ec828bbb0ef846bdf4"],"layout":"IPY_MODEL_77251236c50a4ffb897e1265c95a06f0"}},"4c2875811fe44bf2b7152b5783a36359":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f538d08ed314dc38d17a784a1a2e45a","placeholder":"​","style":"IPY_MODEL_3f2c468d76894b7aa8545d93cb38d6cf","value":"100%"}},"76a6a7a9452d4e51a185fc3fd541a756":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_faf654d4529d450bbb1e93ef50d55d4a","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d03e11b7182441878cfe99d1febccfa0","value":2}},"d6f600a044da45ec828bbb0ef846bdf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5b5a45651e049fdb4c252ab38a446f7","placeholder":"​","style":"IPY_MODEL_857dfb4d6cfc487b844bf312316059f5","value":" 2/2 [00:00&lt;00:00, 62.52it/s]"}},"77251236c50a4ffb897e1265c95a06f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f538d08ed314dc38d17a784a1a2e45a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f2c468d76894b7aa8545d93cb38d6cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"faf654d4529d450bbb1e93ef50d55d4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d03e11b7182441878cfe99d1febccfa0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5b5a45651e049fdb4c252ab38a446f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"857dfb4d6cfc487b844bf312316059f5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c44110abe4c94e7c95a110df9973be71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a33e720f61204cbea8bcec11ddb556f0","IPY_MODEL_01e52043cc34479896e483ce61c6d982","IPY_MODEL_41bc6c9bac7f4392871b18c41067c337"],"layout":"IPY_MODEL_bbca27a1000148d5910d7e9929cdb8c7"}},"a33e720f61204cbea8bcec11ddb556f0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f9f92c3a2864a26a032b151beadaaba","placeholder":"​","style":"IPY_MODEL_cbbb9031827e4f49848a153a84aa2db3","value":"Pushing dataset shards to the dataset hub: 100%"}},"01e52043cc34479896e483ce61c6d982":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_87911707db094ff3a39e091b62e6c151","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e9c36d43b614b0e8e46ad2ab8601c5b","value":1}},"41bc6c9bac7f4392871b18c41067c337":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c86b98df4d994cf9a28089c111d5c516","placeholder":"​","style":"IPY_MODEL_f0ff9f0d0eb24ee98929c6c1fa3dc89a","value":" 1/1 [00:05&lt;00:00,  5.89s/it]"}},"bbca27a1000148d5910d7e9929cdb8c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f9f92c3a2864a26a032b151beadaaba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbbb9031827e4f49848a153a84aa2db3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"87911707db094ff3a39e091b62e6c151":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e9c36d43b614b0e8e46ad2ab8601c5b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c86b98df4d994cf9a28089c111d5c516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0ff9f0d0eb24ee98929c6c1fa3dc89a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b4bf35a22614c2888cd3bc3e7085df2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_196116880d5e4f43a5c7f4e25e0e24ec","IPY_MODEL_6df0e81342e74ff2b1c14833be48f512","IPY_MODEL_65b8d2f335404a82841b13f307ecb493"],"layout":"IPY_MODEL_f9679f8b405e4c0fac93f4c0132581d7"}},"196116880d5e4f43a5c7f4e25e0e24ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_129e9e2c9e84436fb9aa627c0f69d762","placeholder":"​","style":"IPY_MODEL_e8aeeb96e76947f8bc78fb825e4d38a9","value":"Pushing dataset shards to the dataset hub: 100%"}},"6df0e81342e74ff2b1c14833be48f512":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2609ecaa0cf94b40808ac3dd4592814a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef9227097f1c4d37a428a9536200b1e7","value":1}},"65b8d2f335404a82841b13f307ecb493":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28d1336acc13446685a1ee92c7e3ed46","placeholder":"​","style":"IPY_MODEL_a583ffe8f5fa4f4fbb042733c2bf11dc","value":" 1/1 [00:01&lt;00:00,  1.96s/it]"}},"f9679f8b405e4c0fac93f4c0132581d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"129e9e2c9e84436fb9aa627c0f69d762":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8aeeb96e76947f8bc78fb825e4d38a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2609ecaa0cf94b40808ac3dd4592814a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef9227097f1c4d37a428a9536200b1e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28d1336acc13446685a1ee92c7e3ed46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a583ffe8f5fa4f4fbb042733c2bf11dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"70oLi9mZP6oK","executionInfo":{"status":"ok","timestamp":1649303622106,"user_tz":240,"elapsed":299,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"57d484d6-be76-4111-f3ba-094ccf160867"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Apr  7 03:53:41 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    25W / 300W |      0MiB / 16160MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","source":["!pip install datasets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fGqcN-zXTvvo","executionInfo":{"status":"ok","timestamp":1649303631802,"user_tz":240,"elapsed":8025,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"87275d60-6949-404c-8da2-a525ba615be8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n","\u001b[?25l\r\u001b[K     |█                               | 10 kB 36.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 42.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 51 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████                          | 61 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 71 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 81 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 92 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 102 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 112 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 122 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 133 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 143 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 153 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 163 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 174 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 184 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 194 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 204 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 215 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 225 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 235 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 245 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 256 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 266 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 276 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 286 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 296 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 307 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 317 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 325 kB 14.1 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 86.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Collecting huggingface-hub<1.0.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 7.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 83.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 74.0 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 71.8 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 66.7 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 74.6 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.0.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}]},{"cell_type":"code","source":["!pip install git+https://github.com/huggingface/transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tI_RBT1FSotu","outputId":"4479c5b9-8715-4c08-a4a7-a46c3274725b","executionInfo":{"status":"ok","timestamp":1649303656047,"user_tz":240,"elapsed":24250,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-69_sckel\n","  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-69_sckel\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 14.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.63.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (1.21.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 80.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (0.5.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 89.8 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2019.12.20)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0.dev0) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.0.dev0) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.0.dev0) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.15.0)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.19.0.dev0-py3-none-any.whl size=3965509 sha256=e43de73674cae807cd876f537852297b1c241c5a524eb08a2052bc107e3e9620\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_fcwjpnb/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n","Successfully built transformers\n","Installing collected packages: pyyaml, tokenizers, sacremoses, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.19.0.dev0\n"]}]},{"cell_type":"code","source":["import torch\n","import datetime\n","import json\n","import os\n","import time\n","import datasets\n","import pprint\n","import random\n","import string\n","import sys\n","import transformers\n","from datasets import load_dataset\n","from datasets.tasks import QuestionAnsweringExtractive"],"metadata":{"id":"DZ3Ma-pCRJDJ","executionInfo":{"status":"ok","timestamp":1649303664593,"user_tz":240,"elapsed":8553,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda:0' if torch.cuda.is_available()\n","                      else 'cpu')"],"metadata":{"id":"HNMUVyBpRGw8","executionInfo":{"status":"ok","timestamp":1649303664594,"user_tz":240,"elapsed":35,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/huggingface/transformers.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUVkgX-IQIiR","executionInfo":{"status":"ok","timestamp":1649303671930,"user_tz":240,"elapsed":7369,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"4516b6a5-c1c8-474e-f3da-6e97863c72ad"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 108786, done.\u001b[K\n","remote: Total 108786 (delta 0), reused 0 (delta 0), pack-reused 108786\u001b[K\n","Receiving objects: 100% (108786/108786), 95.43 MiB | 29.55 MiB/s, done.\n","Resolving deltas: 100% (79283/79283), done.\n"]}]},{"cell_type":"code","source":["dataset = load_dataset('/content/drive/MyDrive/QA/squad_v2_back_trans_synonym_aug.py')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":148,"referenced_widgets":["125a1c3b34db4332a28fb5e89585cb71","2d96ca07f7ea415fb4b24468f025cab8","6f299e5f70464caba93812bcada928e2","298d3059d080448f97db5c03c6867eba","aac6511fe6ea42afa5d53cb90988a040","738caa95382246b38946ca650e41b6cf","02111b6c2ae9464f98ebbd17d828ecaa","7047455cedd149beb581cc402ef87ad4","55811a6df47e43b1ad52f1398fe6dfdd","ab614f94fe53436e8b26ea6af37297d6","7ab140e9477e40ffb91799c91b1ada76","b02f2c1b279a4f5280b8ad16ea562bb4","701d8d9f92ed48e5ab9acbb9452510fa","79d0073a63d64c639fbbe2e2cd71e8d4","ae9a26e164ad40e99d1dea5d203c9d32","a8515e1f342a49f78b34424dbcca1e97","67dc9eea4715483ea22490b7de2cbbfa","0ffbedde9bc942729a70b993aea48ad5","f9052af6d48047e3b1fb3edebb39e972","7d4892be8b394f69b72f9c184d99cba9","ca88b9cc71de4b4bb324bdffa5b06ccb","9669bdda5d824a919def801a45be28a1","568dbd49c6944e5aab7446d5102dc14e","780bdbc7cf9e4d2f85a8090fd0ec7f9b","350d1be3131a4168aba758b279ed1db4","1743a65a15db4d13b3dd19c2cc3041dd","2bb2e61b4c9c4bcea095ce9cef8c4e56","d131cd0d01674eadbdbb0ea50ebfbfc4","778fa897f6bb4b74aa53d84800012ba8","6d9e7d05ebc74cd59bca676a273e33e8","2688d533371a40038ac117a007a74c3c","d11d582739404d0eba003a1b22cc7ae5","f9d5df8582b3476e89147cf6fedf2f8f","e85e2212b78c4f36a6ff42d57be27665","745919b33fcb41ef8e3d12fdb06dac12","6baeec3ad7ac4350af4029f8ed17219d","20fe30c137134efca5d88736460df368","c36afc82914642e39cc4ed99c591fed3","f44c90c70eba445789bc551d698f742f","8241a2ad3e104a42ae8a24287551c64c","9f59ed29e8fd4ccda0352a69b9a91473","6b0cd6c7a52c4c3581dc4b5b899574d2","49eb4518b9d244218ad18f4290289ee2","e512d8f7a27b473b9a55fa28d295e8a2","085888d96c9f439fa31b7ab7f2f16a42","4c2875811fe44bf2b7152b5783a36359","76a6a7a9452d4e51a185fc3fd541a756","d6f600a044da45ec828bbb0ef846bdf4","77251236c50a4ffb897e1265c95a06f0","2f538d08ed314dc38d17a784a1a2e45a","3f2c468d76894b7aa8545d93cb38d6cf","faf654d4529d450bbb1e93ef50d55d4a","d03e11b7182441878cfe99d1febccfa0","b5b5a45651e049fdb4c252ab38a446f7","857dfb4d6cfc487b844bf312316059f5"]},"id":"A2gdlPTvcmfL","executionInfo":{"status":"ok","timestamp":1648666146853,"user_tz":240,"elapsed":13322,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"4a1b4ac1-f751-43ca-bd83-c29399d2ccd3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading and preparing dataset squad_v2_aug/squad_v2 to /root/.cache/huggingface/datasets/squad_v2_aug/squad_v2/2.0.0/c2ad9a5c6baf431251b06f7407f8b7eacaabd1cb2c4ed9f7f47d41da62b4f413...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"125a1c3b34db4332a28fb5e89585cb71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b02f2c1b279a4f5280b8ad16ea562bb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"568dbd49c6944e5aab7446d5102dc14e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e85e2212b78c4f36a6ff42d57be27665"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset squad_v2_aug downloaded and prepared to /root/.cache/huggingface/datasets/squad_v2_aug/squad_v2/2.0.0/c2ad9a5c6baf431251b06f7407f8b7eacaabd1cb2c4ed9f7f47d41da62b4f413. Subsequent calls will reuse this data.\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"085888d96c9f439fa31b7ab7f2f16a42"}},"metadata":{}}]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ttpAfwxBWdR0","executionInfo":{"status":"ok","timestamp":1648666155414,"user_tz":240,"elapsed":8566,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"1144e7bc-42a4-46c1-8317-181bb12ba9ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/token.\n","        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n","        \n","Token: \n","Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}]},{"cell_type":"code","source":["dataset.push_to_hub(\"sichenzhong/squad_v2_back_trans_synonym_aug\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":150,"referenced_widgets":["c44110abe4c94e7c95a110df9973be71","a33e720f61204cbea8bcec11ddb556f0","01e52043cc34479896e483ce61c6d982","41bc6c9bac7f4392871b18c41067c337","bbca27a1000148d5910d7e9929cdb8c7","1f9f92c3a2864a26a032b151beadaaba","cbbb9031827e4f49848a153a84aa2db3","87911707db094ff3a39e091b62e6c151","4e9c36d43b614b0e8e46ad2ab8601c5b","c86b98df4d994cf9a28089c111d5c516","f0ff9f0d0eb24ee98929c6c1fa3dc89a","8b4bf35a22614c2888cd3bc3e7085df2","196116880d5e4f43a5c7f4e25e0e24ec","6df0e81342e74ff2b1c14833be48f512","65b8d2f335404a82841b13f307ecb493","f9679f8b405e4c0fac93f4c0132581d7","129e9e2c9e84436fb9aa627c0f69d762","e8aeeb96e76947f8bc78fb825e4d38a9","2609ecaa0cf94b40808ac3dd4592814a","ef9227097f1c4d37a428a9536200b1e7","28d1336acc13446685a1ee92c7e3ed46","a583ffe8f5fa4f4fbb042733c2bf11dc"]},"id":"WGAeWENJWR_F","executionInfo":{"status":"ok","timestamp":1648666167187,"user_tz":240,"elapsed":10653,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"3449bbe9-e8aa-4794-958e-f218c42e110b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Pushing split train to the Hub.\n","The repository already exists: the `private` keyword argument will be ignored.\n"]},{"output_type":"display_data","data":{"text/plain":["Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c44110abe4c94e7c95a110df9973be71"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Pushing split validation to the Hub.\n","The repository already exists: the `private` keyword argument will be ignored.\n"]},{"output_type":"display_data","data":{"text/plain":["Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b4bf35a22614c2888cd3bc3e7085df2"}},"metadata":{}}]},{"cell_type":"code","source":["%cd /content/transformers/examples/pytorch/question-answering/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5uLaizsXQrk9","executionInfo":{"status":"ok","timestamp":1649303671931,"user_tz":240,"elapsed":41,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"5f605060-ae76-4be2-d095-7c33f45c0a4c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/transformers/examples/pytorch/question-answering\n"]}]},{"cell_type":"code","source":["!python run_qa.py \\\n","  --model_name_or_path /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug \\\n","  --dataset_name sichenzhong/squad_v2_back_trans_synonym_aug \\\n","  --do_eval \\\n","  --version_2_with_negative \\\n","  --output_dir /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aI-ipSbaHqF6","outputId":"15b999e6-3a01-4c53-d367-7d9d09dff0bb","executionInfo":{"status":"ok","timestamp":1649303932297,"user_tz":240,"elapsed":260402,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["04/07/2022 03:54:35 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","04/07/2022 03:54:35 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=False,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.NO,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/runs/Apr07_03-54-35_e45f44865b23,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=3.0,\n","optim=OptimizerNames.ADAMW_HF,\n","output_dir=/content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=8,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","04/07/2022 03:54:37 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_aug/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpzl1m_hrq\n","Downloading: 100% 2.17k/2.17k [00:00<00:00, 1.86MB/s]\n","04/07/2022 03:54:37 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_aug/resolve/main/dataset_infos.json in cache at /root/.cache/huggingface/datasets/downloads/b19a7348f5a232453afb7de4bbd0a4a1ebd9494572c03f09cacad8bf05484ee6.3f1cc921477c4dcbeb75d4df8795f468077c74d2681f234e5711cbddb7e3b024\n","04/07/2022 03:54:37 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/b19a7348f5a232453afb7de4bbd0a4a1ebd9494572c03f09cacad8bf05484ee6.3f1cc921477c4dcbeb75d4df8795f468077c74d2681f234e5711cbddb7e3b024\n","04/07/2022 03:54:37 - WARNING - datasets.builder - Using custom data configuration sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178\n","04/07/2022 03:54:37 - INFO - datasets.builder - Generating dataset parquet (/root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n","Downloading and preparing dataset squad_v2_aug/squad_v2 (download: 19.96 MiB, generated: 123.83 MiB, post-processed: Unknown size, total: 143.78 MiB) to /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n","04/07/2022 03:54:37 - INFO - datasets.builder - Dataset not on Hf google storage. Downloading and preparing it from source\n","Downloading data files:   0% 0/2 [00:00<?, ?it/s]04/07/2022 03:54:38 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_aug/resolve/c454f213739940027cd5d895e3db162a3a3bb178/data/validation-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp12dvbtpd\n","\n","Downloading data:   0% 0.00/1.26M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   3% 36.9k/1.26M [00:00<00:05, 210kB/s]\u001b[A\n","Downloading data:  20% 246k/1.26M [00:00<00:01, 777kB/s] \u001b[A\n","Downloading data: 100% 1.26M/1.26M [00:00<00:00, 2.34MB/s]\n","04/07/2022 03:54:39 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_aug/resolve/c454f213739940027cd5d895e3db162a3a3bb178/data/validation-00000-of-00001.parquet in cache at /root/.cache/huggingface/datasets/downloads/2f841ea1e6cab5f37f36c7523d05abb9672a742de59d68c33570c9784a27dfe0\n","04/07/2022 03:54:39 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/2f841ea1e6cab5f37f36c7523d05abb9672a742de59d68c33570c9784a27dfe0\n","Downloading data files:  50% 1/2 [00:01<00:01,  1.92s/it]04/07/2022 03:54:40 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_aug/resolve/c454f213739940027cd5d895e3db162a3a3bb178/data/train-00000-of-00001.parquet not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpfvlbtbln\n","\n","Downloading data:   0% 0.00/19.7M [00:00<?, ?B/s]\u001b[A\n","Downloading data:   0% 52.2k/19.7M [00:00<01:06, 295kB/s]\u001b[A\n","Downloading data:   2% 296k/19.7M [00:00<00:20, 923kB/s] \u001b[A\n","Downloading data:   6% 1.19M/19.7M [00:00<00:05, 3.49MB/s]\u001b[A\n","Downloading data:  13% 2.48M/19.7M [00:00<00:03, 5.28MB/s]\u001b[A\n","Downloading data:  28% 5.41M/19.7M [00:00<00:01, 11.8MB/s]\u001b[A\n","Downloading data:  46% 9.01M/19.7M [00:00<00:00, 18.5MB/s]\u001b[A\n","Downloading data:  64% 12.6M/19.7M [00:00<00:00, 23.4MB/s]\u001b[A\n","Downloading data: 100% 19.7M/19.7M [00:01<00:00, 17.7MB/s]\n","04/07/2022 03:54:42 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/sichenzhong/squad_v2_back_trans_synonym_aug/resolve/c454f213739940027cd5d895e3db162a3a3bb178/data/train-00000-of-00001.parquet in cache at /root/.cache/huggingface/datasets/downloads/b60676e87cb0ae4aa32fbc5bb17674c139107ceeea183e828cffae9bbf0962c3\n","04/07/2022 03:54:42 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/b60676e87cb0ae4aa32fbc5bb17674c139107ceeea183e828cffae9bbf0962c3\n","Downloading data files: 100% 2/2 [00:04<00:00,  2.21s/it]\n","04/07/2022 03:54:42 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n","04/07/2022 03:54:42 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n","Extracting data files: 100% 2/2 [00:00<00:00, 1209.08it/s]\n","04/07/2022 03:54:42 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n","04/07/2022 03:54:42 - INFO - datasets.builder - Generating validation split\n","04/07/2022 03:54:42 - INFO - datasets.builder - Generating train split\n","04/07/2022 03:54:42 - INFO - datasets.utils.info_utils - All the splits matched successfully.\n","Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n","100% 2/2 [00:00<00:00, 289.31it/s]\n","[INFO|configuration_utils.py:652] 2022-04-07 03:54:43,436 >> loading configuration file /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/config.json\n","[INFO|configuration_utils.py:690] 2022-04-07 03:54:43,437 >> Model config BertConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug\",\n","  \"architectures\": [\n","    \"BertForQuestionAnswering\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","[INFO|tokenization_utils_base.py:1698] 2022-04-07 03:54:43,783 >> Didn't find file /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/added_tokens.json. We won't load it.\n","[INFO|tokenization_utils_base.py:1776] 2022-04-07 03:54:43,784 >> loading file /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/vocab.txt\n","[INFO|tokenization_utils_base.py:1776] 2022-04-07 03:54:43,784 >> loading file /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/tokenizer.json\n","[INFO|tokenization_utils_base.py:1776] 2022-04-07 03:54:43,784 >> loading file None\n","[INFO|tokenization_utils_base.py:1776] 2022-04-07 03:54:43,784 >> loading file /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:1776] 2022-04-07 03:54:43,784 >> loading file /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/tokenizer_config.json\n","[INFO|modeling_utils.py:1770] 2022-04-07 03:54:44,789 >> loading weights file /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/pytorch_model.bin\n","[INFO|modeling_utils.py:2057] 2022-04-07 03:54:50,374 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n","\n","[INFO|modeling_utils.py:2066] 2022-04-07 03:54:50,374 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n","Running tokenizer on validation dataset:   0% 0/12 [00:00<?, ?ba/s]04/07/2022 03:54:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-908a8488b70fc336.arrow\n","Running tokenizer on validation dataset: 100% 12/12 [01:09<00:00,  5.79s/ba]\n","04/07/2022 03:56:00 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/2.0.0/metrics/squad_v2/squad_v2.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpjs6ky5lo\n","Downloading builder script: 6.46kB [00:00, 5.51MB/s]       \n","04/07/2022 03:56:00 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/2.0.0/metrics/squad_v2/squad_v2.py in cache at /root/.cache/huggingface/datasets/downloads/28e260e79373763d7435864d09ebeccbfa7b9903d7901d5283b0d6b7265e34c7.20ffda40aa962d94515737edbb5a7eda5c13e771416809a70e82ce2aee1820fd.py\n","04/07/2022 03:56:00 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/28e260e79373763d7435864d09ebeccbfa7b9903d7901d5283b0d6b7265e34c7.20ffda40aa962d94515737edbb5a7eda5c13e771416809a70e82ce2aee1820fd.py\n","04/07/2022 03:56:00 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/2.0.0/metrics/squad_v2/evaluate.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmproqbjly3\n","Downloading extra modules: 11.3kB [00:00, 9.98MB/s]       \n","04/07/2022 03:56:00 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/2.0.0/metrics/squad_v2/evaluate.py in cache at /root/.cache/huggingface/datasets/downloads/a1b3f17173d6daeea11b56052a09e38922a52847495c5c51da69b6024f7bc6c5.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n","04/07/2022 03:56:00 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/a1b3f17173d6daeea11b56052a09e38922a52847495c5c51da69b6024f7bc6c5.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n","04/07/2022 03:56:13 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:567] 2022-04-07 03:56:13,514 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `BertForQuestionAnswering.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:2416] 2022-04-07 03:56:13,516 >> ***** Running Evaluation *****\n","[INFO|trainer.py:2418] 2022-04-07 03:56:13,516 >>   Num examples = 12199\n","[INFO|trainer.py:2421] 2022-04-07 03:56:13,516 >>   Batch size = 8\n","100% 1524/1525 [01:37<00:00, 15.64it/s]04/07/2022 03:58:04 - INFO - utils_qa - Post-processing 11873 example predictions split into 12199 features.\n","\n","  0% 0/11873 [00:00<?, ?it/s]\u001b[A\n","  0% 38/11873 [00:00<00:31, 372.15it/s]\u001b[A\n","  1% 76/11873 [00:00<00:34, 345.16it/s]\u001b[A\n","  1% 115/11873 [00:00<00:32, 361.01it/s]\u001b[A\n","  1% 156/11873 [00:00<00:31, 377.54it/s]\u001b[A\n","  2% 198/11873 [00:00<00:29, 392.05it/s]\u001b[A\n","  2% 238/11873 [00:00<00:29, 393.51it/s]\u001b[A\n","  2% 279/11873 [00:00<00:29, 397.00it/s]\u001b[A\n","  3% 319/11873 [00:00<00:29, 394.62it/s]\u001b[A\n","  3% 359/11873 [00:00<00:29, 391.26it/s]\u001b[A\n","  3% 399/11873 [00:01<00:29, 390.90it/s]\u001b[A\n","  4% 442/11873 [00:01<00:28, 400.46it/s]\u001b[A\n","  4% 483/11873 [00:01<00:28, 398.76it/s]\u001b[A\n","  4% 523/11873 [00:01<00:28, 394.98it/s]\u001b[A\n","  5% 563/11873 [00:01<00:28, 393.96it/s]\u001b[A\n","  5% 603/11873 [00:01<00:28, 393.19it/s]\u001b[A\n","  5% 643/11873 [00:01<00:28, 393.04it/s]\u001b[A\n","  6% 683/11873 [00:01<00:28, 390.83it/s]\u001b[A\n","  6% 723/11873 [00:01<00:28, 385.90it/s]\u001b[A\n","  6% 763/11873 [00:01<00:28, 387.30it/s]\u001b[A\n","  7% 805/11873 [00:02<00:27, 396.67it/s]\u001b[A\n","  7% 846/11873 [00:02<00:27, 398.58it/s]\u001b[A\n","  7% 890/11873 [00:02<00:26, 408.08it/s]\u001b[A\n","  8% 931/11873 [00:02<00:26, 406.31it/s]\u001b[A\n","  8% 973/11873 [00:02<00:26, 410.29it/s]\u001b[A\n","  9% 1015/11873 [00:02<00:27, 394.97it/s]\u001b[A\n","  9% 1055/11873 [00:02<00:29, 367.89it/s]\u001b[A\n","  9% 1093/11873 [00:02<00:30, 351.63it/s]\u001b[A\n"," 10% 1129/11873 [00:02<00:31, 343.15it/s]\u001b[A\n"," 10% 1164/11873 [00:03<00:31, 336.82it/s]\u001b[A\n"," 10% 1198/11873 [00:03<00:31, 334.24it/s]\u001b[A\n"," 10% 1232/11873 [00:03<00:32, 329.27it/s]\u001b[A\n"," 11% 1265/11873 [00:03<00:32, 325.59it/s]\u001b[A\n"," 11% 1298/11873 [00:03<00:32, 321.23it/s]\u001b[A\n"," 11% 1332/11873 [00:03<00:32, 323.84it/s]\u001b[A\n"," 11% 1365/11873 [00:03<00:32, 323.83it/s]\u001b[A\n"," 12% 1398/11873 [00:03<00:32, 322.62it/s]\u001b[A\n"," 12% 1431/11873 [00:03<00:32, 322.13it/s]\u001b[A\n"," 12% 1464/11873 [00:03<00:32, 321.11it/s]\u001b[A\n"," 13% 1497/11873 [00:04<00:32, 322.35it/s]\u001b[A\n"," 13% 1530/11873 [00:04<00:32, 322.44it/s]\u001b[A\n"," 13% 1563/11873 [00:04<00:31, 323.48it/s]\u001b[A\n","100% 1525/1525 [01:55<00:00, 15.64it/s]\n"," 14% 1630/11873 [00:04<00:31, 322.79it/s]\u001b[A\n"," 14% 1663/11873 [00:04<00:31, 321.76it/s]\u001b[A\n"," 14% 1696/11873 [00:04<00:32, 317.54it/s]\u001b[A\n"," 15% 1729/11873 [00:04<00:31, 320.12it/s]\u001b[A\n"," 15% 1762/11873 [00:04<00:31, 319.63it/s]\u001b[A\n"," 15% 1794/11873 [00:05<00:31, 316.98it/s]\u001b[A\n"," 15% 1826/11873 [00:05<00:31, 317.09it/s]\u001b[A\n"," 16% 1859/11873 [00:05<00:31, 318.71it/s]\u001b[A\n"," 16% 1891/11873 [00:05<00:31, 315.04it/s]\u001b[A\n"," 16% 1925/11873 [00:05<00:31, 319.72it/s]\u001b[A\n"," 16% 1959/11873 [00:05<00:30, 323.61it/s]\u001b[A\n"," 17% 1992/11873 [00:05<00:30, 322.18it/s]\u001b[A\n"," 17% 2025/11873 [00:05<00:30, 322.88it/s]\u001b[A\n"," 17% 2058/11873 [00:05<00:30, 322.10it/s]\u001b[A\n"," 18% 2091/11873 [00:05<00:30, 323.73it/s]\u001b[A\n"," 18% 2124/11873 [00:06<00:30, 323.64it/s]\u001b[A\n"," 18% 2157/11873 [00:06<00:29, 325.02it/s]\u001b[A\n"," 18% 2190/11873 [00:06<00:30, 320.60it/s]\u001b[A\n"," 19% 2224/11873 [00:06<00:29, 324.13it/s]\u001b[A\n"," 19% 2257/11873 [00:06<00:29, 324.77it/s]\u001b[A\n"," 19% 2290/11873 [00:06<00:29, 325.31it/s]\u001b[A\n"," 20% 2323/11873 [00:06<00:29, 322.80it/s]\u001b[A\n"," 20% 2356/11873 [00:06<00:29, 323.52it/s]\u001b[A\n"," 20% 2389/11873 [00:06<00:29, 321.12it/s]\u001b[A\n"," 20% 2422/11873 [00:06<00:29, 317.70it/s]\u001b[A\n"," 21% 2454/11873 [00:07<00:29, 317.35it/s]\u001b[A\n"," 21% 2487/11873 [00:07<00:29, 319.82it/s]\u001b[A\n"," 21% 2520/11873 [00:07<00:29, 320.25it/s]\u001b[A\n"," 22% 2553/11873 [00:07<00:28, 322.99it/s]\u001b[A\n"," 22% 2586/11873 [00:07<00:29, 319.53it/s]\u001b[A\n"," 22% 2618/11873 [00:07<00:29, 318.67it/s]\u001b[A\n"," 22% 2650/11873 [00:07<00:29, 316.31it/s]\u001b[A\n"," 23% 2682/11873 [00:07<00:29, 315.39it/s]\u001b[A\n"," 23% 2714/11873 [00:07<00:29, 312.93it/s]\u001b[A\n"," 23% 2747/11873 [00:07<00:28, 315.62it/s]\u001b[A\n"," 23% 2779/11873 [00:08<00:28, 316.03it/s]\u001b[A\n"," 24% 2813/11873 [00:08<00:28, 320.69it/s]\u001b[A\n"," 24% 2847/11873 [00:08<00:27, 323.94it/s]\u001b[A\n"," 24% 2880/11873 [00:08<00:28, 319.76it/s]\u001b[A\n"," 25% 2912/11873 [00:08<00:28, 319.06it/s]\u001b[A\n"," 25% 2944/11873 [00:08<00:28, 318.82it/s]\u001b[A\n"," 25% 2977/11873 [00:08<00:27, 319.91it/s]\u001b[A\n"," 25% 3009/11873 [00:08<00:31, 283.88it/s]\u001b[A\n"," 26% 3042/11873 [00:08<00:30, 294.28it/s]\u001b[A\n"," 26% 3074/11873 [00:09<00:29, 301.03it/s]\u001b[A\n"," 26% 3105/11873 [00:09<00:29, 294.79it/s]\u001b[A\n"," 26% 3135/11873 [00:09<00:34, 250.51it/s]\u001b[A\n"," 27% 3162/11873 [00:09<00:36, 237.89it/s]\u001b[A\n"," 27% 3196/11873 [00:09<00:33, 262.09it/s]\u001b[A\n"," 27% 3229/11873 [00:09<00:30, 279.01it/s]\u001b[A\n"," 27% 3262/11873 [00:09<00:29, 291.29it/s]\u001b[A\n"," 28% 3292/11873 [00:09<00:39, 218.28it/s]\u001b[A\n"," 28% 3317/11873 [00:10<00:44, 193.52it/s]\u001b[A\n"," 28% 3339/11873 [00:10<00:44, 190.43it/s]\u001b[A\n"," 28% 3360/11873 [00:10<00:47, 179.33it/s]\u001b[A\n"," 29% 3385/11873 [00:10<00:43, 194.51it/s]\u001b[A\n"," 29% 3418/11873 [00:10<00:37, 227.05it/s]\u001b[A\n"," 29% 3452/11873 [00:10<00:33, 254.88it/s]\u001b[A\n"," 29% 3484/11873 [00:10<00:30, 271.66it/s]\u001b[A\n"," 30% 3517/11873 [00:10<00:29, 286.45it/s]\u001b[A\n"," 30% 3551/11873 [00:11<00:27, 299.28it/s]\u001b[A\n"," 30% 3584/11873 [00:11<00:27, 306.35it/s]\u001b[A\n"," 30% 3618/11873 [00:11<00:26, 314.18it/s]\u001b[A\n"," 31% 3650/11873 [00:11<00:26, 315.74it/s]\u001b[A\n"," 31% 3682/11873 [00:11<00:25, 315.25it/s]\u001b[A\n"," 31% 3714/11873 [00:11<00:25, 315.77it/s]\u001b[A\n"," 32% 3747/11873 [00:11<00:25, 318.91it/s]\u001b[A\n"," 32% 3780/11873 [00:11<00:25, 320.62it/s]\u001b[A\n"," 32% 3813/11873 [00:11<00:25, 322.09it/s]\u001b[A\n"," 32% 3846/11873 [00:11<00:26, 298.33it/s]\u001b[A\n"," 33% 3879/11873 [00:12<00:26, 305.95it/s]\u001b[A\n"," 33% 3911/11873 [00:12<00:25, 306.35it/s]\u001b[A\n"," 33% 3942/11873 [00:12<00:27, 287.18it/s]\u001b[A\n"," 33% 3972/11873 [00:12<00:27, 282.48it/s]\u001b[A\n"," 34% 4006/11873 [00:12<00:26, 297.09it/s]\u001b[A\n"," 34% 4040/11873 [00:12<00:25, 307.56it/s]\u001b[A\n"," 34% 4073/11873 [00:12<00:24, 313.49it/s]\u001b[A\n"," 35% 4106/11873 [00:12<00:24, 316.97it/s]\u001b[A\n"," 35% 4139/11873 [00:12<00:24, 317.96it/s]\u001b[A\n"," 35% 4171/11873 [00:13<00:26, 293.48it/s]\u001b[A\n"," 35% 4203/11873 [00:13<00:25, 299.99it/s]\u001b[A\n"," 36% 4237/11873 [00:13<00:24, 309.49it/s]\u001b[A\n"," 36% 4270/11873 [00:13<00:24, 314.11it/s]\u001b[A\n"," 36% 4303/11873 [00:13<00:23, 317.55it/s]\u001b[A\n"," 37% 4337/11873 [00:13<00:23, 323.10it/s]\u001b[A\n"," 37% 4370/11873 [00:13<00:23, 323.99it/s]\u001b[A\n"," 37% 4403/11873 [00:13<00:23, 323.33it/s]\u001b[A\n"," 37% 4436/11873 [00:13<00:29, 255.60it/s]\u001b[A\n"," 38% 4470/11873 [00:14<00:26, 275.45it/s]\u001b[A\n"," 38% 4503/11873 [00:14<00:25, 287.95it/s]\u001b[A\n"," 38% 4536/11873 [00:14<00:24, 297.46it/s]\u001b[A\n"," 38% 4570/11873 [00:14<00:23, 307.05it/s]\u001b[A\n"," 39% 4602/11873 [00:14<00:23, 306.57it/s]\u001b[A\n"," 39% 4635/11873 [00:14<00:23, 311.38it/s]\u001b[A\n"," 39% 4668/11873 [00:14<00:22, 315.25it/s]\u001b[A\n"," 40% 4701/11873 [00:14<00:22, 317.40it/s]\u001b[A\n"," 40% 4734/11873 [00:14<00:22, 317.91it/s]\u001b[A\n"," 40% 4767/11873 [00:14<00:22, 319.80it/s]\u001b[A\n"," 40% 4800/11873 [00:15<00:22, 316.96it/s]\u001b[A\n"," 41% 4832/11873 [00:15<00:22, 315.89it/s]\u001b[A\n"," 41% 4864/11873 [00:15<00:22, 311.48it/s]\u001b[A\n"," 41% 4896/11873 [00:15<00:22, 312.68it/s]\u001b[A\n"," 42% 4930/11873 [00:15<00:21, 317.93it/s]\u001b[A\n"," 42% 4962/11873 [00:15<00:22, 314.05it/s]\u001b[A\n"," 42% 4994/11873 [00:15<00:21, 315.51it/s]\u001b[A\n"," 42% 5026/11873 [00:15<00:22, 309.52it/s]\u001b[A\n"," 43% 5057/11873 [00:15<00:22, 307.24it/s]\u001b[A\n"," 43% 5091/11873 [00:16<00:21, 314.12it/s]\u001b[A\n"," 43% 5125/11873 [00:16<00:21, 320.78it/s]\u001b[A\n"," 43% 5158/11873 [00:16<00:20, 321.51it/s]\u001b[A\n"," 44% 5192/11873 [00:16<00:20, 325.01it/s]\u001b[A\n"," 44% 5226/11873 [00:16<00:20, 327.41it/s]\u001b[A\n"," 44% 5259/11873 [00:16<00:21, 303.24it/s]\u001b[A\n"," 45% 5290/11873 [00:16<00:21, 303.39it/s]\u001b[A\n"," 45% 5324/11873 [00:16<00:21, 311.29it/s]\u001b[A\n"," 45% 5357/11873 [00:16<00:20, 316.35it/s]\u001b[A\n"," 45% 5391/11873 [00:16<00:20, 321.63it/s]\u001b[A\n"," 46% 5424/11873 [00:17<00:19, 323.12it/s]\u001b[A\n"," 46% 5457/11873 [00:17<00:19, 323.91it/s]\u001b[A\n"," 46% 5490/11873 [00:17<00:19, 320.77it/s]\u001b[A\n"," 47% 5523/11873 [00:17<00:19, 321.77it/s]\u001b[A\n"," 47% 5556/11873 [00:17<00:19, 321.84it/s]\u001b[A\n"," 47% 5589/11873 [00:17<00:19, 321.03it/s]\u001b[A\n"," 47% 5622/11873 [00:17<00:19, 319.70it/s]\u001b[A\n"," 48% 5655/11873 [00:17<00:19, 321.11it/s]\u001b[A\n"," 48% 5688/11873 [00:17<00:19, 322.39it/s]\u001b[A\n"," 48% 5721/11873 [00:17<00:19, 322.45it/s]\u001b[A\n"," 48% 5754/11873 [00:18<00:18, 323.43it/s]\u001b[A\n"," 49% 5787/11873 [00:18<00:18, 321.69it/s]\u001b[A\n"," 49% 5821/11873 [00:18<00:18, 324.48it/s]\u001b[A\n"," 49% 5854/11873 [00:18<00:18, 322.86it/s]\u001b[A\n"," 50% 5887/11873 [00:18<00:18, 323.72it/s]\u001b[A\n"," 50% 5921/11873 [00:18<00:18, 326.96it/s]\u001b[A\n"," 50% 5954/11873 [00:18<00:18, 322.17it/s]\u001b[A\n"," 50% 5988/11873 [00:18<00:18, 325.12it/s]\u001b[A\n"," 51% 6021/11873 [00:18<00:17, 325.97it/s]\u001b[A\n"," 51% 6054/11873 [00:19<00:18, 321.02it/s]\u001b[A\n"," 51% 6087/11873 [00:19<00:18, 319.18it/s]\u001b[A\n"," 52% 6120/11873 [00:19<00:17, 319.75it/s]\u001b[A\n"," 52% 6152/11873 [00:19<00:17, 318.68it/s]\u001b[A\n"," 52% 6185/11873 [00:19<00:17, 321.40it/s]\u001b[A\n"," 52% 6219/11873 [00:19<00:17, 324.85it/s]\u001b[A\n"," 53% 6252/11873 [00:19<00:17, 324.39it/s]\u001b[A\n"," 53% 6286/11873 [00:19<00:17, 328.11it/s]\u001b[A\n"," 53% 6319/11873 [00:19<00:17, 326.65it/s]\u001b[A\n"," 53% 6352/11873 [00:19<00:16, 326.78it/s]\u001b[A\n"," 54% 6385/11873 [00:20<00:16, 323.77it/s]\u001b[A\n"," 54% 6418/11873 [00:20<00:16, 322.59it/s]\u001b[A\n"," 54% 6451/11873 [00:20<00:16, 321.79it/s]\u001b[A\n"," 55% 6484/11873 [00:20<00:16, 322.78it/s]\u001b[A\n"," 55% 6517/11873 [00:20<00:16, 321.01it/s]\u001b[A\n"," 55% 6550/11873 [00:20<00:16, 323.34it/s]\u001b[A\n"," 55% 6583/11873 [00:20<00:16, 318.71it/s]\u001b[A\n"," 56% 6615/11873 [00:20<00:16, 311.50it/s]\u001b[A\n"," 56% 6647/11873 [00:20<00:16, 312.80it/s]\u001b[A\n"," 56% 6679/11873 [00:20<00:16, 312.40it/s]\u001b[A\n"," 57% 6711/11873 [00:21<00:17, 289.53it/s]\u001b[A\n"," 57% 6741/11873 [00:21<00:17, 287.53it/s]\u001b[A\n"," 57% 6773/11873 [00:21<00:17, 295.50it/s]\u001b[A\n"," 57% 6805/11873 [00:21<00:16, 302.00it/s]\u001b[A\n"," 58% 6839/11873 [00:21<00:16, 311.77it/s]\u001b[A\n"," 58% 6872/11873 [00:21<00:15, 316.09it/s]\u001b[A\n"," 58% 6905/11873 [00:21<00:15, 317.73it/s]\u001b[A\n"," 58% 6939/11873 [00:21<00:15, 322.32it/s]\u001b[A\n"," 59% 6972/11873 [00:21<00:15, 324.33it/s]\u001b[A\n"," 59% 7005/11873 [00:22<00:15, 322.61it/s]\u001b[A\n"," 59% 7038/11873 [00:22<00:15, 320.50it/s]\u001b[A\n"," 60% 7071/11873 [00:22<00:14, 323.14it/s]\u001b[A\n"," 60% 7104/11873 [00:22<00:14, 323.72it/s]\u001b[A\n"," 60% 7137/11873 [00:22<00:14, 324.44it/s]\u001b[A\n"," 60% 7170/11873 [00:22<00:14, 322.47it/s]\u001b[A\n"," 61% 7203/11873 [00:22<00:14, 320.59it/s]\u001b[A\n"," 61% 7236/11873 [00:22<00:14, 319.80it/s]\u001b[A\n"," 61% 7269/11873 [00:22<00:14, 322.38it/s]\u001b[A\n"," 62% 7302/11873 [00:22<00:14, 322.76it/s]\u001b[A\n"," 62% 7335/11873 [00:23<00:14, 322.11it/s]\u001b[A\n"," 62% 7369/11873 [00:23<00:13, 325.65it/s]\u001b[A\n"," 62% 7402/11873 [00:23<00:13, 324.86it/s]\u001b[A\n"," 63% 7435/11873 [00:23<00:14, 308.23it/s]\u001b[A\n"," 63% 7468/11873 [00:23<00:14, 313.76it/s]\u001b[A\n"," 63% 7502/11873 [00:23<00:13, 319.08it/s]\u001b[A\n"," 63% 7536/11873 [00:23<00:13, 323.59it/s]\u001b[A\n"," 64% 7570/11873 [00:23<00:13, 326.18it/s]\u001b[A\n"," 64% 7603/11873 [00:23<00:13, 323.61it/s]\u001b[A\n"," 64% 7636/11873 [00:23<00:13, 316.89it/s]\u001b[A\n"," 65% 7669/11873 [00:24<00:13, 317.75it/s]\u001b[A\n"," 65% 7701/11873 [00:24<00:13, 312.42it/s]\u001b[A\n"," 65% 7733/11873 [00:24<00:13, 296.23it/s]\u001b[A\n"," 65% 7765/11873 [00:24<00:13, 300.40it/s]\u001b[A\n"," 66% 7797/11873 [00:24<00:13, 305.80it/s]\u001b[A\n"," 66% 7830/11873 [00:24<00:13, 310.72it/s]\u001b[A\n"," 66% 7862/11873 [00:24<00:12, 311.87it/s]\u001b[A\n"," 66% 7894/11873 [00:24<00:13, 291.90it/s]\u001b[A\n"," 67% 7927/11873 [00:24<00:13, 300.68it/s]\u001b[A\n"," 67% 7960/11873 [00:25<00:12, 306.74it/s]\u001b[A\n"," 67% 7992/11873 [00:25<00:12, 309.61it/s]\u001b[A\n"," 68% 8026/11873 [00:25<00:12, 315.71it/s]\u001b[A\n"," 68% 8058/11873 [00:25<00:12, 316.65it/s]\u001b[A\n"," 68% 8091/11873 [00:25<00:11, 319.02it/s]\u001b[A\n"," 68% 8124/11873 [00:25<00:11, 321.85it/s]\u001b[A\n"," 69% 8157/11873 [00:25<00:11, 321.22it/s]\u001b[A\n"," 69% 8190/11873 [00:25<00:11, 318.68it/s]\u001b[A\n"," 69% 8222/11873 [00:25<00:11, 315.25it/s]\u001b[A\n"," 70% 8256/11873 [00:25<00:11, 319.73it/s]\u001b[A\n"," 70% 8289/11873 [00:26<00:11, 320.29it/s]\u001b[A\n"," 70% 8322/11873 [00:26<00:11, 319.47it/s]\u001b[A\n"," 70% 8354/11873 [00:26<00:11, 318.79it/s]\u001b[A\n"," 71% 8387/11873 [00:26<00:10, 320.56it/s]\u001b[A\n"," 71% 8420/11873 [00:26<00:10, 318.40it/s]\u001b[A\n"," 71% 8452/11873 [00:26<00:10, 317.13it/s]\u001b[A\n"," 71% 8484/11873 [00:26<00:10, 317.05it/s]\u001b[A\n"," 72% 8518/11873 [00:26<00:10, 321.74it/s]\u001b[A\n"," 72% 8551/11873 [00:26<00:10, 322.49it/s]\u001b[A\n"," 72% 8585/11873 [00:26<00:10, 325.82it/s]\u001b[A\n"," 73% 8618/11873 [00:27<00:10, 322.96it/s]\u001b[A\n"," 73% 8651/11873 [00:27<00:10, 321.33it/s]\u001b[A\n"," 73% 8684/11873 [00:27<00:09, 321.82it/s]\u001b[A\n"," 73% 8717/11873 [00:27<00:09, 319.91it/s]\u001b[A\n"," 74% 8750/11873 [00:27<00:09, 321.53it/s]\u001b[A\n"," 74% 8783/11873 [00:27<00:09, 318.87it/s]\u001b[A\n"," 74% 8815/11873 [00:27<00:09, 314.00it/s]\u001b[A\n"," 75% 8848/11873 [00:27<00:09, 315.90it/s]\u001b[A\n"," 75% 8880/11873 [00:27<00:09, 316.21it/s]\u001b[A\n"," 75% 8912/11873 [00:28<00:09, 315.46it/s]\u001b[A\n"," 75% 8944/11873 [00:28<00:09, 316.22it/s]\u001b[A\n"," 76% 8976/11873 [00:28<00:09, 315.67it/s]\u001b[A\n"," 76% 9008/11873 [00:28<00:09, 314.18it/s]\u001b[A\n"," 76% 9040/11873 [00:28<00:08, 315.37it/s]\u001b[A\n"," 76% 9072/11873 [00:28<00:08, 314.26it/s]\u001b[A\n"," 77% 9104/11873 [00:28<00:08, 313.38it/s]\u001b[A\n"," 77% 9136/11873 [00:28<00:08, 315.31it/s]\u001b[A\n"," 77% 9169/11873 [00:28<00:08, 317.67it/s]\u001b[A\n"," 77% 9201/11873 [00:28<00:08, 318.31it/s]\u001b[A\n"," 78% 9234/11873 [00:29<00:08, 319.83it/s]\u001b[A\n"," 78% 9266/11873 [00:29<00:08, 317.87it/s]\u001b[A\n"," 78% 9298/11873 [00:29<00:08, 315.82it/s]\u001b[A\n"," 79% 9330/11873 [00:29<00:08, 313.55it/s]\u001b[A\n"," 79% 9362/11873 [00:29<00:08, 310.16it/s]\u001b[A\n"," 79% 9394/11873 [00:29<00:07, 312.36it/s]\u001b[A\n"," 79% 9426/11873 [00:29<00:07, 311.06it/s]\u001b[A\n"," 80% 9458/11873 [00:29<00:07, 310.66it/s]\u001b[A\n"," 80% 9491/11873 [00:29<00:07, 314.27it/s]\u001b[A\n"," 80% 9524/11873 [00:29<00:07, 317.98it/s]\u001b[A\n"," 80% 9556/11873 [00:30<00:07, 315.85it/s]\u001b[A\n"," 81% 9588/11873 [00:30<00:07, 316.47it/s]\u001b[A\n"," 81% 9620/11873 [00:30<00:07, 314.92it/s]\u001b[A\n"," 81% 9653/11873 [00:30<00:07, 316.67it/s]\u001b[A\n"," 82% 9686/11873 [00:30<00:06, 319.77it/s]\u001b[A\n"," 82% 9718/11873 [00:30<00:06, 317.22it/s]\u001b[A\n"," 82% 9752/11873 [00:30<00:06, 322.69it/s]\u001b[A\n"," 82% 9785/11873 [00:30<00:06, 323.79it/s]\u001b[A\n"," 83% 9818/11873 [00:30<00:06, 325.00it/s]\u001b[A\n"," 83% 9851/11873 [00:30<00:06, 323.64it/s]\u001b[A\n"," 83% 9884/11873 [00:31<00:06, 324.00it/s]\u001b[A\n"," 84% 9917/11873 [00:31<00:06, 323.23it/s]\u001b[A\n"," 84% 9950/11873 [00:31<00:05, 322.36it/s]\u001b[A\n"," 84% 9983/11873 [00:31<00:05, 321.99it/s]\u001b[A\n"," 84% 10016/11873 [00:31<00:05, 322.77it/s]\u001b[A\n"," 85% 10049/11873 [00:31<00:05, 323.63it/s]\u001b[A\n"," 85% 10082/11873 [00:31<00:05, 321.34it/s]\u001b[A\n"," 85% 10115/11873 [00:31<00:05, 319.50it/s]\u001b[A\n"," 85% 10147/11873 [00:31<00:05, 319.18it/s]\u001b[A\n"," 86% 10179/11873 [00:32<00:05, 317.19it/s]\u001b[A\n"," 86% 10211/11873 [00:32<00:05, 312.30it/s]\u001b[A\n"," 86% 10243/11873 [00:32<00:05, 310.51it/s]\u001b[A\n"," 87% 10275/11873 [00:32<00:05, 312.07it/s]\u001b[A\n"," 87% 10307/11873 [00:32<00:05, 309.74it/s]\u001b[A\n"," 87% 10339/11873 [00:32<00:04, 312.01it/s]\u001b[A\n"," 87% 10371/11873 [00:32<00:04, 313.31it/s]\u001b[A\n"," 88% 10403/11873 [00:32<00:04, 314.99it/s]\u001b[A\n"," 88% 10435/11873 [00:32<00:04, 293.36it/s]\u001b[A\n"," 88% 10466/11873 [00:32<00:04, 297.27it/s]\u001b[A\n"," 88% 10500/11873 [00:33<00:04, 307.23it/s]\u001b[A\n"," 89% 10532/11873 [00:33<00:04, 309.81it/s]\u001b[A\n"," 89% 10564/11873 [00:33<00:04, 291.30it/s]\u001b[A\n"," 89% 10596/11873 [00:33<00:04, 297.08it/s]\u001b[A\n"," 90% 10628/11873 [00:33<00:04, 301.85it/s]\u001b[A\n"," 90% 10660/11873 [00:33<00:03, 304.74it/s]\u001b[A\n"," 90% 10693/11873 [00:33<00:03, 310.44it/s]\u001b[A\n"," 90% 10726/11873 [00:33<00:03, 316.07it/s]\u001b[A\n"," 91% 10759/11873 [00:33<00:03, 318.36it/s]\u001b[A\n"," 91% 10791/11873 [00:34<00:03, 317.95it/s]\u001b[A\n"," 91% 10823/11873 [00:34<00:03, 304.15it/s]\u001b[A\n"," 91% 10854/11873 [00:34<00:03, 295.31it/s]\u001b[A\n"," 92% 10884/11873 [00:34<00:03, 296.29it/s]\u001b[A\n"," 92% 10916/11873 [00:34<00:03, 302.11it/s]\u001b[A\n"," 92% 10947/11873 [00:34<00:03, 300.76it/s]\u001b[A\n"," 92% 10980/11873 [00:34<00:02, 307.42it/s]\u001b[A\n"," 93% 11013/11873 [00:34<00:02, 312.34it/s]\u001b[A\n"," 93% 11046/11873 [00:34<00:02, 315.97it/s]\u001b[A\n"," 93% 11078/11873 [00:34<00:02, 316.17it/s]\u001b[A\n"," 94% 11111/11873 [00:35<00:02, 319.27it/s]\u001b[A\n"," 94% 11143/11873 [00:35<00:02, 319.24it/s]\u001b[A\n"," 94% 11175/11873 [00:35<00:02, 319.31it/s]\u001b[A\n"," 94% 11207/11873 [00:35<00:02, 314.15it/s]\u001b[A\n"," 95% 11240/11873 [00:35<00:02, 316.15it/s]\u001b[A\n"," 95% 11272/11873 [00:35<00:01, 314.43it/s]\u001b[A\n"," 95% 11304/11873 [00:35<00:01, 315.98it/s]\u001b[A\n"," 95% 11337/11873 [00:35<00:01, 318.00it/s]\u001b[A\n"," 96% 11369/11873 [00:35<00:01, 317.95it/s]\u001b[A\n"," 96% 11402/11873 [00:35<00:01, 319.51it/s]\u001b[A\n"," 96% 11434/11873 [00:36<00:01, 315.43it/s]\u001b[A\n"," 97% 11466/11873 [00:36<00:01, 316.47it/s]\u001b[A\n"," 97% 11499/11873 [00:36<00:01, 317.62it/s]\u001b[A\n"," 97% 11531/11873 [00:36<00:01, 316.56it/s]\u001b[A\n"," 97% 11563/11873 [00:36<00:00, 316.56it/s]\u001b[A\n"," 98% 11596/11873 [00:36<00:00, 318.22it/s]\u001b[A\n"," 98% 11628/11873 [00:36<00:00, 312.54it/s]\u001b[A\n"," 98% 11661/11873 [00:36<00:00, 314.96it/s]\u001b[A\n"," 98% 11693/11873 [00:36<00:00, 311.00it/s]\u001b[A\n"," 99% 11726/11873 [00:36<00:00, 315.84it/s]\u001b[A\n"," 99% 11759/11873 [00:37<00:00, 317.86it/s]\u001b[A\n"," 99% 11792/11873 [00:37<00:00, 321.15it/s]\u001b[A\n","100% 11825/11873 [00:37<00:00, 319.00it/s]\u001b[A\n","100% 11873/11873 [00:37<00:00, 317.03it/s]\n","04/07/2022 03:58:41 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/eval_predictions.json.\n","04/07/2022 03:58:42 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/eval_nbest_predictions.json.\n","04/07/2022 03:58:45 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/QA/model_results/bert-base-cased/back-trans-synonym-aug/eval_null_odds.json.\n","04/07/2022 03:58:48 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n","100% 1525/1525 [02:35<00:00,  9.83it/s]\n","***** eval metrics *****\n","  eval_HasAns_exact      = 72.4359\n","  eval_HasAns_f1         = 79.0347\n","  eval_HasAns_total      =    5928\n","  eval_NoAns_exact       = 62.5399\n","  eval_NoAns_f1          = 62.5399\n","  eval_NoAns_total       =    5945\n","  eval_best_exact        = 67.4808\n","  eval_best_exact_thresh =     0.0\n","  eval_best_f1           = 70.7755\n","  eval_best_f1_thresh    =     0.0\n","  eval_exact             = 67.4808\n","  eval_f1                = 70.7755\n","  eval_samples           =   12199\n","  eval_total             =   11873\n","[INFO|modelcard.py:460] 2022-04-07 03:58:49,595 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'sichenzhong/squad_v2_back_trans_synonym_aug', 'type': 'sichenzhong/squad_v2_back_trans_synonym_aug', 'args': 'squad_v2'}}\n"]}]},{"cell_type":"code","source":["!python run_qa.py \\\n","  --model_name_or_path albert-base-v2 \\\n","  --dataset_name sichenzhong/squad_v2_back_trans_synonym_aug \\\n","  --do_train \\\n","  --do_eval \\\n","  --per_device_train_batch_size 16 \\\n","  --learning_rate 2e-5 \\\n","  --num_train_epochs 2 \\\n","  --max_seq_length 512 \\\n","  --doc_stride 128 \\\n","  --version_2_with_negative \\\n","  --output_dir /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug"],"metadata":{"id":"YC1SX-FRTOxk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649312601926,"user_tz":240,"elapsed":7889214,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"54522596-0249-4152-e04f-eeab4ff32277"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["04/07/2022 03:58:55 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","04/07/2022 03:58:55 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.NO,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=2e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/runs/Apr07_03-58-55_e45f44865b23,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=2.0,\n","optim=OptimizerNames.ADAMW_HF,\n","output_dir=/content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=16,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","04/07/2022 03:58:56 - WARNING - datasets.builder - Using custom data configuration sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178\n","04/07/2022 03:58:56 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n","04/07/2022 03:58:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901\n","04/07/2022 03:58:56 - WARNING - datasets.builder - Reusing dataset parquet (/root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n","04/07/2022 03:58:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901\n","100% 2/2 [00:00<00:00, 587.60it/s]\n","[INFO|hub.py:583] 2022-04-07 03:58:57,266 >> https://huggingface.co/albert-base-v2/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpaatgirqd\n","Downloading: 100% 684/684 [00:00<00:00, 605kB/s]\n","[INFO|hub.py:587] 2022-04-07 03:58:57,626 >> storing https://huggingface.co/albert-base-v2/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|hub.py:595] 2022-04-07 03:58:57,627 >> creating metadata file for /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|configuration_utils.py:654] 2022-04-07 03:58:57,627 >> loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|configuration_utils.py:690] 2022-04-07 03:58:57,628 >> Model config AlbertConfig {\n","  \"_name_or_path\": \"albert-base-v2\",\n","  \"architectures\": [\n","    \"AlbertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","[INFO|tokenization_auto.py:344] 2022-04-07 03:58:57,987 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n","[INFO|configuration_utils.py:654] 2022-04-07 03:58:58,348 >> loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|configuration_utils.py:690] 2022-04-07 03:58:58,349 >> Model config AlbertConfig {\n","  \"_name_or_path\": \"albert-base-v2\",\n","  \"architectures\": [\n","    \"AlbertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","[INFO|hub.py:583] 2022-04-07 03:58:59,065 >> https://huggingface.co/albert-base-v2/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp4nml3nwe\n","Downloading: 100% 742k/742k [00:00<00:00, 1.77MB/s]\n","[INFO|hub.py:587] 2022-04-07 03:58:59,861 >> storing https://huggingface.co/albert-base-v2/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/10be6ce6d3508f1fdce98a57a574283b47c055228c1235f8686f039287ff8174.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d\n","[INFO|hub.py:595] 2022-04-07 03:58:59,861 >> creating metadata file for /root/.cache/huggingface/transformers/10be6ce6d3508f1fdce98a57a574283b47c055228c1235f8686f039287ff8174.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d\n","[INFO|hub.py:583] 2022-04-07 03:59:00,222 >> https://huggingface.co/albert-base-v2/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpralkxb9o\n","Downloading: 100% 1.25M/1.25M [00:00<00:00, 2.56MB/s]\n","[INFO|hub.py:587] 2022-04-07 03:59:01,102 >> storing https://huggingface.co/albert-base-v2/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/828a43aa4b9d07e2b7d3be7c6bc10a3ae6e16e8d9c3a0c557783639de9eaeb1b.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74\n","[INFO|hub.py:595] 2022-04-07 03:59:01,102 >> creating metadata file for /root/.cache/huggingface/transformers/828a43aa4b9d07e2b7d3be7c6bc10a3ae6e16e8d9c3a0c557783639de9eaeb1b.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 03:59:02,189 >> loading file https://huggingface.co/albert-base-v2/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/10be6ce6d3508f1fdce98a57a574283b47c055228c1235f8686f039287ff8174.d6110e25022b713452eb83d5bfa8ae64530995a93d8e694fe52e05aa85dd3a7d\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 03:59:02,189 >> loading file https://huggingface.co/albert-base-v2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/828a43aa4b9d07e2b7d3be7c6bc10a3ae6e16e8d9c3a0c557783639de9eaeb1b.670e237d152dd53ef77575d4f4a6cd34158db03128fe4f63437ce0d5992bac74\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 03:59:02,189 >> loading file https://huggingface.co/albert-base-v2/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 03:59:02,189 >> loading file https://huggingface.co/albert-base-v2/resolve/main/special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 03:59:02,189 >> loading file https://huggingface.co/albert-base-v2/resolve/main/tokenizer_config.json from cache at None\n","[INFO|configuration_utils.py:654] 2022-04-07 03:59:02,550 >> loading configuration file https://huggingface.co/albert-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/e48be00f755a5f765e36a32885e8d6a573081df3321c9e19428d12abadf7dba2.b8f28145885741cf994c0e8a97b724f6c974460c297002145e48e511d2496e88\n","[INFO|configuration_utils.py:690] 2022-04-07 03:59:02,551 >> Model config AlbertConfig {\n","  \"_name_or_path\": \"albert-base-v2\",\n","  \"architectures\": [\n","    \"AlbertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 2,\n","  \"classifier_dropout_prob\": 0.1,\n","  \"down_scale_factor\": 1,\n","  \"embedding_size\": 128,\n","  \"eos_token_id\": 3,\n","  \"gap_size\": 0,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"inner_group_num\": 1,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"albert\",\n","  \"net_structure_type\": 0,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_groups\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_memory_blocks\": 0,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 2,\n","  \"vocab_size\": 30000\n","}\n","\n","[INFO|hub.py:583] 2022-04-07 03:59:02,997 >> https://huggingface.co/albert-base-v2/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpn1e11kep\n","Downloading: 100% 45.2M/45.2M [00:00<00:00, 62.1MB/s]\n","[INFO|hub.py:587] 2022-04-07 03:59:03,792 >> storing https://huggingface.co/albert-base-v2/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/bf1986d976e9a8320cbd3a0597e610bf299d639ce31b7ca581cbf54be3aaa6d3.d6d54047dfe6ae844e3bf6e7a7d0aff71cb598d3df019361e076ba7639b1da9b\n","[INFO|hub.py:595] 2022-04-07 03:59:03,792 >> creating metadata file for /root/.cache/huggingface/transformers/bf1986d976e9a8320cbd3a0597e610bf299d639ce31b7ca581cbf54be3aaa6d3.d6d54047dfe6ae844e3bf6e7a7d0aff71cb598d3df019361e076ba7639b1da9b\n","[INFO|modeling_utils.py:1772] 2022-04-07 03:59:03,792 >> loading weights file https://huggingface.co/albert-base-v2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/bf1986d976e9a8320cbd3a0597e610bf299d639ce31b7ca581cbf54be3aaa6d3.d6d54047dfe6ae844e3bf6e7a7d0aff71cb598d3df019361e076ba7639b1da9b\n","[WARNING|modeling_utils.py:2049] 2022-04-07 03:59:03,912 >> Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForQuestionAnswering: ['predictions.LayerNorm.weight', 'predictions.decoder.bias', 'predictions.dense.weight', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.dense.bias', 'predictions.decoder.weight']\n","- This IS expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:2060] 2022-04-07 03:59:03,912 >> Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Running tokenizer on train dataset:   0% 0/131 [00:00<?, ?ba/s]04/07/2022 03:59:04 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-c4369894bcc688dd.arrow\n","Running tokenizer on train dataset: 100% 131/131 [01:00<00:00,  2.17ba/s]\n","Running tokenizer on validation dataset:   0% 0/12 [00:00<?, ?ba/s]04/07/2022 04:00:04 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-b46b5d010b47e8f6.arrow\n","Running tokenizer on validation dataset: 100% 12/12 [01:19<00:00,  6.61s/ba]\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","[INFO|trainer.py:1290] 2022-04-07 04:01:28,659 >> ***** Running training *****\n","[INFO|trainer.py:1291] 2022-04-07 04:01:28,659 >>   Num examples = 130551\n","[INFO|trainer.py:1292] 2022-04-07 04:01:28,659 >>   Num Epochs = 2\n","[INFO|trainer.py:1293] 2022-04-07 04:01:28,659 >>   Instantaneous batch size per device = 16\n","[INFO|trainer.py:1294] 2022-04-07 04:01:28,659 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n","[INFO|trainer.py:1295] 2022-04-07 04:01:28,659 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1296] 2022-04-07 04:01:28,659 >>   Total optimization steps = 16320\n","{'loss': 1.9481, 'learning_rate': 1.9387254901960785e-05, 'epoch': 0.06}\n","  3% 500/16320 [04:13<2:13:37,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:05:41,892 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-500\n","[INFO|configuration_utils.py:441] 2022-04-07 04:05:41,897 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:05:42,022 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:05:42,026 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:05:42,028 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-500/special_tokens_map.json\n","{'loss': 1.5097, 'learning_rate': 1.877450980392157e-05, 'epoch': 0.12}\n","  6% 1000/16320 [08:27<2:09:27,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:09:55,973 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1000\n","[INFO|configuration_utils.py:441] 2022-04-07 04:09:55,978 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:09:56,097 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:09:56,101 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:09:56,104 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1000/special_tokens_map.json\n","{'loss': 1.4419, 'learning_rate': 1.8161764705882355e-05, 'epoch': 0.18}\n","  9% 1500/16320 [12:41<2:05:26,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:14:10,161 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1500\n","[INFO|configuration_utils.py:441] 2022-04-07 04:14:10,166 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:14:10,292 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:14:10,296 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:14:10,299 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-1500/special_tokens_map.json\n","{'loss': 1.3424, 'learning_rate': 1.7549019607843138e-05, 'epoch': 0.25}\n"," 12% 2000/16320 [16:55<2:01:07,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:18:24,353 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2000\n","[INFO|configuration_utils.py:441] 2022-04-07 04:18:24,359 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:18:24,486 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:18:24,490 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:18:24,494 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2000/special_tokens_map.json\n","{'loss': 1.3324, 'learning_rate': 1.693627450980392e-05, 'epoch': 0.31}\n"," 15% 2500/16320 [21:09<1:56:54,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:22:38,630 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2500\n","[INFO|configuration_utils.py:441] 2022-04-07 04:22:38,648 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:22:38,773 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:22:38,777 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:22:38,780 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-2500/special_tokens_map.json\n","{'loss': 1.3028, 'learning_rate': 1.6323529411764708e-05, 'epoch': 0.37}\n"," 18% 3000/16320 [25:24<1:52:30,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:26:52,774 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3000\n","[INFO|configuration_utils.py:441] 2022-04-07 04:26:52,780 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:26:52,920 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:26:52,924 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:26:52,927 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3000/special_tokens_map.json\n","{'loss': 1.2325, 'learning_rate': 1.571078431372549e-05, 'epoch': 0.43}\n"," 21% 3500/16320 [29:38<1:48:27,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:31:07,023 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3500\n","[INFO|configuration_utils.py:441] 2022-04-07 04:31:07,028 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:31:07,150 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:31:07,154 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:31:07,175 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-3500/special_tokens_map.json\n","{'loss': 1.2166, 'learning_rate': 1.5098039215686276e-05, 'epoch': 0.49}\n"," 25% 4000/16320 [33:52<1:44:10,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:35:21,129 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4000\n","[INFO|configuration_utils.py:441] 2022-04-07 04:35:21,134 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:35:21,257 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:35:21,261 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:35:21,264 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4000/special_tokens_map.json\n","{'loss': 1.1913, 'learning_rate': 1.448529411764706e-05, 'epoch': 0.55}\n"," 28% 4500/16320 [38:06<1:40:01,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:39:35,282 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4500\n","[INFO|configuration_utils.py:441] 2022-04-07 04:39:35,287 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:39:35,405 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:39:35,408 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:39:35,411 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-4500/special_tokens_map.json\n","{'loss': 1.1771, 'learning_rate': 1.3872549019607844e-05, 'epoch': 0.61}\n"," 31% 5000/16320 [42:20<1:35:51,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:43:49,497 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5000\n","[INFO|configuration_utils.py:441] 2022-04-07 04:43:49,503 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:43:49,627 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:43:49,631 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:43:49,634 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5000/special_tokens_map.json\n","{'loss': 1.1537, 'learning_rate': 1.3259803921568627e-05, 'epoch': 0.67}\n"," 34% 5500/16320 [46:35<1:31:27,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:48:03,863 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5500\n","[INFO|configuration_utils.py:441] 2022-04-07 04:48:03,868 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:48:03,996 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:48:04,001 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:48:04,004 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-5500/special_tokens_map.json\n","{'loss': 1.1386, 'learning_rate': 1.2647058823529412e-05, 'epoch': 0.74}\n"," 37% 6000/16320 [50:49<1:27:13,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:52:18,204 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6000\n","[INFO|configuration_utils.py:441] 2022-04-07 04:52:18,209 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:52:18,329 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:52:18,333 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:52:18,337 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6000/special_tokens_map.json\n","{'loss': 1.1374, 'learning_rate': 1.2034313725490197e-05, 'epoch': 0.8}\n"," 40% 6500/16320 [55:03<1:23:16,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 04:56:32,602 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6500\n","[INFO|configuration_utils.py:441] 2022-04-07 04:56:32,608 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 04:56:32,733 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 04:56:32,738 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 04:56:32,741 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-6500/special_tokens_map.json\n","{'loss': 1.1022, 'learning_rate': 1.142156862745098e-05, 'epoch': 0.86}\n"," 43% 7000/16320 [59:18<1:18:58,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:00:47,122 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7000\n","[INFO|configuration_utils.py:441] 2022-04-07 05:00:47,128 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:00:47,256 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:00:47,261 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:00:47,264 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7000/special_tokens_map.json\n","{'loss': 1.0784, 'learning_rate': 1.0808823529411765e-05, 'epoch': 0.92}\n"," 46% 7500/16320 [1:03:32<1:14:45,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:05:01,592 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7500\n","[INFO|configuration_utils.py:441] 2022-04-07 05:05:01,598 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:05:01,720 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:05:01,724 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:05:01,727 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-7500/special_tokens_map.json\n","{'loss': 1.0923, 'learning_rate': 1.0196078431372549e-05, 'epoch': 0.98}\n"," 49% 8000/16320 [1:07:47<1:10:28,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:09:16,082 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8000\n","[INFO|configuration_utils.py:441] 2022-04-07 05:09:16,087 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:09:16,214 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:09:16,218 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:09:16,221 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8000/special_tokens_map.json\n","{'loss': 0.9466, 'learning_rate': 9.583333333333335e-06, 'epoch': 1.04}\n"," 52% 8500/16320 [1:12:01<1:06:12,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:13:30,214 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8500\n","[INFO|configuration_utils.py:441] 2022-04-07 05:13:30,220 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:13:30,344 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:13:30,348 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:13:30,351 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-8500/special_tokens_map.json\n","{'loss': 0.8664, 'learning_rate': 8.970588235294119e-06, 'epoch': 1.1}\n"," 55% 9000/16320 [1:16:15<1:01:51,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:17:44,349 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9000\n","[INFO|configuration_utils.py:441] 2022-04-07 05:17:44,354 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:17:44,474 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:17:44,477 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:17:44,481 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9000/special_tokens_map.json\n","{'loss': 0.8633, 'learning_rate': 8.357843137254903e-06, 'epoch': 1.16}\n"," 58% 9500/16320 [1:20:29<57:35,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:21:58,492 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9500\n","[INFO|configuration_utils.py:441] 2022-04-07 05:21:58,497 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:21:58,619 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:21:58,623 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:21:58,625 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-9500/special_tokens_map.json\n","{'loss': 0.868, 'learning_rate': 7.745098039215687e-06, 'epoch': 1.23}\n"," 61% 10000/16320 [1:24:43<53:28,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:26:12,675 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10000\n","[INFO|configuration_utils.py:441] 2022-04-07 05:26:12,680 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:26:12,805 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:26:12,810 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:26:12,813 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10000/special_tokens_map.json\n","{'loss': 0.8547, 'learning_rate': 7.132352941176472e-06, 'epoch': 1.29}\n"," 64% 10500/16320 [1:28:58<49:14,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:30:26,998 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10500\n","[INFO|configuration_utils.py:441] 2022-04-07 05:30:27,006 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:30:27,130 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:30:27,134 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:30:27,136 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-10500/special_tokens_map.json\n","{'loss': 0.8559, 'learning_rate': 6.519607843137256e-06, 'epoch': 1.35}\n"," 67% 11000/16320 [1:33:12<44:57,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:34:41,397 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11000\n","[INFO|configuration_utils.py:441] 2022-04-07 05:34:41,403 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:34:41,529 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:34:41,534 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:34:41,557 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11000/special_tokens_map.json\n","{'loss': 0.8534, 'learning_rate': 5.90686274509804e-06, 'epoch': 1.41}\n"," 70% 11500/16320 [1:37:27<40:47,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:38:55,730 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11500\n","[INFO|configuration_utils.py:441] 2022-04-07 05:38:55,735 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:38:55,860 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:38:55,864 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:38:55,867 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-11500/special_tokens_map.json\n","{'loss': 0.8554, 'learning_rate': 5.294117647058824e-06, 'epoch': 1.47}\n"," 74% 12000/16320 [1:41:41<36:33,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:43:10,032 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12000\n","[INFO|configuration_utils.py:441] 2022-04-07 05:43:10,037 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:43:10,157 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:43:10,161 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:43:10,165 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12000/special_tokens_map.json\n","{'loss': 0.8496, 'learning_rate': 4.681372549019608e-06, 'epoch': 1.53}\n"," 77% 12500/16320 [1:45:55<32:20,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:47:24,352 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12500\n","[INFO|configuration_utils.py:441] 2022-04-07 05:47:24,357 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:47:24,477 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:47:24,481 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:47:24,484 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-12500/special_tokens_map.json\n","{'loss': 0.824, 'learning_rate': 4.068627450980392e-06, 'epoch': 1.59}\n"," 80% 13000/16320 [1:50:09<28:05,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:51:38,617 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13000\n","[INFO|configuration_utils.py:441] 2022-04-07 05:51:38,622 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:51:38,746 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:51:38,751 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:51:38,754 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13000/special_tokens_map.json\n","{'loss': 0.8303, 'learning_rate': 3.4558823529411766e-06, 'epoch': 1.65}\n"," 83% 13500/16320 [1:54:24<23:51,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 05:55:52,824 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13500\n","[INFO|configuration_utils.py:441] 2022-04-07 05:55:52,830 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 05:55:52,952 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 05:55:52,957 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 05:55:52,960 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-13500/special_tokens_map.json\n","{'loss': 0.8187, 'learning_rate': 2.843137254901961e-06, 'epoch': 1.72}\n"," 86% 14000/16320 [1:58:38<19:39,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 06:00:07,162 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:00:07,167 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:00:07,286 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:00:07,290 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:00:07,293 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14000/special_tokens_map.json\n","{'loss': 0.8206, 'learning_rate': 2.2303921568627456e-06, 'epoch': 1.78}\n"," 89% 14500/16320 [2:02:52<15:22,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 06:04:21,443 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:04:21,447 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:04:21,566 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:04:21,571 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:04:21,574 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-14500/special_tokens_map.json\n","{'loss': 0.8031, 'learning_rate': 1.6176470588235297e-06, 'epoch': 1.84}\n"," 92% 15000/16320 [2:07:07<11:10,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 06:08:35,854 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:08:35,860 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:08:35,987 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:08:35,991 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:08:35,995 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15000/special_tokens_map.json\n","{'loss': 0.7984, 'learning_rate': 1.0049019607843138e-06, 'epoch': 1.9}\n"," 95% 15500/16320 [2:11:21<06:56,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 06:12:50,167 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:12:50,173 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:12:50,294 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:12:50,299 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:12:50,301 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-15500/special_tokens_map.json\n","{'loss': 0.8043, 'learning_rate': 3.921568627450981e-07, 'epoch': 1.96}\n"," 98% 16000/16320 [2:15:35<02:42,  1.97it/s][INFO|trainer.py:2166] 2022-04-07 06:17:04,562 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-16000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:17:04,568 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-16000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:17:04,691 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-16000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:17:04,696 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-16000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:17:04,700 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/checkpoint-16000/special_tokens_map.json\n","100% 16320/16320 [2:18:18<00:00,  2.34it/s][INFO|trainer.py:1530] 2022-04-07 06:19:47,205 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 8298.5464, 'train_samples_per_second': 31.464, 'train_steps_per_second': 1.967, 'train_loss': 1.0546364784240723, 'epoch': 2.0}\n","100% 16320/16320 [2:18:18<00:00,  1.97it/s]\n","[INFO|trainer.py:2166] 2022-04-07 06:19:47,209 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug\n","[INFO|configuration_utils.py:441] 2022-04-07 06:19:47,214 >> Configuration saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:19:47,359 >> Model weights saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:19:47,364 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:19:47,368 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =        2.0\n","  train_loss               =     1.0546\n","  train_runtime            = 2:18:18.54\n","  train_samples            =     130551\n","  train_samples_per_second =     31.464\n","  train_steps_per_second   =      1.967\n","04/07/2022 06:19:47 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:567] 2022-04-07 06:19:47,397 >> The following columns in the evaluation set  don't have a corresponding argument in `AlbertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping. If example_id, offset_mapping are not expected by `AlbertForQuestionAnswering.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:2416] 2022-04-07 06:19:47,399 >> ***** Running Evaluation *****\n","[INFO|trainer.py:2418] 2022-04-07 06:19:47,399 >>   Num examples = 11968\n","[INFO|trainer.py:2421] 2022-04-07 06:19:47,399 >>   Batch size = 8\n","100% 1495/1496 [02:23<00:00, 10.38it/s]04/07/2022 06:22:28 - INFO - utils_qa - Post-processing 11873 example predictions split into 11968 features.\n","\n","100% 1496/1496 [02:40<00:00, 10.38it/s]\n","  0% 32/11873 [00:00<00:37, 319.57it/s]\u001b[A\n","  1% 65/11873 [00:00<00:36, 324.33it/s]\u001b[A\n","  1% 98/11873 [00:00<00:36, 324.39it/s]\u001b[A\n","  1% 132/11873 [00:00<00:35, 328.68it/s]\u001b[A\n","  1% 167/11873 [00:00<00:35, 334.36it/s]\u001b[A\n","  2% 202/11873 [00:00<00:34, 339.46it/s]\u001b[A\n","  2% 237/11873 [00:00<00:34, 340.40it/s]\u001b[A\n","  2% 272/11873 [00:00<00:33, 343.27it/s]\u001b[A\n","  3% 307/11873 [00:00<00:33, 343.14it/s]\u001b[A\n","  3% 342/11873 [00:01<00:34, 336.07it/s]\u001b[A\n","  3% 376/11873 [00:01<00:34, 332.36it/s]\u001b[A\n","  3% 410/11873 [00:01<00:34, 333.17it/s]\u001b[A\n","  4% 446/11873 [00:01<00:33, 340.31it/s]\u001b[A\n","  4% 481/11873 [00:01<00:33, 341.27it/s]\u001b[A\n","  4% 516/11873 [00:01<00:33, 343.73it/s]\u001b[A\n","  5% 551/11873 [00:01<00:33, 341.81it/s]\u001b[A\n","  5% 586/11873 [00:01<00:32, 344.23it/s]\u001b[A\n","  5% 622/11873 [00:01<00:32, 348.71it/s]\u001b[A\n","  6% 657/11873 [00:01<00:32, 348.55it/s]\u001b[A\n","  6% 692/11873 [00:02<00:32, 344.53it/s]\u001b[A\n","  6% 727/11873 [00:02<00:32, 340.48it/s]\u001b[A\n","  6% 762/11873 [00:02<00:32, 337.32it/s]\u001b[A\n","  7% 797/11873 [00:02<00:32, 339.79it/s]\u001b[A\n","  7% 832/11873 [00:02<00:32, 342.72it/s]\u001b[A\n","  7% 870/11873 [00:02<00:31, 352.30it/s]\u001b[A\n","  8% 906/11873 [00:02<00:31, 347.71it/s]\u001b[A\n","  8% 942/11873 [00:02<00:31, 349.95it/s]\u001b[A\n","  8% 978/11873 [00:02<00:31, 347.24it/s]\u001b[A\n","  9% 1013/11873 [00:02<00:32, 333.97it/s]\u001b[A\n","  9% 1047/11873 [00:03<00:34, 309.66it/s]\u001b[A\n","  9% 1079/11873 [00:03<00:36, 294.72it/s]\u001b[A\n","  9% 1109/11873 [00:03<00:37, 286.10it/s]\u001b[A\n"," 10% 1138/11873 [00:03<00:38, 277.53it/s]\u001b[A\n"," 10% 1166/11873 [00:03<00:39, 269.49it/s]\u001b[A\n"," 10% 1194/11873 [00:03<00:40, 266.03it/s]\u001b[A\n"," 10% 1221/11873 [00:03<00:40, 265.55it/s]\u001b[A\n"," 11% 1248/11873 [00:03<00:39, 265.75it/s]\u001b[A\n"," 11% 1275/11873 [00:03<00:40, 262.00it/s]\u001b[A\n"," 11% 1302/11873 [00:04<00:40, 258.26it/s]\u001b[A\n"," 11% 1329/11873 [00:04<00:40, 258.98it/s]\u001b[A\n"," 11% 1357/11873 [00:04<00:40, 262.77it/s]\u001b[A\n"," 12% 1384/11873 [00:04<00:39, 263.01it/s]\u001b[A\n"," 12% 1412/11873 [00:04<00:39, 265.85it/s]\u001b[A\n"," 12% 1439/11873 [00:04<00:40, 259.50it/s]\u001b[A\n"," 12% 1465/11873 [00:04<00:40, 258.89it/s]\u001b[A\n"," 13% 1493/11873 [00:04<00:39, 262.33it/s]\u001b[A\n"," 13% 1520/11873 [00:04<00:39, 264.26it/s]\u001b[A\n"," 13% 1547/11873 [00:05<00:39, 264.23it/s]\u001b[A\n"," 13% 1574/11873 [00:05<00:39, 259.58it/s]\u001b[A\n"," 13% 1601/11873 [00:05<00:39, 262.37it/s]\u001b[A\n"," 14% 1628/11873 [00:05<00:39, 261.11it/s]\u001b[A\n"," 14% 1655/11873 [00:05<00:38, 262.90it/s]\u001b[A\n"," 14% 1683/11873 [00:05<00:38, 265.12it/s]\u001b[A\n"," 14% 1710/11873 [00:05<00:38, 264.54it/s]\u001b[A\n"," 15% 1737/11873 [00:05<00:38, 263.22it/s]\u001b[A\n"," 15% 1764/11873 [00:05<00:38, 262.67it/s]\u001b[A\n"," 15% 1791/11873 [00:05<00:38, 262.67it/s]\u001b[A\n"," 15% 1818/11873 [00:06<00:38, 262.14it/s]\u001b[A\n"," 16% 1845/11873 [00:06<00:38, 258.94it/s]\u001b[A\n"," 16% 1873/11873 [00:06<00:37, 264.36it/s]\u001b[A\n"," 16% 1901/11873 [00:06<00:37, 266.46it/s]\u001b[A\n"," 16% 1928/11873 [00:06<00:37, 263.12it/s]\u001b[A\n"," 16% 1955/11873 [00:06<00:37, 263.27it/s]\u001b[A\n"," 17% 1982/11873 [00:06<00:37, 264.18it/s]\u001b[A\n"," 17% 2010/11873 [00:06<00:36, 266.88it/s]\u001b[A\n"," 17% 2037/11873 [00:06<00:36, 266.80it/s]\u001b[A\n"," 17% 2064/11873 [00:06<00:36, 266.72it/s]\u001b[A\n"," 18% 2091/11873 [00:07<00:36, 266.78it/s]\u001b[A\n"," 18% 2118/11873 [00:07<00:36, 266.32it/s]\u001b[A\n"," 18% 2145/11873 [00:07<00:36, 266.90it/s]\u001b[A\n"," 18% 2172/11873 [00:07<00:36, 266.27it/s]\u001b[A\n"," 19% 2199/11873 [00:07<00:36, 265.71it/s]\u001b[A\n"," 19% 2226/11873 [00:07<00:36, 266.47it/s]\u001b[A\n"," 19% 2253/11873 [00:07<00:36, 264.79it/s]\u001b[A\n"," 19% 2280/11873 [00:07<00:36, 262.42it/s]\u001b[A\n"," 19% 2307/11873 [00:07<00:36, 262.94it/s]\u001b[A\n"," 20% 2334/11873 [00:08<00:36, 260.45it/s]\u001b[A\n"," 20% 2361/11873 [00:08<00:36, 263.17it/s]\u001b[A\n"," 20% 2388/11873 [00:08<00:35, 263.76it/s]\u001b[A\n"," 20% 2415/11873 [00:08<00:35, 263.03it/s]\u001b[A\n"," 21% 2442/11873 [00:08<00:35, 262.72it/s]\u001b[A\n"," 21% 2469/11873 [00:08<00:35, 262.38it/s]\u001b[A\n"," 21% 2496/11873 [00:08<00:35, 262.97it/s]\u001b[A\n"," 21% 2523/11873 [00:08<00:35, 261.33it/s]\u001b[A\n"," 21% 2551/11873 [00:08<00:35, 263.88it/s]\u001b[A\n"," 22% 2578/11873 [00:08<00:35, 264.30it/s]\u001b[A\n"," 22% 2605/11873 [00:09<00:35, 263.92it/s]\u001b[A\n"," 22% 2633/11873 [00:09<00:34, 266.62it/s]\u001b[A\n"," 22% 2660/11873 [00:09<00:34, 263.29it/s]\u001b[A\n"," 23% 2687/11873 [00:09<00:34, 263.79it/s]\u001b[A\n"," 23% 2714/11873 [00:09<00:34, 264.82it/s]\u001b[A\n"," 23% 2741/11873 [00:09<00:34, 261.05it/s]\u001b[A\n"," 23% 2768/11873 [00:09<00:34, 261.28it/s]\u001b[A\n"," 24% 2795/11873 [00:09<00:34, 261.21it/s]\u001b[A\n"," 24% 2823/11873 [00:09<00:34, 264.41it/s]\u001b[A\n"," 24% 2851/11873 [00:09<00:33, 268.40it/s]\u001b[A\n"," 24% 2878/11873 [00:10<00:33, 265.92it/s]\u001b[A\n"," 24% 2905/11873 [00:10<00:33, 263.79it/s]\u001b[A\n"," 25% 2932/11873 [00:10<00:34, 262.78it/s]\u001b[A\n"," 25% 2959/11873 [00:10<00:33, 264.00it/s]\u001b[A\n"," 25% 2986/11873 [00:10<00:33, 264.16it/s]\u001b[A\n"," 25% 3013/11873 [00:10<00:34, 256.56it/s]\u001b[A\n"," 26% 3039/11873 [00:10<00:34, 254.37it/s]\u001b[A\n"," 26% 3065/11873 [00:10<00:34, 254.49it/s]\u001b[A\n"," 26% 3091/11873 [00:10<00:34, 251.24it/s]\u001b[A\n"," 26% 3117/11873 [00:11<00:38, 227.47it/s]\u001b[A\n"," 26% 3141/11873 [00:11<00:38, 229.77it/s]\u001b[A\n"," 27% 3165/11873 [00:11<00:40, 213.05it/s]\u001b[A\n"," 27% 3192/11873 [00:11<00:38, 226.53it/s]\u001b[A\n"," 27% 3220/11873 [00:11<00:36, 239.95it/s]\u001b[A\n"," 27% 3247/11873 [00:11<00:34, 247.47it/s]\u001b[A\n"," 28% 3273/11873 [00:11<00:34, 250.26it/s]\u001b[A\n"," 28% 3299/11873 [00:11<00:42, 203.64it/s]\u001b[A\n"," 28% 3321/11873 [00:12<00:44, 193.33it/s]\u001b[A\n"," 28% 3346/11873 [00:12<00:41, 206.98it/s]\u001b[A\n"," 28% 3368/11873 [00:12<00:47, 179.96it/s]\u001b[A\n"," 29% 3394/11873 [00:12<00:42, 198.41it/s]\u001b[A\n"," 29% 3421/11873 [00:12<00:39, 215.44it/s]\u001b[A\n"," 29% 3448/11873 [00:12<00:36, 228.13it/s]\u001b[A\n"," 29% 3474/11873 [00:12<00:35, 236.85it/s]\u001b[A\n"," 29% 3500/11873 [00:12<00:34, 243.13it/s]\u001b[A\n"," 30% 3527/11873 [00:12<00:33, 249.70it/s]\u001b[A\n"," 30% 3554/11873 [00:12<00:32, 253.48it/s]\u001b[A\n"," 30% 3581/11873 [00:13<00:32, 255.79it/s]\u001b[A\n"," 30% 3607/11873 [00:13<00:32, 254.22it/s]\u001b[A\n"," 31% 3634/11873 [00:13<00:32, 256.75it/s]\u001b[A\n"," 31% 3660/11873 [00:13<00:32, 254.92it/s]\u001b[A\n"," 31% 3686/11873 [00:13<00:32, 254.85it/s]\u001b[A\n"," 31% 3712/11873 [00:13<00:32, 251.52it/s]\u001b[A\n"," 31% 3738/11873 [00:13<00:32, 251.55it/s]\u001b[A\n"," 32% 3765/11873 [00:13<00:31, 254.53it/s]\u001b[A\n"," 32% 3791/11873 [00:13<00:31, 255.10it/s]\u001b[A\n"," 32% 3817/11873 [00:14<00:31, 255.10it/s]\u001b[A\n"," 32% 3843/11873 [00:14<00:31, 255.97it/s]\u001b[A\n"," 33% 3869/11873 [00:14<00:31, 257.03it/s]\u001b[A\n"," 33% 3896/11873 [00:14<00:30, 258.38it/s]\u001b[A\n"," 33% 3922/11873 [00:14<00:30, 258.66it/s]\u001b[A\n"," 33% 3948/11873 [00:14<00:30, 258.47it/s]\u001b[A\n"," 33% 3974/11873 [00:14<00:30, 255.08it/s]\u001b[A\n"," 34% 4001/11873 [00:14<00:30, 259.13it/s]\u001b[A\n"," 34% 4028/11873 [00:14<00:29, 262.21it/s]\u001b[A\n"," 34% 4055/11873 [00:14<00:29, 262.62it/s]\u001b[A\n"," 34% 4082/11873 [00:15<00:29, 264.24it/s]\u001b[A\n"," 35% 4109/11873 [00:15<00:29, 261.76it/s]\u001b[A\n"," 35% 4136/11873 [00:15<00:29, 260.68it/s]\u001b[A\n"," 35% 4163/11873 [00:15<00:29, 259.14it/s]\u001b[A\n"," 35% 4189/11873 [00:15<00:29, 256.68it/s]\u001b[A\n"," 36% 4215/11873 [00:15<00:29, 256.50it/s]\u001b[A\n"," 36% 4243/11873 [00:15<00:29, 261.34it/s]\u001b[A\n"," 36% 4270/11873 [00:15<00:29, 259.94it/s]\u001b[A\n"," 36% 4298/11873 [00:15<00:28, 263.51it/s]\u001b[A\n"," 36% 4325/11873 [00:15<00:29, 259.38it/s]\u001b[A\n"," 37% 4352/11873 [00:16<00:28, 259.98it/s]\u001b[A\n"," 37% 4379/11873 [00:16<00:28, 261.83it/s]\u001b[A\n"," 37% 4406/11873 [00:16<00:28, 261.31it/s]\u001b[A\n"," 37% 4433/11873 [00:16<00:33, 225.38it/s]\u001b[A\n"," 38% 4460/11873 [00:16<00:31, 235.40it/s]\u001b[A\n"," 38% 4487/11873 [00:16<00:30, 243.98it/s]\u001b[A\n"," 38% 4512/11873 [00:16<00:30, 245.30it/s]\u001b[A\n"," 38% 4539/11873 [00:16<00:29, 250.07it/s]\u001b[A\n"," 38% 4566/11873 [00:16<00:28, 254.69it/s]\u001b[A\n"," 39% 4594/11873 [00:17<00:27, 260.96it/s]\u001b[A\n"," 39% 4621/11873 [00:17<00:27, 262.14it/s]\u001b[A\n"," 39% 4648/11873 [00:17<00:27, 261.60it/s]\u001b[A\n"," 39% 4675/11873 [00:17<00:28, 253.78it/s]\u001b[A\n"," 40% 4701/11873 [00:17<00:28, 253.12it/s]\u001b[A\n"," 40% 4727/11873 [00:17<00:28, 254.82it/s]\u001b[A\n"," 40% 4753/11873 [00:17<00:27, 255.14it/s]\u001b[A\n"," 40% 4779/11873 [00:17<00:27, 256.29it/s]\u001b[A\n"," 40% 4805/11873 [00:17<00:27, 253.27it/s]\u001b[A\n"," 41% 4832/11873 [00:17<00:27, 256.62it/s]\u001b[A\n"," 41% 4858/11873 [00:18<00:27, 255.91it/s]\u001b[A\n"," 41% 4885/11873 [00:18<00:27, 257.74it/s]\u001b[A\n"," 41% 4911/11873 [00:18<00:26, 258.17it/s]\u001b[A\n"," 42% 4937/11873 [00:18<00:27, 251.40it/s]\u001b[A\n"," 42% 4964/11873 [00:18<00:27, 254.16it/s]\u001b[A\n"," 42% 4990/11873 [00:18<00:27, 254.47it/s]\u001b[A\n"," 42% 5016/11873 [00:18<00:27, 253.60it/s]\u001b[A\n"," 42% 5042/11873 [00:18<00:26, 253.88it/s]\u001b[A\n"," 43% 5069/11873 [00:18<00:26, 256.86it/s]\u001b[A\n"," 43% 5095/11873 [00:19<00:26, 253.18it/s]\u001b[A\n"," 43% 5121/11873 [00:19<00:26, 253.46it/s]\u001b[A\n"," 43% 5148/11873 [00:19<00:26, 255.72it/s]\u001b[A\n"," 44% 5175/11873 [00:19<00:25, 258.39it/s]\u001b[A\n"," 44% 5201/11873 [00:19<00:25, 257.37it/s]\u001b[A\n"," 44% 5228/11873 [00:19<00:25, 259.31it/s]\u001b[A\n"," 44% 5254/11873 [00:19<00:26, 254.52it/s]\u001b[A\n"," 44% 5280/11873 [00:19<00:27, 241.56it/s]\u001b[A\n"," 45% 5307/11873 [00:19<00:26, 247.87it/s]\u001b[A\n"," 45% 5333/11873 [00:19<00:26, 250.89it/s]\u001b[A\n"," 45% 5360/11873 [00:20<00:25, 254.84it/s]\u001b[A\n"," 45% 5387/11873 [00:20<00:25, 256.60it/s]\u001b[A\n"," 46% 5413/11873 [00:20<00:25, 250.18it/s]\u001b[A\n"," 46% 5439/11873 [00:20<00:25, 249.34it/s]\u001b[A\n"," 46% 5464/11873 [00:20<00:25, 248.73it/s]\u001b[A\n"," 46% 5491/11873 [00:20<00:25, 253.41it/s]\u001b[A\n"," 46% 5519/11873 [00:20<00:24, 260.14it/s]\u001b[A\n"," 47% 5546/11873 [00:20<00:24, 258.85it/s]\u001b[A\n"," 47% 5573/11873 [00:20<00:24, 259.77it/s]\u001b[A\n"," 47% 5600/11873 [00:20<00:23, 262.47it/s]\u001b[A\n"," 47% 5627/11873 [00:21<00:24, 258.17it/s]\u001b[A\n"," 48% 5654/11873 [00:21<00:23, 260.02it/s]\u001b[A\n"," 48% 5681/11873 [00:21<00:24, 256.76it/s]\u001b[A\n"," 48% 5707/11873 [00:21<00:24, 256.42it/s]\u001b[A\n"," 48% 5734/11873 [00:21<00:23, 260.31it/s]\u001b[A\n"," 49% 5761/11873 [00:21<00:24, 253.70it/s]\u001b[A\n"," 49% 5788/11873 [00:21<00:23, 257.15it/s]\u001b[A\n"," 49% 5814/11873 [00:21<00:23, 257.61it/s]\u001b[A\n"," 49% 5841/11873 [00:21<00:23, 258.79it/s]\u001b[A\n"," 49% 5868/11873 [00:22<00:22, 261.36it/s]\u001b[A\n"," 50% 5895/11873 [00:22<00:22, 262.04it/s]\u001b[A\n"," 50% 5922/11873 [00:22<00:22, 259.43it/s]\u001b[A\n"," 50% 5949/11873 [00:22<00:22, 260.83it/s]\u001b[A\n"," 50% 5976/11873 [00:22<00:22, 260.09it/s]\u001b[A\n"," 51% 6003/11873 [00:22<00:22, 261.74it/s]\u001b[A\n"," 51% 6030/11873 [00:22<00:22, 264.11it/s]\u001b[A\n"," 51% 6057/11873 [00:22<00:21, 264.95it/s]\u001b[A\n"," 51% 6084/11873 [00:22<00:21, 263.82it/s]\u001b[A\n"," 51% 6111/11873 [00:22<00:22, 260.06it/s]\u001b[A\n"," 52% 6138/11873 [00:23<00:22, 255.67it/s]\u001b[A\n"," 52% 6164/11873 [00:23<00:22, 256.14it/s]\u001b[A\n"," 52% 6190/11873 [00:23<00:22, 257.15it/s]\u001b[A\n"," 52% 6217/11873 [00:23<00:21, 259.15it/s]\u001b[A\n"," 53% 6243/11873 [00:23<00:21, 257.31it/s]\u001b[A\n"," 53% 6269/11873 [00:23<00:21, 256.26it/s]\u001b[A\n"," 53% 6296/11873 [00:23<00:21, 258.13it/s]\u001b[A\n"," 53% 6322/11873 [00:23<00:21, 258.57it/s]\u001b[A\n"," 53% 6348/11873 [00:23<00:21, 256.64it/s]\u001b[A\n"," 54% 6374/11873 [00:23<00:21, 256.11it/s]\u001b[A\n"," 54% 6400/11873 [00:24<00:21, 253.72it/s]\u001b[A\n"," 54% 6426/11873 [00:24<00:21, 252.53it/s]\u001b[A\n"," 54% 6452/11873 [00:24<00:21, 251.50it/s]\u001b[A\n"," 55% 6478/11873 [00:24<00:21, 253.70it/s]\u001b[A\n"," 55% 6504/11873 [00:24<00:21, 252.18it/s]\u001b[A\n"," 55% 6532/11873 [00:24<00:20, 257.79it/s]\u001b[A\n"," 55% 6558/11873 [00:24<00:20, 255.31it/s]\u001b[A\n"," 55% 6584/11873 [00:24<00:20, 254.53it/s]\u001b[A\n"," 56% 6610/11873 [00:24<00:20, 250.93it/s]\u001b[A\n"," 56% 6636/11873 [00:25<00:20, 251.85it/s]\u001b[A\n"," 56% 6662/11873 [00:25<00:20, 252.85it/s]\u001b[A\n"," 56% 6688/11873 [00:25<00:20, 251.40it/s]\u001b[A\n"," 57% 6714/11873 [00:25<00:20, 247.46it/s]\u001b[A\n"," 57% 6741/11873 [00:25<00:20, 251.38it/s]\u001b[A\n"," 57% 6767/11873 [00:25<00:20, 253.18it/s]\u001b[A\n"," 57% 6793/11873 [00:25<00:20, 253.81it/s]\u001b[A\n"," 57% 6819/11873 [00:25<00:19, 254.18it/s]\u001b[A\n"," 58% 6847/11873 [00:25<00:19, 258.99it/s]\u001b[A\n"," 58% 6873/11873 [00:25<00:19, 258.66it/s]\u001b[A\n"," 58% 6899/11873 [00:26<00:19, 255.48it/s]\u001b[A\n"," 58% 6926/11873 [00:26<00:19, 259.63it/s]\u001b[A\n"," 59% 6952/11873 [00:26<00:19, 258.10it/s]\u001b[A\n"," 59% 6980/11873 [00:26<00:18, 263.45it/s]\u001b[A\n"," 59% 7008/11873 [00:26<00:18, 266.25it/s]\u001b[A\n"," 59% 7035/11873 [00:26<00:18, 263.13it/s]\u001b[A\n"," 59% 7062/11873 [00:26<00:18, 264.00it/s]\u001b[A\n"," 60% 7089/11873 [00:26<00:18, 261.52it/s]\u001b[A\n"," 60% 7116/11873 [00:26<00:18, 259.05it/s]\u001b[A\n"," 60% 7142/11873 [00:26<00:18, 254.54it/s]\u001b[A\n"," 60% 7169/11873 [00:27<00:18, 256.93it/s]\u001b[A\n"," 61% 7195/11873 [00:27<00:18, 256.01it/s]\u001b[A\n"," 61% 7221/11873 [00:27<00:18, 255.74it/s]\u001b[A\n"," 61% 7248/11873 [00:27<00:17, 257.41it/s]\u001b[A\n"," 61% 7274/11873 [00:27<00:17, 256.31it/s]\u001b[A\n"," 61% 7300/11873 [00:27<00:18, 252.13it/s]\u001b[A\n"," 62% 7326/11873 [00:27<00:18, 251.08it/s]\u001b[A\n"," 62% 7353/11873 [00:27<00:17, 254.77it/s]\u001b[A\n"," 62% 7379/11873 [00:27<00:17, 253.86it/s]\u001b[A\n"," 62% 7405/11873 [00:28<00:17, 254.54it/s]\u001b[A\n"," 63% 7431/11873 [00:28<00:17, 251.36it/s]\u001b[A\n"," 63% 7458/11873 [00:28<00:17, 256.30it/s]\u001b[A\n"," 63% 7485/11873 [00:28<00:17, 257.37it/s]\u001b[A\n"," 63% 7512/11873 [00:28<00:16, 260.64it/s]\u001b[A\n"," 63% 7539/11873 [00:28<00:16, 259.81it/s]\u001b[A\n"," 64% 7567/11873 [00:28<00:16, 262.92it/s]\u001b[A\n"," 64% 7594/11873 [00:28<00:16, 259.08it/s]\u001b[A\n"," 64% 7620/11873 [00:28<00:16, 258.81it/s]\u001b[A\n"," 64% 7646/11873 [00:28<00:16, 258.43it/s]\u001b[A\n"," 65% 7672/11873 [00:29<00:16, 258.26it/s]\u001b[A\n"," 65% 7698/11873 [00:29<00:16, 258.55it/s]\u001b[A\n"," 65% 7724/11873 [00:29<00:16, 256.01it/s]\u001b[A\n"," 65% 7750/11873 [00:29<00:16, 256.48it/s]\u001b[A\n"," 65% 7776/11873 [00:29<00:16, 255.08it/s]\u001b[A\n"," 66% 7802/11873 [00:29<00:16, 254.36it/s]\u001b[A\n"," 66% 7828/11873 [00:29<00:15, 253.33it/s]\u001b[A\n"," 66% 7854/11873 [00:29<00:16, 247.24it/s]\u001b[A\n"," 66% 7879/11873 [00:29<00:16, 245.22it/s]\u001b[A\n"," 67% 7906/11873 [00:29<00:15, 249.96it/s]\u001b[A\n"," 67% 7932/11873 [00:30<00:15, 251.75it/s]\u001b[A\n"," 67% 7958/11873 [00:30<00:15, 253.76it/s]\u001b[A\n"," 67% 7984/11873 [00:30<00:16, 241.13it/s]\u001b[A\n"," 67% 8011/11873 [00:30<00:15, 247.49it/s]\u001b[A\n"," 68% 8038/11873 [00:30<00:15, 252.81it/s]\u001b[A\n"," 68% 8064/11873 [00:30<00:15, 251.72it/s]\u001b[A\n"," 68% 8090/11873 [00:30<00:14, 253.65it/s]\u001b[A\n"," 68% 8117/11873 [00:30<00:14, 256.07it/s]\u001b[A\n"," 69% 8143/11873 [00:30<00:14, 256.73it/s]\u001b[A\n"," 69% 8169/11873 [00:31<00:14, 257.14it/s]\u001b[A\n"," 69% 8195/11873 [00:31<00:14, 252.88it/s]\u001b[A\n"," 69% 8221/11873 [00:31<00:14, 246.85it/s]\u001b[A\n"," 69% 8248/11873 [00:31<00:14, 252.38it/s]\u001b[A\n"," 70% 8275/11873 [00:31<00:14, 255.64it/s]\u001b[A\n"," 70% 8302/11873 [00:31<00:13, 258.93it/s]\u001b[A\n"," 70% 8328/11873 [00:31<00:13, 259.20it/s]\u001b[A\n"," 70% 8355/11873 [00:31<00:13, 261.40it/s]\u001b[A\n"," 71% 8382/11873 [00:31<00:13, 263.80it/s]\u001b[A\n"," 71% 8409/11873 [00:31<00:13, 262.25it/s]\u001b[A\n"," 71% 8436/11873 [00:32<00:13, 260.93it/s]\u001b[A\n"," 71% 8463/11873 [00:32<00:13, 258.12it/s]\u001b[A\n"," 71% 8489/11873 [00:32<00:13, 257.13it/s]\u001b[A\n"," 72% 8516/11873 [00:32<00:12, 259.45it/s]\u001b[A\n"," 72% 8543/11873 [00:32<00:12, 260.89it/s]\u001b[A\n"," 72% 8571/11873 [00:32<00:12, 264.84it/s]\u001b[A\n"," 72% 8599/11873 [00:32<00:12, 268.47it/s]\u001b[A\n"," 73% 8626/11873 [00:32<00:12, 263.68it/s]\u001b[A\n"," 73% 8653/11873 [00:32<00:12, 264.40it/s]\u001b[A\n"," 73% 8680/11873 [00:32<00:12, 263.84it/s]\u001b[A\n"," 73% 8707/11873 [00:33<00:12, 262.71it/s]\u001b[A\n"," 74% 8734/11873 [00:33<00:11, 262.43it/s]\u001b[A\n"," 74% 8761/11873 [00:33<00:11, 260.78it/s]\u001b[A\n"," 74% 8788/11873 [00:33<00:11, 259.02it/s]\u001b[A\n"," 74% 8815/11873 [00:33<00:11, 260.26it/s]\u001b[A\n"," 74% 8842/11873 [00:33<00:11, 262.61it/s]\u001b[A\n"," 75% 8869/11873 [00:33<00:11, 260.88it/s]\u001b[A\n"," 75% 8896/11873 [00:33<00:11, 262.15it/s]\u001b[A\n"," 75% 8923/11873 [00:33<00:11, 263.33it/s]\u001b[A\n"," 75% 8950/11873 [00:34<00:11, 260.68it/s]\u001b[A\n"," 76% 8977/11873 [00:34<00:11, 262.75it/s]\u001b[A\n"," 76% 9004/11873 [00:34<00:10, 263.82it/s]\u001b[A\n"," 76% 9031/11873 [00:34<00:10, 264.20it/s]\u001b[A\n"," 76% 9059/11873 [00:34<00:10, 267.61it/s]\u001b[A\n"," 77% 9087/11873 [00:34<00:10, 270.01it/s]\u001b[A\n"," 77% 9115/11873 [00:34<00:10, 267.16it/s]\u001b[A\n"," 77% 9142/11873 [00:34<00:10, 266.47it/s]\u001b[A\n"," 77% 9169/11873 [00:34<00:10, 264.84it/s]\u001b[A\n"," 77% 9196/11873 [00:34<00:10, 264.94it/s]\u001b[A\n"," 78% 9223/11873 [00:35<00:10, 263.31it/s]\u001b[A\n"," 78% 9250/11873 [00:35<00:09, 263.47it/s]\u001b[A\n"," 78% 9277/11873 [00:35<00:09, 260.81it/s]\u001b[A\n"," 78% 9304/11873 [00:35<00:09, 261.23it/s]\u001b[A\n"," 79% 9331/11873 [00:35<00:09, 261.59it/s]\u001b[A\n"," 79% 9358/11873 [00:35<00:09, 262.68it/s]\u001b[A\n"," 79% 9385/11873 [00:35<00:09, 263.51it/s]\u001b[A\n"," 79% 9412/11873 [00:35<00:09, 260.90it/s]\u001b[A\n"," 79% 9439/11873 [00:35<00:09, 261.24it/s]\u001b[A\n"," 80% 9466/11873 [00:35<00:09, 261.82it/s]\u001b[A\n"," 80% 9493/11873 [00:36<00:09, 262.54it/s]\u001b[A\n"," 80% 9520/11873 [00:36<00:08, 264.72it/s]\u001b[A\n"," 80% 9549/11873 [00:36<00:08, 269.83it/s]\u001b[A\n"," 81% 9577/11873 [00:36<00:08, 270.85it/s]\u001b[A\n"," 81% 9605/11873 [00:36<00:08, 268.24it/s]\u001b[A\n"," 81% 9632/11873 [00:36<00:08, 268.31it/s]\u001b[A\n"," 81% 9659/11873 [00:36<00:08, 265.02it/s]\u001b[A\n"," 82% 9687/11873 [00:36<00:08, 267.45it/s]\u001b[A\n"," 82% 9714/11873 [00:36<00:08, 267.93it/s]\u001b[A\n"," 82% 9741/11873 [00:36<00:07, 268.47it/s]\u001b[A\n"," 82% 9769/11873 [00:37<00:07, 270.71it/s]\u001b[A\n"," 83% 9797/11873 [00:37<00:07, 269.86it/s]\u001b[A\n"," 83% 9824/11873 [00:37<00:07, 269.56it/s]\u001b[A\n"," 83% 9852/11873 [00:37<00:07, 271.65it/s]\u001b[A\n"," 83% 9880/11873 [00:37<00:07, 266.11it/s]\u001b[A\n"," 83% 9907/11873 [00:37<00:07, 262.41it/s]\u001b[A\n"," 84% 9934/11873 [00:37<00:07, 262.12it/s]\u001b[A\n"," 84% 9961/11873 [00:37<00:07, 262.58it/s]\u001b[A\n"," 84% 9989/11873 [00:37<00:07, 266.13it/s]\u001b[A\n"," 84% 10016/11873 [00:38<00:06, 266.97it/s]\u001b[A\n"," 85% 10043/11873 [00:38<00:07, 256.76it/s]\u001b[A\n"," 85% 10070/11873 [00:38<00:06, 260.43it/s]\u001b[A\n"," 85% 10098/11873 [00:38<00:06, 263.51it/s]\u001b[A\n"," 85% 10125/11873 [00:38<00:06, 264.09it/s]\u001b[A\n"," 86% 10152/11873 [00:38<00:06, 265.18it/s]\u001b[A\n"," 86% 10179/11873 [00:38<00:06, 265.16it/s]\u001b[A\n"," 86% 10206/11873 [00:38<00:06, 264.73it/s]\u001b[A\n"," 86% 10233/11873 [00:38<00:06, 265.33it/s]\u001b[A\n"," 86% 10261/11873 [00:38<00:06, 266.98it/s]\u001b[A\n"," 87% 10288/11873 [00:39<00:05, 266.06it/s]\u001b[A\n"," 87% 10315/11873 [00:39<00:05, 265.10it/s]\u001b[A\n"," 87% 10344/11873 [00:39<00:05, 269.60it/s]\u001b[A\n"," 87% 10371/11873 [00:39<00:05, 267.89it/s]\u001b[A\n"," 88% 10398/11873 [00:39<00:05, 267.61it/s]\u001b[A\n"," 88% 10425/11873 [00:39<00:05, 265.96it/s]\u001b[A\n"," 88% 10452/11873 [00:39<00:05, 264.54it/s]\u001b[A\n"," 88% 10479/11873 [00:39<00:05, 265.98it/s]\u001b[A\n"," 88% 10506/11873 [00:39<00:05, 266.69it/s]\u001b[A\n"," 89% 10534/11873 [00:39<00:04, 268.70it/s]\u001b[A\n"," 89% 10561/11873 [00:40<00:04, 266.03it/s]\u001b[A\n"," 89% 10588/11873 [00:40<00:04, 266.98it/s]\u001b[A\n"," 89% 10615/11873 [00:40<00:04, 267.79it/s]\u001b[A\n"," 90% 10642/11873 [00:40<00:04, 263.46it/s]\u001b[A\n"," 90% 10669/11873 [00:40<00:06, 175.10it/s]\u001b[A\n"," 90% 10695/11873 [00:40<00:06, 192.97it/s]\u001b[A\n"," 90% 10722/11873 [00:40<00:05, 210.68it/s]\u001b[A\n"," 91% 10748/11873 [00:40<00:05, 220.98it/s]\u001b[A\n"," 91% 10775/11873 [00:41<00:04, 232.31it/s]\u001b[A\n"," 91% 10800/11873 [00:41<00:04, 236.51it/s]\u001b[A\n"," 91% 10825/11873 [00:41<00:04, 240.02it/s]\u001b[A\n"," 91% 10851/11873 [00:41<00:04, 244.06it/s]\u001b[A\n"," 92% 10877/11873 [00:41<00:04, 243.80it/s]\u001b[A\n"," 92% 10903/11873 [00:41<00:03, 247.57it/s]\u001b[A\n"," 92% 10929/11873 [00:41<00:03, 246.03it/s]\u001b[A\n"," 92% 10955/11873 [00:41<00:03, 248.34it/s]\u001b[A\n"," 93% 10983/11873 [00:41<00:03, 255.01it/s]\u001b[A\n"," 93% 11009/11873 [00:41<00:03, 255.27it/s]\u001b[A\n"," 93% 11035/11873 [00:42<00:03, 256.47it/s]\u001b[A\n"," 93% 11062/11873 [00:42<00:03, 258.06it/s]\u001b[A\n"," 93% 11088/11873 [00:42<00:03, 256.90it/s]\u001b[A\n"," 94% 11114/11873 [00:42<00:02, 256.88it/s]\u001b[A\n"," 94% 11140/11873 [00:42<00:02, 256.25it/s]\u001b[A\n"," 94% 11167/11873 [00:42<00:02, 258.70it/s]\u001b[A\n"," 94% 11194/11873 [00:42<00:02, 261.37it/s]\u001b[A\n"," 95% 11221/11873 [00:42<00:02, 261.49it/s]\u001b[A\n"," 95% 11248/11873 [00:42<00:02, 261.61it/s]\u001b[A\n"," 95% 11275/11873 [00:43<00:02, 258.40it/s]\u001b[A\n"," 95% 11301/11873 [00:43<00:02, 258.42it/s]\u001b[A\n"," 95% 11328/11873 [00:43<00:02, 259.91it/s]\u001b[A\n"," 96% 11354/11873 [00:43<00:01, 259.86it/s]\u001b[A\n"," 96% 11380/11873 [00:43<00:01, 257.45it/s]\u001b[A\n"," 96% 11406/11873 [00:43<00:01, 257.16it/s]\u001b[A\n"," 96% 11433/11873 [00:43<00:01, 259.16it/s]\u001b[A\n"," 97% 11459/11873 [00:43<00:01, 258.88it/s]\u001b[A\n"," 97% 11486/11873 [00:43<00:01, 260.05it/s]\u001b[A\n"," 97% 11513/11873 [00:43<00:01, 260.15it/s]\u001b[A\n"," 97% 11540/11873 [00:44<00:01, 259.57it/s]\u001b[A\n"," 97% 11566/11873 [00:44<00:01, 259.52it/s]\u001b[A\n"," 98% 11593/11873 [00:44<00:01, 260.42it/s]\u001b[A\n"," 98% 11620/11873 [00:44<00:00, 256.95it/s]\u001b[A\n"," 98% 11647/11873 [00:44<00:00, 258.23it/s]\u001b[A\n"," 98% 11673/11873 [00:44<00:00, 257.78it/s]\u001b[A\n"," 99% 11699/11873 [00:44<00:00, 254.89it/s]\u001b[A\n"," 99% 11727/11873 [00:44<00:00, 259.79it/s]\u001b[A\n"," 99% 11754/11873 [00:44<00:00, 259.94it/s]\u001b[A\n"," 99% 11782/11873 [00:44<00:00, 262.97it/s]\u001b[A\n"," 99% 11809/11873 [00:45<00:00, 263.24it/s]\u001b[A\n","100% 11836/11873 [00:45<00:00, 254.44it/s]\u001b[A\n","100% 11873/11873 [00:45<00:00, 261.93it/s]\n","04/07/2022 06:23:13 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/eval_predictions.json.\n","04/07/2022 06:23:13 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/eval_nbest_predictions.json.\n","04/07/2022 06:23:16 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/QA/model_results/albert-base-v2/back-trans-synonym-aug/eval_null_odds.json.\n","04/07/2022 06:23:19 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n","100% 1496/1496 [03:31<00:00,  7.06it/s]\n","***** eval metrics *****\n","  epoch                  =     2.0\n","  eval_HasAns_exact      = 77.0412\n","  eval_HasAns_f1         = 83.1711\n","  eval_HasAns_total      =    5928\n","  eval_NoAns_exact       = 75.3911\n","  eval_NoAns_f1          = 75.3911\n","  eval_NoAns_total       =    5945\n","  eval_best_exact        = 76.2234\n","  eval_best_exact_thresh =     0.0\n","  eval_best_f1           =  79.284\n","  eval_best_f1_thresh    =     0.0\n","  eval_exact             = 76.2149\n","  eval_f1                = 79.2755\n","  eval_samples           =   11968\n","  eval_total             =   11873\n","[INFO|modelcard.py:460] 2022-04-07 06:23:19,789 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'sichenzhong/squad_v2_back_trans_synonym_aug', 'type': 'sichenzhong/squad_v2_back_trans_synonym_aug', 'args': 'squad_v2'}}\n"]}]},{"cell_type":"code","source":["!python run_qa.py \\\n","  --model_name_or_path roberta-base \\\n","  --dataset_name sichenzhong/squad_v2_back_trans_synonym_aug \\\n","  --do_train \\\n","  --do_eval \\\n","  --per_device_train_batch_size 24 \\\n","  --learning_rate 4e-5 \\\n","  --num_train_epochs 2 \\\n","  --max_seq_length 384 \\\n","  --doc_stride 128 \\\n","  --version_2_with_negative \\\n","  --output_dir /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug"],"metadata":{"id":"RYNXODGJey1t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649318764299,"user_tz":240,"elapsed":6162374,"user":{"displayName":"SICHEN ZHONG","userId":"08427994781088390833"}},"outputId":"19bb8aa4-a746-4538-854b-159a9ee85d43"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["04/07/2022 06:23:25 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","04/07/2022 06:23:25 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=IntervalStrategy.NO,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_strategy=HubStrategy.EVERY_SAVE,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=4e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=-1,\n","log_level_replica=-1,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/runs/Apr07_06-23-25_e45f44865b23,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=IntervalStrategy.STEPS,\n","lr_scheduler_type=SchedulerType.LINEAR,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=2.0,\n","optim=OptimizerNames.ADAMW_HF,\n","output_dir=/content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug,\n","overwrite_output_dir=False,\n","past_index=-1,\n","per_device_eval_batch_size=8,\n","per_device_train_batch_size=24,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug,\n","save_on_each_node=False,\n","save_steps=500,\n","save_strategy=IntervalStrategy.STEPS,\n","save_total_limit=None,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_legacy_prediction_loop=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","04/07/2022 06:23:26 - WARNING - datasets.builder - Using custom data configuration sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178\n","04/07/2022 06:23:26 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n","04/07/2022 06:23:26 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901\n","04/07/2022 06:23:26 - WARNING - datasets.builder - Reusing dataset parquet (/root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n","04/07/2022 06:23:26 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901\n","100% 2/2 [00:00<00:00, 623.36it/s]\n","[INFO|hub.py:583] 2022-04-07 06:23:26,898 >> https://huggingface.co/roberta-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpzhh2867g\n","Downloading: 100% 481/481 [00:00<00:00, 420kB/s]\n","[INFO|hub.py:587] 2022-04-07 06:23:27,259 >> storing https://huggingface.co/roberta-base/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","[INFO|hub.py:595] 2022-04-07 06:23:27,259 >> creating metadata file for /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","[INFO|configuration_utils.py:654] 2022-04-07 06:23:27,259 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","[INFO|configuration_utils.py:690] 2022-04-07 06:23:27,261 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|tokenization_auto.py:344] 2022-04-07 06:23:27,621 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n","[INFO|configuration_utils.py:654] 2022-04-07 06:23:27,978 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","[INFO|configuration_utils.py:690] 2022-04-07 06:23:27,979 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|hub.py:583] 2022-04-07 06:23:28,700 >> https://huggingface.co/roberta-base/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpdd5_3l1n\n","Downloading: 100% 878k/878k [00:00<00:00, 1.78MB/s]\n","[INFO|hub.py:587] 2022-04-07 06:23:29,572 >> storing https://huggingface.co/roberta-base/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","[INFO|hub.py:595] 2022-04-07 06:23:29,572 >> creating metadata file for /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","[INFO|hub.py:583] 2022-04-07 06:23:29,933 >> https://huggingface.co/roberta-base/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_2nuy40h\n","Downloading: 100% 446k/446k [00:00<00:00, 1.08MB/s]\n","[INFO|hub.py:587] 2022-04-07 06:23:30,717 >> storing https://huggingface.co/roberta-base/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","[INFO|hub.py:595] 2022-04-07 06:23:30,718 >> creating metadata file for /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","[INFO|hub.py:583] 2022-04-07 06:23:31,089 >> https://huggingface.co/roberta-base/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpclda9vo8\n","Downloading: 100% 1.29M/1.29M [00:00<00:00, 3.14MB/s]\n","[INFO|hub.py:587] 2022-04-07 06:23:31,976 >> storing https://huggingface.co/roberta-base/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","[INFO|hub.py:595] 2022-04-07 06:23:31,976 >> creating metadata file for /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 06:23:33,060 >> loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 06:23:33,061 >> loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 06:23:33,061 >> loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 06:23:33,061 >> loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 06:23:33,061 >> loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n","[INFO|tokenization_utils_base.py:1778] 2022-04-07 06:23:33,061 >> loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n","[INFO|configuration_utils.py:654] 2022-04-07 06:23:33,422 >> loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n","[INFO|configuration_utils.py:690] 2022-04-07 06:23:33,422 >> Model config RobertaConfig {\n","  \"_name_or_path\": \"roberta-base\",\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.0.dev0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","[INFO|hub.py:583] 2022-04-07 06:23:33,884 >> https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmph4j2flhb\n","Downloading: 100% 478M/478M [00:07<00:00, 63.7MB/s]\n","[INFO|hub.py:587] 2022-04-07 06:23:41,820 >> storing https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n","[INFO|hub.py:595] 2022-04-07 06:23:41,821 >> creating metadata file for /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n","[INFO|modeling_utils.py:1772] 2022-04-07 06:23:41,821 >> loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n","[WARNING|modeling_utils.py:2049] 2022-04-07 06:23:43,173 >> Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForQuestionAnswering: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","[WARNING|modeling_utils.py:2060] 2022-04-07 06:23:43,173 >> Some weights of RobertaForQuestionAnswering were not initialized from the model checkpoint at roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Running tokenizer on train dataset:   0% 0/131 [00:00<?, ?ba/s]04/07/2022 06:23:43 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-e9d7abc7206ccdce.arrow\n","Running tokenizer on train dataset: 100% 131/131 [00:43<00:00,  2.99ba/s]\n","Running tokenizer on validation dataset:   0% 0/12 [00:00<?, ?ba/s]04/07/2022 06:24:27 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/parquet/sichenzhong--squad_v2_back_trans_synonym_aug-db22dcaef5d3b178/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-7444a1706c3429cf.arrow\n","Running tokenizer on validation dataset: 100% 12/12 [01:08<00:00,  5.72s/ba]\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","[INFO|trainer.py:1290] 2022-04-07 06:25:41,003 >> ***** Running training *****\n","[INFO|trainer.py:1291] 2022-04-07 06:25:41,003 >>   Num examples = 131838\n","[INFO|trainer.py:1292] 2022-04-07 06:25:41,003 >>   Num Epochs = 2\n","[INFO|trainer.py:1293] 2022-04-07 06:25:41,003 >>   Instantaneous batch size per device = 24\n","[INFO|trainer.py:1294] 2022-04-07 06:25:41,003 >>   Total train batch size (w. parallel, distributed & accumulation) = 24\n","[INFO|trainer.py:1295] 2022-04-07 06:25:41,003 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1296] 2022-04-07 06:25:41,003 >>   Total optimization steps = 10988\n","{'loss': 2.0097, 'learning_rate': 3.8179832544594105e-05, 'epoch': 0.09}\n","  5% 500/10988 [04:22<1:31:45,  1.91it/s][INFO|trainer.py:2166] 2022-04-07 06:30:03,292 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:30:03,298 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:30:04,620 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:30:04,624 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:30:04,628 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-500/special_tokens_map.json\n","{'loss': 1.5142, 'learning_rate': 3.6359665089188207e-05, 'epoch': 0.18}\n","  9% 1000/10988 [08:49<1:27:26,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 06:34:30,797 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:34:30,802 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:34:32,125 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:34:32,129 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:34:32,133 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1000/special_tokens_map.json\n","{'loss': 1.4031, 'learning_rate': 3.4539497633782315e-05, 'epoch': 0.27}\n"," 14% 1500/10988 [13:17<1:23:09,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 06:38:58,036 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:38:58,042 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:38:59,368 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:38:59,373 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:38:59,376 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-1500/special_tokens_map.json\n","{'loss': 1.3204, 'learning_rate': 3.271933017837641e-05, 'epoch': 0.36}\n"," 18% 2000/10988 [17:44<1:18:39,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 06:43:25,614 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:43:25,620 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:43:26,956 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:43:26,960 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:43:26,963 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2000/special_tokens_map.json\n","{'loss': 1.2794, 'learning_rate': 3.089916272297051e-05, 'epoch': 0.46}\n"," 23% 2500/10988 [22:12<1:14:32,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 06:47:53,310 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:47:53,315 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:47:54,671 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:47:54,675 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:47:54,678 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-2500/special_tokens_map.json\n","{'loss': 1.2371, 'learning_rate': 2.9078995267564617e-05, 'epoch': 0.55}\n"," 27% 3000/10988 [26:40<1:10:12,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 06:52:21,415 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3000\n","[INFO|configuration_utils.py:441] 2022-04-07 06:52:21,422 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:52:22,761 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:52:22,765 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:52:22,768 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3000/special_tokens_map.json\n","{'loss': 1.2152, 'learning_rate': 2.725882781215872e-05, 'epoch': 0.64}\n"," 32% 3500/10988 [31:08<1:05:38,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 06:56:49,151 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3500\n","[INFO|configuration_utils.py:441] 2022-04-07 06:56:49,156 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 06:56:50,505 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 06:56:50,509 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 06:56:50,513 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-3500/special_tokens_map.json\n","{'loss': 1.1838, 'learning_rate': 2.5438660356752823e-05, 'epoch': 0.73}\n"," 36% 4000/10988 [35:35<1:01:11,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 07:01:16,415 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:01:16,422 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:01:17,750 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:01:17,755 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:01:17,758 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4000/special_tokens_map.json\n","{'loss': 1.148, 'learning_rate': 2.3618492901346928e-05, 'epoch': 0.82}\n"," 41% 4500/10988 [40:03<56:54,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 07:05:44,221 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:05:44,226 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:05:45,634 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:05:45,658 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:05:45,672 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-4500/special_tokens_map.json\n","{'loss': 1.1255, 'learning_rate': 2.1798325445941027e-05, 'epoch': 0.91}\n"," 46% 5000/10988 [44:31<52:21,  1.91it/s][INFO|trainer.py:2166] 2022-04-07 07:10:12,115 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:10:12,122 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:10:13,529 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:10:13,533 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:10:13,536 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5000/special_tokens_map.json\n","{'loss': 1.123, 'learning_rate': 1.997815799053513e-05, 'epoch': 1.0}\n"," 50% 5500/10988 [48:57<46:57,  1.95it/s][INFO|trainer.py:2166] 2022-04-07 07:14:38,976 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:14:38,981 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:14:40,293 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:14:40,298 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:14:40,302 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-5500/special_tokens_map.json\n","{'loss': 0.877, 'learning_rate': 1.8157990535129233e-05, 'epoch': 1.09}\n"," 55% 6000/10988 [53:25<43:40,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 07:19:06,264 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:19:06,269 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:19:07,628 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:19:07,633 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:19:07,636 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6000/special_tokens_map.json\n","{'loss': 0.8736, 'learning_rate': 1.6337823079723335e-05, 'epoch': 1.18}\n"," 59% 6500/10988 [57:52<39:14,  1.91it/s][INFO|trainer.py:2166] 2022-04-07 07:23:33,810 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:23:33,816 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:23:35,176 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:23:35,181 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:23:35,185 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-6500/special_tokens_map.json\n","{'loss': 0.8532, 'learning_rate': 1.451765562431744e-05, 'epoch': 1.27}\n"," 64% 7000/10988 [1:02:20<34:58,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 07:28:01,423 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:28:01,429 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:28:02,762 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:28:02,766 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:28:02,769 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7000/special_tokens_map.json\n","{'loss': 0.8746, 'learning_rate': 1.269748816891154e-05, 'epoch': 1.37}\n"," 68% 7500/10988 [1:06:48<30:31,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 07:32:29,043 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:32:29,049 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:32:30,396 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:32:30,401 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:32:30,405 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-7500/special_tokens_map.json\n","{'loss': 0.8282, 'learning_rate': 1.0877320713505643e-05, 'epoch': 1.46}\n"," 73% 8000/10988 [1:11:15<26:08,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 07:36:56,647 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:36:56,652 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:36:58,065 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:36:58,070 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:36:58,073 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8000/special_tokens_map.json\n","{'loss': 0.8155, 'learning_rate': 9.057153258099745e-06, 'epoch': 1.55}\n"," 77% 8500/10988 [1:15:43<21:46,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 07:41:24,332 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:41:24,338 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:41:25,615 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:41:25,619 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:41:25,624 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-8500/special_tokens_map.json\n","{'loss': 0.7948, 'learning_rate': 7.236985802693849e-06, 'epoch': 1.64}\n"," 82% 9000/10988 [1:20:10<17:20,  1.91it/s][INFO|trainer.py:2166] 2022-04-07 07:45:51,452 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:45:51,457 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:45:52,731 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:45:52,735 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:45:52,738 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9000/special_tokens_map.json\n","{'loss': 0.8093, 'learning_rate': 5.416818347287951e-06, 'epoch': 1.73}\n"," 86% 9500/10988 [1:24:37<13:01,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 07:50:18,556 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:50:18,561 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:50:19,849 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:50:19,854 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:50:19,858 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-9500/special_tokens_map.json\n","{'loss': 0.7977, 'learning_rate': 3.5966508918820536e-06, 'epoch': 1.82}\n"," 91% 10000/10988 [1:29:04<08:37,  1.91it/s][INFO|trainer.py:2166] 2022-04-07 07:54:45,541 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10000\n","[INFO|configuration_utils.py:441] 2022-04-07 07:54:45,547 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10000/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:54:46,819 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10000/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:54:46,823 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10000/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:54:46,826 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10000/special_tokens_map.json\n","{'loss': 0.7861, 'learning_rate': 1.776483436476156e-06, 'epoch': 1.91}\n"," 96% 10500/10988 [1:33:31<04:16,  1.90it/s][INFO|trainer.py:2166] 2022-04-07 07:59:12,304 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10500\n","[INFO|configuration_utils.py:441] 2022-04-07 07:59:12,309 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10500/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 07:59:13,591 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10500/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 07:59:13,597 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10500/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 07:59:13,601 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/checkpoint-10500/special_tokens_map.json\n","100% 10988/10988 [1:37:51<00:00,  2.41it/s][INFO|trainer.py:1530] 2022-04-07 08:03:32,814 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 5871.8118, 'train_samples_per_second': 44.905, 'train_steps_per_second': 1.871, 'train_loss': 1.0758908427668608, 'epoch': 2.0}\n","100% 10988/10988 [1:37:51<00:00,  1.87it/s]\n","[INFO|trainer.py:2166] 2022-04-07 08:03:32,832 >> Saving model checkpoint to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug\n","[INFO|configuration_utils.py:441] 2022-04-07 08:03:32,837 >> Configuration saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/config.json\n","[INFO|modeling_utils.py:1378] 2022-04-07 08:03:34,144 >> Model weights saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/pytorch_model.bin\n","[INFO|tokenization_utils_base.py:2086] 2022-04-07 08:03:34,150 >> tokenizer config file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2092] 2022-04-07 08:03:34,154 >> Special tokens file saved in /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/special_tokens_map.json\n","***** train metrics *****\n","  epoch                    =        2.0\n","  train_loss               =     1.0759\n","  train_runtime            = 1:37:51.81\n","  train_samples            =     131838\n","  train_samples_per_second =     44.905\n","  train_steps_per_second   =      1.871\n","04/07/2022 08:03:34 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:567] 2022-04-07 08:03:34,314 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id. If offset_mapping, example_id are not expected by `RobertaForQuestionAnswering.forward`,  you can safely ignore this message.\n","[INFO|trainer.py:2416] 2022-04-07 08:03:34,316 >> ***** Running Evaluation *****\n","[INFO|trainer.py:2418] 2022-04-07 08:03:34,316 >>   Num examples = 12165\n","[INFO|trainer.py:2421] 2022-04-07 08:03:34,317 >>   Batch size = 8\n","100% 1520/1521 [01:34<00:00, 16.24it/s]04/07/2022 08:05:20 - INFO - utils_qa - Post-processing 11873 example predictions split into 12165 features.\n","\n","  0% 0/11873 [00:00<?, ?it/s]\u001b[A\n","  0% 42/11873 [00:00<00:28, 417.52it/s]\u001b[A\n","  1% 84/11873 [00:00<00:30, 388.36it/s]\u001b[A\n","  1% 127/11873 [00:00<00:28, 405.78it/s]\u001b[A\n","  1% 172/11873 [00:00<00:27, 422.57it/s]\u001b[A\n","  2% 217/11873 [00:00<00:27, 430.95it/s]\u001b[A\n","  2% 263/11873 [00:00<00:26, 439.43it/s]\u001b[A\n","  3% 308/11873 [00:00<00:26, 441.41it/s]\u001b[A\n","  3% 353/11873 [00:00<00:26, 438.44it/s]\u001b[A\n","  3% 397/11873 [00:00<00:26, 437.12it/s]\u001b[A\n","  4% 443/11873 [00:01<00:25, 442.39it/s]\u001b[A\n","  4% 488/11873 [00:01<00:25, 443.95it/s]\u001b[A\n","  4% 533/11873 [00:01<00:26, 433.03it/s]\u001b[A\n","  5% 577/11873 [00:01<00:26, 429.99it/s]\u001b[A\n","  5% 623/11873 [00:01<00:25, 436.83it/s]\u001b[A\n","  6% 668/11873 [00:01<00:25, 440.01it/s]\u001b[A\n","  6% 713/11873 [00:01<00:25, 429.50it/s]\u001b[A\n","  6% 757/11873 [00:01<00:26, 424.44it/s]\u001b[A\n","  7% 801/11873 [00:01<00:25, 428.09it/s]\u001b[A\n","  7% 846/11873 [00:01<00:25, 432.67it/s]\u001b[A\n","  8% 893/11873 [00:02<00:24, 440.19it/s]\u001b[A\n","  8% 938/11873 [00:02<00:24, 442.51it/s]\u001b[A\n","  8% 983/11873 [00:02<00:24, 441.89it/s]\u001b[A\n","  9% 1028/11873 [00:02<00:26, 411.66it/s]\u001b[A\n","  9% 1070/11873 [00:02<00:27, 387.59it/s]\u001b[A\n","  9% 1110/11873 [00:02<00:29, 370.55it/s]\u001b[A\n"," 10% 1148/11873 [00:02<00:29, 359.36it/s]\u001b[A\n"," 10% 1185/11873 [00:02<00:30, 352.85it/s]\u001b[A\n"," 10% 1221/11873 [00:02<00:30, 347.79it/s]\u001b[A\n"," 11% 1256/11873 [00:03<00:30, 344.94it/s]\u001b[A\n"," 11% 1291/11873 [00:03<00:30, 343.40it/s]\u001b[A\n"," 11% 1326/11873 [00:03<00:30, 340.51it/s]\u001b[A\n"," 11% 1362/11873 [00:03<00:30, 344.99it/s]\u001b[A\n"," 12% 1397/11873 [00:03<00:30, 343.55it/s]\u001b[A\n"," 12% 1432/11873 [00:03<00:30, 342.46it/s]\u001b[A\n"," 12% 1467/11873 [00:03<00:31, 334.72it/s]\u001b[A\n"," 13% 1501/11873 [00:03<00:30, 336.15it/s]\u001b[A\n"," 13% 1536/11873 [00:03<00:30, 338.37it/s]\u001b[A\n"," 13% 1570/11873 [00:03<00:30, 338.26it/s]\u001b[A\n"," 14% 1605/11873 [00:04<00:30, 340.10it/s]\u001b[A\n"," 14% 1640/11873 [00:04<00:30, 339.10it/s]\u001b[A\n"," 14% 1674/11873 [00:04<00:30, 335.16it/s]\u001b[A\n"," 14% 1708/11873 [00:04<00:30, 333.77it/s]\u001b[A\n"," 15% 1742/11873 [00:04<00:30, 333.84it/s]\u001b[A\n"," 15% 1776/11873 [00:04<00:30, 330.16it/s]\u001b[A\n"," 15% 1810/11873 [00:04<00:30, 330.39it/s]\u001b[A\n"," 16% 1844/11873 [00:04<00:30, 331.78it/s]\u001b[A\n"," 16% 1878/11873 [00:04<00:30, 332.58it/s]\u001b[A\n"," 16% 1913/11873 [00:05<00:29, 336.30it/s]\u001b[A\n"," 16% 1948/11873 [00:05<00:29, 339.82it/s]\u001b[A\n"," 17% 1983/11873 [00:05<00:28, 342.13it/s]\u001b[A\n"," 17% 2019/11873 [00:05<00:28, 344.72it/s]\u001b[A\n"," 17% 2054/11873 [00:05<00:28, 343.27it/s]\u001b[A\n"," 18% 2089/11873 [00:05<00:28, 344.02it/s]\u001b[A\n"," 18% 2124/11873 [00:05<00:28, 343.93it/s]\u001b[A\n"," 18% 2159/11873 [00:05<00:28, 341.09it/s]\u001b[A\n"," 18% 2194/11873 [00:05<00:28, 340.50it/s]\u001b[A\n"," 19% 2229/11873 [00:05<00:28, 342.06it/s]\u001b[A\n"," 19% 2265/11873 [00:06<00:27, 346.08it/s]\u001b[A\n"," 19% 2301/11873 [00:06<00:27, 347.79it/s]\u001b[A\n"," 20% 2336/11873 [00:06<00:27, 344.63it/s]\u001b[A\n"," 20% 2373/11873 [00:06<00:27, 351.81it/s]\u001b[A\n"," 20% 2409/11873 [00:06<00:27, 346.62it/s]\u001b[A\n"," 21% 2444/11873 [00:06<00:27, 343.10it/s]\u001b[A\n"," 21% 2479/11873 [00:06<00:27, 342.70it/s]\u001b[A\n"," 21% 2514/11873 [00:06<00:27, 341.79it/s]\u001b[A\n"," 21% 2550/11873 [00:06<00:26, 346.20it/s]\u001b[A\n"," 22% 2586/11873 [00:06<00:26, 349.80it/s]\u001b[A\n"," 22% 2621/11873 [00:07<00:26, 347.60it/s]\u001b[A\n","100% 1521/1521 [01:53<00:00, 16.24it/s]\n"," 23% 2691/11873 [00:07<00:26, 345.50it/s]\u001b[A\n"," 23% 2727/11873 [00:07<00:26, 347.10it/s]\u001b[A\n"," 23% 2762/11873 [00:07<00:26, 345.66it/s]\u001b[A\n"," 24% 2797/11873 [00:07<00:26, 344.38it/s]\u001b[A\n"," 24% 2832/11873 [00:07<00:26, 345.05it/s]\u001b[A\n"," 24% 2868/11873 [00:07<00:25, 347.87it/s]\u001b[A\n"," 24% 2903/11873 [00:07<00:26, 344.17it/s]\u001b[A\n"," 25% 2938/11873 [00:07<00:25, 345.24it/s]\u001b[A\n"," 25% 2973/11873 [00:08<00:25, 346.03it/s]\u001b[A\n"," 25% 3008/11873 [00:08<00:26, 337.63it/s]\u001b[A\n"," 26% 3043/11873 [00:08<00:26, 339.07it/s]\u001b[A\n"," 26% 3077/11873 [00:08<00:26, 334.89it/s]\u001b[A\n"," 26% 3111/11873 [00:08<00:28, 312.48it/s]\u001b[A\n"," 26% 3143/11873 [00:08<00:31, 274.44it/s]\u001b[A\n"," 27% 3172/11873 [00:08<00:32, 265.64it/s]\u001b[A\n"," 27% 3205/11873 [00:08<00:30, 281.31it/s]\u001b[A\n"," 27% 3239/11873 [00:09<00:29, 297.11it/s]\u001b[A\n"," 28% 3270/11873 [00:09<00:29, 289.10it/s]\u001b[A\n"," 28% 3300/11873 [00:09<00:39, 218.30it/s]\u001b[A\n"," 28% 3325/11873 [00:09<00:43, 197.68it/s]\u001b[A\n"," 28% 3348/11873 [00:09<00:41, 204.02it/s]\u001b[A\n"," 28% 3371/11873 [00:09<00:44, 190.12it/s]\u001b[A\n"," 29% 3406/11873 [00:09<00:37, 227.06it/s]\u001b[A\n"," 29% 3440/11873 [00:09<00:33, 255.21it/s]\u001b[A\n"," 29% 3474/11873 [00:10<00:30, 277.00it/s]\u001b[A\n"," 30% 3508/11873 [00:10<00:28, 292.59it/s]\u001b[A\n"," 30% 3542/11873 [00:10<00:27, 305.82it/s]\u001b[A\n"," 30% 3575/11873 [00:10<00:26, 312.13it/s]\u001b[A\n"," 30% 3610/11873 [00:10<00:25, 322.63it/s]\u001b[A\n"," 31% 3646/11873 [00:10<00:24, 332.83it/s]\u001b[A\n"," 31% 3680/11873 [00:10<00:24, 330.27it/s]\u001b[A\n"," 31% 3714/11873 [00:10<00:24, 330.77it/s]\u001b[A\n"," 32% 3749/11873 [00:10<00:24, 335.49it/s]\u001b[A\n"," 32% 3783/11873 [00:10<00:24, 329.64it/s]\u001b[A\n"," 32% 3817/11873 [00:11<00:25, 319.26it/s]\u001b[A\n"," 32% 3850/11873 [00:11<00:25, 309.68it/s]\u001b[A\n"," 33% 3883/11873 [00:11<00:25, 315.36it/s]\u001b[A\n"," 33% 3915/11873 [00:11<00:25, 309.96it/s]\u001b[A\n"," 33% 3947/11873 [00:11<00:25, 308.08it/s]\u001b[A\n"," 34% 3980/11873 [00:11<00:25, 313.86it/s]\u001b[A\n"," 34% 4015/11873 [00:11<00:24, 324.19it/s]\u001b[A\n"," 34% 4048/11873 [00:11<00:24, 324.58it/s]\u001b[A\n"," 34% 4082/11873 [00:11<00:23, 328.71it/s]\u001b[A\n"," 35% 4117/11873 [00:12<00:23, 334.44it/s]\u001b[A\n"," 35% 4151/11873 [00:12<00:24, 310.55it/s]\u001b[A\n"," 35% 4184/11873 [00:12<00:24, 315.02it/s]\u001b[A\n"," 36% 4219/11873 [00:12<00:23, 323.55it/s]\u001b[A\n"," 36% 4255/11873 [00:12<00:22, 331.36it/s]\u001b[A\n"," 36% 4291/11873 [00:12<00:22, 339.20it/s]\u001b[A\n"," 36% 4327/11873 [00:12<00:21, 344.50it/s]\u001b[A\n"," 37% 4363/11873 [00:12<00:21, 347.08it/s]\u001b[A\n"," 37% 4398/11873 [00:12<00:21, 340.86it/s]\u001b[A\n"," 37% 4433/11873 [00:13<00:26, 276.80it/s]\u001b[A\n"," 38% 4469/11873 [00:13<00:24, 297.63it/s]\u001b[A\n"," 38% 4504/11873 [00:13<00:23, 311.01it/s]\u001b[A\n"," 38% 4539/11873 [00:13<00:22, 319.69it/s]\u001b[A\n"," 39% 4576/11873 [00:13<00:22, 331.22it/s]\u001b[A\n"," 39% 4612/11873 [00:13<00:21, 336.90it/s]\u001b[A\n"," 39% 4647/11873 [00:13<00:21, 336.84it/s]\u001b[A\n"," 39% 4682/11873 [00:13<00:21, 339.29it/s]\u001b[A\n"," 40% 4717/11873 [00:13<00:21, 336.77it/s]\u001b[A\n"," 40% 4752/11873 [00:13<00:21, 337.83it/s]\u001b[A\n"," 40% 4786/11873 [00:14<00:21, 335.50it/s]\u001b[A\n"," 41% 4820/11873 [00:14<00:21, 332.31it/s]\u001b[A\n"," 41% 4855/11873 [00:14<00:20, 335.03it/s]\u001b[A\n"," 41% 4889/11873 [00:14<00:20, 336.09it/s]\u001b[A\n"," 41% 4923/11873 [00:14<00:20, 333.31it/s]\u001b[A\n"," 42% 4959/11873 [00:14<00:20, 339.81it/s]\u001b[A\n"," 42% 4994/11873 [00:14<00:20, 335.12it/s]\u001b[A\n"," 42% 5028/11873 [00:14<00:20, 326.61it/s]\u001b[A\n"," 43% 5062/11873 [00:14<00:20, 330.43it/s]\u001b[A\n"," 43% 5097/11873 [00:15<00:20, 334.36it/s]\u001b[A\n"," 43% 5132/11873 [00:15<00:20, 337.04it/s]\u001b[A\n"," 44% 5168/11873 [00:15<00:19, 341.57it/s]\u001b[A\n"," 44% 5204/11873 [00:15<00:19, 345.11it/s]\u001b[A\n"," 44% 5239/11873 [00:15<00:19, 342.99it/s]\u001b[A\n"," 44% 5274/11873 [00:15<00:20, 321.03it/s]\u001b[A\n"," 45% 5308/11873 [00:15<00:20, 324.36it/s]\u001b[A\n"," 45% 5343/11873 [00:15<00:19, 331.19it/s]\u001b[A\n"," 45% 5377/11873 [00:15<00:19, 332.10it/s]\u001b[A\n"," 46% 5412/11873 [00:15<00:19, 336.71it/s]\u001b[A\n"," 46% 5446/11873 [00:16<00:19, 334.64it/s]\u001b[A\n"," 46% 5481/11873 [00:16<00:19, 336.22it/s]\u001b[A\n"," 46% 5518/11873 [00:16<00:18, 345.17it/s]\u001b[A\n"," 47% 5553/11873 [00:16<00:18, 342.69it/s]\u001b[A\n"," 47% 5588/11873 [00:16<00:18, 341.14it/s]\u001b[A\n"," 47% 5623/11873 [00:16<00:18, 331.50it/s]\u001b[A\n"," 48% 5657/11873 [00:16<00:18, 332.00it/s]\u001b[A\n"," 48% 5691/11873 [00:16<00:18, 333.48it/s]\u001b[A\n"," 48% 5725/11873 [00:16<00:18, 334.27it/s]\u001b[A\n"," 49% 5760/11873 [00:16<00:18, 336.48it/s]\u001b[A\n"," 49% 5796/11873 [00:17<00:17, 342.97it/s]\u001b[A\n"," 49% 5831/11873 [00:17<00:17, 343.61it/s]\u001b[A\n"," 49% 5867/11873 [00:17<00:17, 347.88it/s]\u001b[A\n"," 50% 5902/11873 [00:17<00:17, 345.59it/s]\u001b[A\n"," 50% 5937/11873 [00:17<00:17, 339.35it/s]\u001b[A\n"," 50% 5972/11873 [00:17<00:17, 342.30it/s]\u001b[A\n"," 51% 6007/11873 [00:17<00:17, 336.99it/s]\u001b[A\n"," 51% 6042/11873 [00:17<00:17, 339.96it/s]\u001b[A\n"," 51% 6077/11873 [00:17<00:17, 338.92it/s]\u001b[A\n"," 51% 6111/11873 [00:18<00:17, 336.77it/s]\u001b[A\n"," 52% 6147/11873 [00:18<00:16, 342.07it/s]\u001b[A\n"," 52% 6182/11873 [00:18<00:16, 341.94it/s]\u001b[A\n"," 52% 6217/11873 [00:18<00:16, 342.09it/s]\u001b[A\n"," 53% 6253/11873 [00:18<00:16, 344.99it/s]\u001b[A\n"," 53% 6289/11873 [00:18<00:16, 346.80it/s]\u001b[A\n"," 53% 6324/11873 [00:18<00:16, 342.32it/s]\u001b[A\n"," 54% 6359/11873 [00:18<00:16, 344.35it/s]\u001b[A\n"," 54% 6394/11873 [00:18<00:15, 343.71it/s]\u001b[A\n"," 54% 6429/11873 [00:18<00:16, 338.81it/s]\u001b[A\n"," 54% 6463/11873 [00:19<00:16, 338.12it/s]\u001b[A\n"," 55% 6497/11873 [00:19<00:15, 336.41it/s]\u001b[A\n"," 55% 6531/11873 [00:19<00:16, 330.08it/s]\u001b[A\n"," 55% 6565/11873 [00:19<00:16, 329.69it/s]\u001b[A\n"," 56% 6598/11873 [00:19<00:16, 322.62it/s]\u001b[A\n"," 56% 6632/11873 [00:19<00:16, 326.02it/s]\u001b[A\n"," 56% 6665/11873 [00:19<00:15, 326.88it/s]\u001b[A\n"," 56% 6700/11873 [00:19<00:15, 331.47it/s]\u001b[A\n"," 57% 6734/11873 [00:19<00:17, 296.89it/s]\u001b[A\n"," 57% 6768/11873 [00:20<00:16, 307.31it/s]\u001b[A\n"," 57% 6802/11873 [00:20<00:16, 315.03it/s]\u001b[A\n"," 58% 6835/11873 [00:20<00:15, 316.68it/s]\u001b[A\n"," 58% 6869/11873 [00:20<00:15, 322.15it/s]\u001b[A\n"," 58% 6902/11873 [00:20<00:15, 322.47it/s]\u001b[A\n"," 58% 6936/11873 [00:20<00:15, 324.71it/s]\u001b[A\n"," 59% 6971/11873 [00:20<00:14, 330.55it/s]\u001b[A\n"," 59% 7006/11873 [00:20<00:14, 334.27it/s]\u001b[A\n"," 59% 7040/11873 [00:20<00:14, 334.43it/s]\u001b[A\n"," 60% 7074/11873 [00:20<00:14, 333.87it/s]\u001b[A\n"," 60% 7108/11873 [00:21<00:14, 333.44it/s]\u001b[A\n"," 60% 7142/11873 [00:21<00:14, 332.85it/s]\u001b[A\n"," 60% 7176/11873 [00:21<00:14, 333.53it/s]\u001b[A\n"," 61% 7211/11873 [00:21<00:13, 337.23it/s]\u001b[A\n"," 61% 7245/11873 [00:21<00:14, 329.18it/s]\u001b[A\n"," 61% 7281/11873 [00:21<00:13, 335.56it/s]\u001b[A\n"," 62% 7316/11873 [00:21<00:13, 337.64it/s]\u001b[A\n"," 62% 7350/11873 [00:21<00:13, 338.09it/s]\u001b[A\n"," 62% 7385/11873 [00:21<00:13, 339.85it/s]\u001b[A\n"," 62% 7420/11873 [00:21<00:13, 321.17it/s]\u001b[A\n"," 63% 7454/11873 [00:22<00:13, 325.69it/s]\u001b[A\n"," 63% 7487/11873 [00:22<00:13, 325.00it/s]\u001b[A\n"," 63% 7522/11873 [00:22<00:13, 331.18it/s]\u001b[A\n"," 64% 7556/11873 [00:22<00:13, 331.05it/s]\u001b[A\n"," 64% 7590/11873 [00:22<00:12, 332.95it/s]\u001b[A\n"," 64% 7624/11873 [00:22<00:12, 332.54it/s]\u001b[A\n"," 65% 7659/11873 [00:22<00:12, 335.74it/s]\u001b[A\n"," 65% 7693/11873 [00:22<00:12, 334.01it/s]\u001b[A\n"," 65% 7727/11873 [00:22<00:13, 311.06it/s]\u001b[A\n"," 65% 7759/11873 [00:23<00:13, 311.03it/s]\u001b[A\n"," 66% 7793/11873 [00:23<00:12, 317.50it/s]\u001b[A\n"," 66% 7826/11873 [00:23<00:12, 320.59it/s]\u001b[A\n"," 66% 7859/11873 [00:23<00:12, 319.11it/s]\u001b[A\n"," 66% 7892/11873 [00:23<00:13, 305.92it/s]\u001b[A\n"," 67% 7927/11873 [00:23<00:12, 317.13it/s]\u001b[A\n"," 67% 7962/11873 [00:23<00:12, 324.56it/s]\u001b[A\n"," 67% 7996/11873 [00:23<00:11, 327.37it/s]\u001b[A\n"," 68% 8032/11873 [00:23<00:11, 334.18it/s]\u001b[A\n"," 68% 8066/11873 [00:23<00:11, 331.65it/s]\u001b[A\n"," 68% 8100/11873 [00:24<00:11, 331.99it/s]\u001b[A\n"," 69% 8134/11873 [00:24<00:11, 330.87it/s]\u001b[A\n"," 69% 8170/11873 [00:24<00:10, 336.96it/s]\u001b[A\n"," 69% 8204/11873 [00:24<00:10, 337.15it/s]\u001b[A\n"," 69% 8238/11873 [00:24<00:10, 333.21it/s]\u001b[A\n"," 70% 8272/11873 [00:24<00:10, 334.00it/s]\u001b[A\n"," 70% 8306/11873 [00:24<00:10, 333.03it/s]\u001b[A\n"," 70% 8341/11873 [00:24<00:10, 336.84it/s]\u001b[A\n"," 71% 8376/11873 [00:24<00:10, 338.64it/s]\u001b[A\n"," 71% 8410/11873 [00:24<00:10, 335.09it/s]\u001b[A\n"," 71% 8445/11873 [00:25<00:10, 336.65it/s]\u001b[A\n"," 71% 8480/11873 [00:25<00:10, 338.73it/s]\u001b[A\n"," 72% 8516/11873 [00:25<00:09, 344.41it/s]\u001b[A\n"," 72% 8551/11873 [00:25<00:09, 343.36it/s]\u001b[A\n"," 72% 8586/11873 [00:25<00:09, 342.20it/s]\u001b[A\n"," 73% 8621/11873 [00:25<00:09, 340.64it/s]\u001b[A\n"," 73% 8656/11873 [00:25<00:09, 342.38it/s]\u001b[A\n"," 73% 8691/11873 [00:25<00:09, 340.68it/s]\u001b[A\n"," 74% 8727/11873 [00:25<00:09, 344.27it/s]\u001b[A\n"," 74% 8763/11873 [00:25<00:08, 346.63it/s]\u001b[A\n"," 74% 8799/11873 [00:26<00:08, 347.48it/s]\u001b[A\n"," 74% 8834/11873 [00:26<00:08, 346.01it/s]\u001b[A\n"," 75% 8870/11873 [00:26<00:08, 348.26it/s]\u001b[A\n"," 75% 8905/11873 [00:26<00:08, 344.56it/s]\u001b[A\n"," 75% 8940/11873 [00:26<00:08, 340.50it/s]\u001b[A\n"," 76% 8975/11873 [00:26<00:08, 340.31it/s]\u001b[A\n"," 76% 9010/11873 [00:26<00:08, 338.85it/s]\u001b[A\n"," 76% 9044/11873 [00:26<00:08, 338.66it/s]\u001b[A\n"," 76% 9078/11873 [00:26<00:08, 338.06it/s]\u001b[A\n"," 77% 9112/11873 [00:27<00:08, 338.56it/s]\u001b[A\n"," 77% 9147/11873 [00:27<00:08, 340.52it/s]\u001b[A\n"," 77% 9182/11873 [00:27<00:07, 343.12it/s]\u001b[A\n"," 78% 9217/11873 [00:27<00:07, 345.05it/s]\u001b[A\n"," 78% 9252/11873 [00:27<00:07, 339.85it/s]\u001b[A\n"," 78% 9287/11873 [00:27<00:07, 341.82it/s]\u001b[A\n"," 79% 9322/11873 [00:27<00:07, 342.73it/s]\u001b[A\n"," 79% 9357/11873 [00:27<00:07, 343.10it/s]\u001b[A\n"," 79% 9393/11873 [00:27<00:07, 346.68it/s]\u001b[A\n"," 79% 9428/11873 [00:27<00:07, 345.86it/s]\u001b[A\n"," 80% 9463/11873 [00:28<00:06, 346.66it/s]\u001b[A\n"," 80% 9499/11873 [00:28<00:06, 348.80it/s]\u001b[A\n"," 80% 9535/11873 [00:28<00:06, 349.49it/s]\u001b[A\n"," 81% 9570/11873 [00:28<00:06, 348.01it/s]\u001b[A\n"," 81% 9605/11873 [00:28<00:06, 335.76it/s]\u001b[A\n"," 81% 9639/11873 [00:28<00:06, 335.40it/s]\u001b[A\n"," 81% 9674/11873 [00:28<00:06, 337.34it/s]\u001b[A\n"," 82% 9710/11873 [00:28<00:06, 342.52it/s]\u001b[A\n"," 82% 9747/11873 [00:28<00:06, 348.02it/s]\u001b[A\n"," 82% 9783/11873 [00:28<00:05, 350.52it/s]\u001b[A\n"," 83% 9819/11873 [00:29<00:05, 347.21it/s]\u001b[A\n"," 83% 9854/11873 [00:29<00:05, 346.85it/s]\u001b[A\n"," 83% 9889/11873 [00:29<00:05, 342.32it/s]\u001b[A\n"," 84% 9924/11873 [00:29<00:05, 339.04it/s]\u001b[A\n"," 84% 9959/11873 [00:29<00:05, 340.14it/s]\u001b[A\n"," 84% 9994/11873 [00:29<00:05, 338.06it/s]\u001b[A\n"," 84% 10029/11873 [00:29<00:05, 338.83it/s]\u001b[A\n"," 85% 10064/11873 [00:29<00:05, 339.33it/s]\u001b[A\n"," 85% 10099/11873 [00:29<00:05, 342.14it/s]\u001b[A\n"," 85% 10134/11873 [00:30<00:05, 341.44it/s]\u001b[A\n"," 86% 10169/11873 [00:30<00:05, 337.02it/s]\u001b[A\n"," 86% 10203/11873 [00:30<00:04, 334.84it/s]\u001b[A\n"," 86% 10237/11873 [00:30<00:04, 336.30it/s]\u001b[A\n"," 87% 10272/11873 [00:30<00:04, 338.57it/s]\u001b[A\n"," 87% 10306/11873 [00:30<00:04, 333.67it/s]\u001b[A\n"," 87% 10341/11873 [00:30<00:04, 336.88it/s]\u001b[A\n"," 87% 10377/11873 [00:30<00:04, 341.59it/s]\u001b[A\n"," 88% 10412/11873 [00:30<00:04, 341.47it/s]\u001b[A\n"," 88% 10447/11873 [00:30<00:04, 326.16it/s]\u001b[A\n"," 88% 10481/11873 [00:31<00:04, 329.27it/s]\u001b[A\n"," 89% 10515/11873 [00:31<00:04, 330.51it/s]\u001b[A\n"," 89% 10549/11873 [00:31<00:03, 331.39it/s]\u001b[A\n"," 89% 10583/11873 [00:31<00:03, 332.58it/s]\u001b[A\n"," 89% 10617/11873 [00:31<00:03, 332.51it/s]\u001b[A\n"," 90% 10651/11873 [00:31<00:03, 331.31it/s]\u001b[A\n"," 90% 10686/11873 [00:31<00:03, 336.04it/s]\u001b[A\n"," 90% 10721/11873 [00:31<00:03, 340.05it/s]\u001b[A\n"," 91% 10756/11873 [00:31<00:03, 338.86it/s]\u001b[A\n"," 91% 10790/11873 [00:31<00:03, 337.47it/s]\u001b[A\n"," 91% 10824/11873 [00:32<00:03, 314.07it/s]\u001b[A\n"," 91% 10856/11873 [00:32<00:03, 314.03it/s]\u001b[A\n"," 92% 10890/11873 [00:32<00:03, 320.77it/s]\u001b[A\n"," 92% 10923/11873 [00:32<00:02, 319.31it/s]\u001b[A\n"," 92% 10958/11873 [00:32<00:02, 327.44it/s]\u001b[A\n"," 93% 10994/11873 [00:32<00:02, 336.26it/s]\u001b[A\n"," 93% 11030/11873 [00:32<00:02, 340.89it/s]\u001b[A\n"," 93% 11066/11873 [00:32<00:02, 344.42it/s]\u001b[A\n"," 93% 11101/11873 [00:32<00:02, 344.97it/s]\u001b[A\n"," 94% 11136/11873 [00:33<00:02, 340.77it/s]\u001b[A\n"," 94% 11171/11873 [00:33<00:02, 338.27it/s]\u001b[A\n"," 94% 11206/11873 [00:33<00:01, 338.68it/s]\u001b[A\n"," 95% 11240/11873 [00:33<00:01, 336.59it/s]\u001b[A\n"," 95% 11275/11873 [00:33<00:01, 338.76it/s]\u001b[A\n"," 95% 11310/11873 [00:33<00:01, 340.47it/s]\u001b[A\n"," 96% 11345/11873 [00:33<00:01, 338.64it/s]\u001b[A\n"," 96% 11380/11873 [00:33<00:01, 341.50it/s]\u001b[A\n"," 96% 11415/11873 [00:33<00:01, 340.75it/s]\u001b[A\n"," 96% 11450/11873 [00:33<00:01, 338.58it/s]\u001b[A\n"," 97% 11484/11873 [00:34<00:01, 338.24it/s]\u001b[A\n"," 97% 11518/11873 [00:34<00:01, 336.16it/s]\u001b[A\n"," 97% 11552/11873 [00:34<00:00, 334.76it/s]\u001b[A\n"," 98% 11588/11873 [00:34<00:00, 341.71it/s]\u001b[A\n"," 98% 11623/11873 [00:34<00:00, 339.77it/s]\u001b[A\n"," 98% 11660/11873 [00:34<00:00, 346.72it/s]\u001b[A\n"," 99% 11695/11873 [00:34<00:00, 345.39it/s]\u001b[A\n"," 99% 11730/11873 [00:34<00:00, 344.95it/s]\u001b[A\n"," 99% 11765/11873 [00:34<00:00, 337.39it/s]\u001b[A\n"," 99% 11801/11873 [00:34<00:00, 341.90it/s]\u001b[A\n","100% 11836/11873 [00:35<00:00, 342.76it/s]\u001b[A\n","100% 11873/11873 [00:35<00:00, 337.55it/s]\n","04/07/2022 08:05:55 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/eval_predictions.json.\n","04/07/2022 08:05:55 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/eval_nbest_predictions.json.\n","04/07/2022 08:05:58 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/QA/model_results/roberta-base/back-trans-synonym-aug/eval_null_odds.json.\n","04/07/2022 08:06:01 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n","100% 1521/1521 [02:27<00:00, 10.33it/s]\n","***** eval metrics *****\n","  epoch                  =     2.0\n","  eval_HasAns_exact      = 79.9426\n","  eval_HasAns_f1         = 85.8184\n","  eval_HasAns_total      =    5928\n","  eval_NoAns_exact       = 73.8267\n","  eval_NoAns_f1          = 73.8267\n","  eval_NoAns_total       =    5945\n","  eval_best_exact        = 76.8803\n","  eval_best_exact_thresh =     0.0\n","  eval_best_f1           =  79.814\n","  eval_best_f1_thresh    =     0.0\n","  eval_exact             = 76.8803\n","  eval_f1                =  79.814\n","  eval_samples           =   12165\n","  eval_total             =   11873\n","[INFO|modelcard.py:460] 2022-04-07 08:06:02,111 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'sichenzhong/squad_v2_back_trans_synonym_aug', 'type': 'sichenzhong/squad_v2_back_trans_synonym_aug', 'args': 'squad_v2'}}\n"]}]}]}